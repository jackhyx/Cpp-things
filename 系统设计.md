#### 场景题：转账操作怎么设计

场景题：库存在redis中缓存，秒杀时redis单点可以承受1000tps
怎么样处理10000tps的请求？(纯用redis解决，不考虑限流）（集群，但集群时各结点库存怎么分配需要认真考虑）

系统设计题：如何解决进程切换、周期任务和非周期任务的处理、任务集改变的处理。

#### 分布式锁怎么实现

场景题：一个订单，有创建订单、待支付、支付成功、支付失败这几个状态，超时未支付则支付失败，应该怎么设计(可以使用任何中间件)

然后问一个系统设计需要注意些什么和各自的作用：答了低耦合性，可拓展性，并发性什么的（说实话我不确定这是考的什么，哪里有整理的比较好的答案谁可以分享下？？？）

设计抖音评论系统（完整的设计流程，从场景、数据库、api实现、应用的技术栈、高并发读写的解决方案等）

转账操作 如何通过保证操作不出问题，我说事物，然后说了 undo log 和xa事物和binlog保证 读已提交和可重复读
next-key lock保证幻读，但是说到一半面试官好像不满意打断我了，然后问我具体操作怎么操作，我.....不知道咋回答就说开启事物，修改后在提交事物。

微服务是什么有什么好处，相对于单体服务来说有什么优势，为什么要用微服务巴拉巴拉
（一）什么是微服务？
微服务是分布式架构的一种，分布式架构是要把服务做一个拆分，微服务可以降低服务的耦合，有利于服务的维护升级。特征如下：
·每个模块都有自己独立的业务；
·每个模块都是服务的应用，可以独立运行并提供接口服务；
·开发新的业务只需要新增模块，提供自己的接口服务即可；
·原生支持高可用、集群；
（二）什么是单体应用？
单体应用也称为单体系统或者是单体架构，是一种把系统中所有的功能、模块耦合在一个应用中的架构方式。特征如下：
·单体应用就是传统的应用，前端与后端做了分离；
·所有业务都在同一个应用中运行并提供接口服务；
·新开发的业务也放在同一个应用中运行；
·高可用、集群方案需要另外处理；
（三）两者的区别在哪？
微服务架构是将每一个功能模块分别放进到一个独立的服务中，并且通过跨服务器分发这些服务进行扩展，只有需要时才复制。
意即：需要部署N个应用，还需要其它外部应用支撑（注册中心、网关等），部署、运维成本较高。集群、高可用方案无需额外处理。

单体应用是将所有功能模块放在一个单一进程中，并且通过在不同的服务器上面复制这个单体进行扩展。意即：只需要部署一个应用即可，相对于微服务部署、运维成本较低。高可用、集群方案需要另外处理。

#### 秒杀 QPS10W+
问题：
高并发 redis : 3 - 4w QPS
超卖 恶意请求 连接暴露 数据库
思考：
* 单一职责：微服务 分布式部署 单一职责的好处就是就算秒杀没抗住，秒杀库崩了，服务挂了，也不会影响到其他的服务。
* 秒杀链接加盐：通过MD5之类的加密算法加密随机的字符串去做url，然后通过前端代码获取url后台校验才能通过。
* Redis集群：Redis集群，主从同步、读写分离，我们还搞点哨兵，开启持久化
* Nginx：负载均衡 流量机 微服务的网关侧会有各种限流算法
* 资源静态化：前端cdn服务器
* 按钮控制：置灰
* 限流：前端限流一般秒杀不会让你一直点的，一般都是点击一下或者两下然后几秒之后才可以继续点击
后端限流：一旦100个产品卖光了，return了一个false，前端直接秒杀结束
真正的限流还会有限流组件 Hystrix
* 库存预热：
秒杀前你通过定时任务或者运维同学提前把商品的库存加载到Redis中去
让整个流程都在Redis里面去做，然后等秒杀结束了，再异步的去修改库存
Lua脚本是类似Redis事务，有一定的原子性，不会被其他命令插队，可以完成一些Redis事务性的操作
判断库存扣减库存的操作都写在一个脚本丢给Redis去做，那到0了后面的都Return False
一个失败了你修改一个开关，直接挡住所有的请求
* 削峰填谷：MQ多个商品
* 风控：风管分析出来这个用户是真实用户的概率没有其他用户概率大，那就认为他是机器了，丢弃他的请求
这样设计能让真实的用户买到东西，还可以减少自己被薅羊毛的概率。
* 分布式事务：两段式（2PC）和三段式（3PC）


* 接口限流
令牌桶限流算法：大小固定的令牌桶可自行以恒定的速率源源不断地产生令牌。
如果令牌不被消耗，或者被消耗的速度小于产生的速度，令牌就会不断地增多，直到把桶填满。后面再产生的令牌就会从桶中溢出。
最后桶中可以保存的最大令牌数永远不会超过桶的大小。
漏桶算法能够强行限制数据的传输速率，而令牌桶算法在能够限制数据的平均传输速率外，还允许某种程度的突发传输。
在令牌桶算法中，只要令牌桶中存在令牌，那么就允许突发地传输数据直到达到用户配置的门限，因此它适合于具有突发特性的流量。
阻塞式获取令牌：请求进来后，若令牌桶里没有足够的令牌，就在这里阻塞住，等待令牌的发放。
非阻塞式获取令牌：请求进来后，若令牌桶里没有足够的令牌，会尝试等待设置好的时间（这里写了1000ms）
其会自动判断在1000ms后，这个请求能不能拿到令牌，如果不能拿到，直接返回抢购失败。如果timeout设置为0，则等于阻塞时获取令牌。

#### 短连接
平台长度限制
原理：302重定向
分布式ID生成：
uuid:同一时空所有机器唯一 uuid 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作
雪花算法：系统时钟回拨，有可能造成ID冲突重复，或者ID乱序
mysql自增主键，高并发db压力大
redis自增性能高，但要考虑持久性

### 幂等：计算机科学中，幂等表示一次和多次请求某一个资源应该具有同样的副作用，或者说，多次请求所产生的影响与一次请求执行的影响效果相同。
* 场景
我们转账超时的时候，如果下游转账系统做好幂等控制，我们发起重试，那即可以保证转账正常进行，又可以保证不会多转一笔。
MQ（消息中间件）消费者读取消息时，有可能会读取到重复消息。（重复消费）
比如提交form表单时，如果快速点击提交按钮，可能产生了两条一样的数据（前端重复提交）
* 设计幂等
幂等意味着一条请求的唯一性。不管是你哪个方案去设计幂等，都需要一个全局唯一的ID，去标记这个请求是独一无二的。

如果你是利用唯一索引控制幂等，那唯一索引是唯一的
如果你是利用数据库主键控制幂等，那主键是唯一的
如果你是悲观锁的方式，底层标记还是全局唯一的ID

全局唯一ID
UUID，但是UUID的缺点比较明显，它字符串占用的空间比较大，生成的ID过于随机，可读性差，而且没有递增
雪花算法：
第一位符号位，41位时间戳，10位计算机ID，12位机器生成的序列号共64位

流程：过滤已收到的请求，带上全局ID；存储请求，收到时先查询记录，存在就返回，不存在就处理。

### 转账设计

a.明确接口设计的范围和完整的流程
交易系统：生成订单号
风控系统：判断交易是否合理
账户系统：实际的转账操作
日志系统：对整个过程进行记录

RPC框架
数据库：mysql Innodb 可重复读
MQ:rocketMQ
分布式缓存：Redis
语言框架

### 分布式锁
* zk基于节点实现
ZK有四种节点

* 持久节点
默认的节点类型。创建节点的客户端与zookeeper断开连接后，该节点依旧存在。

* 持久节点顺序节点
在创建节点时，zookeeper根据创建的时间顺序给该节点名称进行编号

* 临时节点
和持久节点相反，当创建节点的客户端与zookeeper断开连接后，临时节点会被删除

* 临时顺序节点
在创建节点时，zookeeper根据创建的时间顺序给该节点名称进行编号排序（排序的节点形成一个类似队列）。
* 当创建节点的客户端与zookeeper断开连接后，临时节点会被删除（解锁）
* 每个节点只监听了自己的前一个节点，释放当然也是一个个释放下去，避免出现羊群效应
使用Zookeeper也有可能带来并发问题，只是并不常见而已。
由于网络抖动，客户端可ZK集群的session连接断了，那么zk以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。
就可能产生并发问题了，这个问题不常见是因为zk有重试机制，一旦zk集群检测不到客户端的心跳，就会重试，Curator客户端支持多种重试策略。
多次重试之后还不行的话才会删除临时节

### Mysql分库分表之后，主键如何处理？
* 数据库自增 ID
搞一个数据库，什么也不干，就用于生成主键。
你的系统里每次得到一个 id，都需要往那个专门生成主键的数据库中通过插入获取一个自增的ID，拿到这个 id 之后再往对应的分库分表里去写入。
优点：方便简单。
缺点：单库生成自增 id，要是高并发的话，就会有瓶颈的；如果你硬是要改进一下，那么就专门开一个服务出来，这个服务每次就拿到当前 id 最大值，然后自己递增几个 id，一次性返回一批 id，然后再把当前最大 id 值修改成递增几个 id 之后的一个值；但是无论如何都是基于单个数据库。
适合的场景：系统并发不大，只是因为数据量大的原因而去做的分库分表的话，可以采用这种方式。

* 设置数据库 sequence 或者表自增字段步长
可以通过设置数据库 sequence 或者表的自增字段步长来进行水平伸缩。
比如说，现在有 8 个服务节点，每个服务节点使用一个 sequence 功能来产生 ID，每个 sequence 的起始 ID 不同，并且依次递增，步长都是8
适合的场景：在用户防止产生的 ID 重复时，这种方案实现起来比较简单，也能达到性能目标。
但是服务节点固定，步长也固定，将来如果还要增加服务节点，就不好搞了。

* UUID
优点：本地生成，不需要基于数据库；
缺点：UUID 太长了、占用空间大；作为主键性能太差：UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），
还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，导致频繁的进行页分裂，性能下降明显。

适合的场景：如果你是要随机生成个什么文件名、编号之类的，你可以用 UUID，但是作为InnoDB表的主键是不能用 UUID 的。
UUID.randomUUID().toString().replace(“-”, “”) -> sfsdf23423rr234sfdaf

* 系统当前时间戳+XXX
适合的场景：一般如果用这个方案，是将当前时间戳跟很多其他的业务字段拼接起来，作为一个 id，如果业务上你觉得可以接受，那么也是可以的。
* 你可以将别的业务字段值跟当前时间拼接起来，组成一个全局唯一的编号。

* Snowflake 算法
snowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bit 作为时间戳（毫秒数），用 10 bit 作为工作机器 id，12 bit 作为序列号。
1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。
41 bit：表示的是时间戳，单位是毫秒。41 bit 可以表示的数字多达 2^41 - 1，也就是可以标识 2^41 - 1 个毫秒值，换算成年就是表示69年的时间。
10 bit：记录工作机器 id，代表的是这个服务最多可以部署在 2^10台机器上哪，也就是1024台机器。但是 10 bit 里 5 个 bit 代表机房 id，5 个 bit 代表机器 id。意思就是最多代表 2^5个机房（32个机房），每个机房里可以代表 2^5 个机器（32台机器）。
12 bit：这个是用来记录同一个毫秒内产生的不同 id，12 bit 可以代表的最大正整数是 2^12 - 1 = 4096，也就是说可以用这个 12 bit 代表的数字来区分同一个毫秒内的 4096 个不同的 id。
0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000

