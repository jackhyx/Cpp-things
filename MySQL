## 关系型和非关系型数据库的区别你了解多少？

# 关系型数据库的优点
# 容易理解。因为它采用了关系模型来组织数据。
# 可以保持数据的一致性。
# 数据更新的开销比较小。
# 支持复杂查询（带where子句的查询）

# 非关系型数据库的优点
# 不需要经过SQL层的解析，读写效率高。
# 基于键值对，数据的扩展性很好。
# 可以支持多种类型数据的存储，如图片，文档等等。

## 什么是非关系型数据库？

# 非关系型数据库也叫NOSQL# 采用键值对的形式进行存储 #

# 它的读写性能很高，易于扩展 #可分为内存性数据库以及文档型数据库，比如 Redis，Mongodb，HBase等等。

# 适合使用非关系型数据库的场景：
日志系统
地理位置存储
数据量巨大
高可用


## 为什么使用索引？
通过创建唯一性索引，可以保证# 数据库表中每一行数据的唯一性 #
可以大大# 加快数据的检索速度，这也是创建索引的最主要的原因 #
# 帮助服务器避免排序和临时表 #
# 将随机IO变为顺序IO #
# 可以加速表和表之间的连接 #特别是在实现数据的参考完整性方面特别有意义。


## Innodb为什么要用自增id作为主键？
如果表使用自增主键，那么每次插入新的记录，记录就会# 顺序添加到当前索引节点的后续位置 #当一页写满，就会自动开辟一个新的页
如果使用非自增主键（如果身份证号或学号等），由于# 每次插入主键的值近似于随机 #
因此每次新纪录都要被插到现有索引页得中间某个位置， 频繁的移动、分页操作造成了# 大量的碎片，得到了不够紧凑的索引结构 #
后续# 不得不通过OPTIMIZE TABLE（optimize table）来重建表并优化填充页面 #



## Server层按顺序执行sql的步骤为：

客户端请求->
连接器（验证用户身份，给予权限） ->
查询缓存（存在缓存则直接返回，不存在则执行后续操作）->
分析器（对SQL进行词法分析和语法分析操作） ->
优化器（主要对执行的sql优化选择最优的执行方案方法） ->
执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口）->
去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果）
简单概括：

连接器：管理连接、权限验证；
查询缓存：命中缓存则直接返回结果；
分析器：对SQL进行词法分析、语法分析；（判断查询的SQL字段是否存在也是在这步）
优化器：执行计划生成、选择索引；
执行器：操作引擎、返回结果；
存储引擎：存储数据、提供读写接口。

## 你了解MySQL的内部构造吗？一般可以分为哪两个部分？
可以分为服务层和存储引擎层两部分，其中：

# 服务层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等）
所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

# 存储引擎层负责数据的存储和提取
其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认的存储引擎。


## 说一说Drop、Delete与Truncate的共同点和区别
第一种回答
Drop、Delete、Truncate都表示删除，但是三者有一些差别：
Delete用来删除表的全部或者一部分数据行，执行delete之后，用户需要提交(commmit)或者回滚(rollback)来执行删除或者撤销删除，会触发这个表上所有的delete触发器
Truncate删除表中的所有数据，这个操作不能回滚，也不会触发这个表上的触发器，TRUNCATE比delete更快，占用的空间更小
Drop命令从数据库中删除表，所有的数据行，索引和权限也会被删除，所有的DML触发器也不会被触发，这个命令也不能回滚。

因此，在不再需要一张表的时候，用Drop；在想删除部分数据行时候，用Delete；在保留表而删除所有数据的时候用Truncate。

第二种回答

Drop直接删掉表;
Truncate删除表中数据，再插入时自增长id又从1开始 ;
Delete删除表中数据，可以加where字句。
具体解析
DELETE语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行进行回滚操作
TRUNCATE TABLE 则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的
并且在删除的过程中不会激活与表有关的删除触发器。执行速度快。
表和索引所占空间。当表被TRUNCATE 后，这个表和索引所占用的空间会恢复到初始大小，而DELETE操作不会减少表或索引所占用的空间。drop语句将表所占用的空间全释放掉。

一般而言，drop > truncate > delete
应用范围。TRUNCATE 只能对TABLE；DELETE可以是table和view
TRUNCATE 和DELETE只删除数据，而DROP则删除整个表（结构和数据）。
truncate与不带where的delete ：只删除数据，而不删除表的结构（定义）drop语句将删除表的结构被依赖的约束（constrain),触发器（trigger)索引（index)
依赖于该表的存储过程/函数将被保留，但其状态会变为：invalid。
delete语句为DML（Data Manipulation Language),这个操作会被放到 rollback segment中,事务提交后才生效
如果有相应的 tigger,执行的时候将被触发。
truncate、drop是DDL（Data Define Language),操作立即生效，原数据不放到 rollback segment中，不能回滚
在没有备份情况下，谨慎使用 drop 与 truncate。要删除部分数据行采用delete且注意结合where来约束影响范围
回滚段要足够大。要删除表用drop;若想保留表而将表中数据删除，如果与事务无关，用truncate即可实现
如果和事务有关，或老是想触发trigger,还是用delete。
Truncate table 表名 速度快,而且效率高,因为: truncate table 在功能上与不带 WHERE 子句的 DELETE 语句相同
二者均删除表中的全部行。但 TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少
DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项。TRUNCATE TABLE 通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放。
TRUNCATE TABLE 删除表中的所有行，但表结构及其列、约束、索引等保持不变。新行标识所用的计数值重置为该列的种子
如果想保留标识计数值，请改用 DELETE。如果要删除表定义及其数据，请使用 DROP TABLE 语句。
对于由 FOREIGN KEY 约束引用的表，不能使用 TRUNCATE TABLE，而应使用不带 WHERE 子句的 DELETE 语句。由于 TRUNCATE TABLE 不记录在日志中，所以它不能激活触发器。

## MySQL中有四种索引类型，可以简单说说吗？

FULLTEXT ：即为全文索引，目前只有MyISAM引擎支持。
其可以在CREATE TABLE ，ALTER TABLE ，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。



HASH ：由于HASH的唯一（几乎100%的唯一）及类似键值对的形式，很适合作为索引。
HASH索引可以一次定位，不需要像树形索引那样逐层查找,因此具有极高的效率。但是，这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。

BTREE ：BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。
这是MySQL里默认和最常用的索引类型。

RTREE ：RTREE在MySQL很少使用，仅支持geometry数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种。 相对于BTREE，RTREE的优势在于范围查找。

## MySQL索引主要使用的两种数据结构是什么？

哈希索引，对于哈希索引来说，底层的数据结构肯定是哈希表# 因此在绝大多数需求为# 单条记录查询 #的时候，可以选择哈希索引，查询性能最快 #其余大部分场景，建议选择BTree索引

BTree索引，Mysql的BTree索引使用的是B树中的B+Tree，BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。

但对于主要的两种存储引擎（MyISAM和InnoDB）的实现方式是不同的。

## 数据库并发事务会带来哪些问题？
数据库并发会带来脏读、幻读、丢弃更改、不可重复读这四个常见问题，其中：

脏读：在第一个修改事务和读取事务进行的时候，读取事务读到的数据为100，这是修改之后的数据，但是之后该事务满足一致性等特性而做了回滚操作，那么读取事务得到的结果就是脏数据了。

幻读：一般是T1在某个范围内进行修改操作（增加或者删除），而T2读取该范围导致读到的数据是修改之间的了，强调范围。

丢弃修改：两个写事务T1 T2同时对A=0进行递增操作，结果T2覆盖T1，导致最终结果是1 而不是2，事务被覆盖

不可重复读：T2 读取一个数据，然后T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。

## 数据库隔离级别
# 未提交读，事务中发生了修改，即使没有提交，其他事务也是可见的，比如对于一个数A原来50修改为100，但是我还没有提交修改，另一个事务看到这个修改，而这个时候原事务发生了回滚，这时候A还是50，但是另一个事务看到的A是100.可能会导致脏读、幻读或不可重复读
# 提交读，对于一个事务从开始直到提交之前，所做的任何修改是其他事务不可见的，举例就是对于一个数A原来是50，然后提交修改成100，这个时候另一个事务在A提交修改之前，读取的A是50，刚读取完，A就被修改成100，这个时候另一个事务再进行读取发现A就突然变成100了；可以阻止脏读，但是幻读或不可重复读仍有可能发生
# 重复读，就是对一个记录读取多次的记录是相同的，比如对于一个数A读取的话一直是A，前后两次读取的A是一致的；可以阻止脏读和不可重复读，但幻读仍有可能发生
# 可串行化读，在并发情况下，和串行化的读取的结果是一致的，没有什么不同，比如不会发生脏读和幻读；该级别可以防止脏读、不可重复读以及幻读

隔离级别	脏读	不可重复读	幻影读
READ-UNCOMMITTED 未提交读	√	√	√
READ-COMMITTED 提交读	×	√	√
REPEATABLE-READ 重复读	×	×	√
SERIALIZABLE 可串行化读	×	×	×
MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）

这里需要注意的是：与 SQL 标准不同的地方在于InnoDB 存储引擎在 REPEATABLE-READ（可重读）事务隔离级别下使用的是Next-Key Lock 锁算法
因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server)是不同的
所以说InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）已经可以完全保证事务的隔离性要求，即达到了SQL标准的SERIALIZABLE(可串行化)隔离级别。

因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是READ-COMMITTED(读取提交内容):
但是你要知道的是InnoDB 存储引擎默认使用 REPEATABLE-READ（可重读）并不会有任何性能损失。

InnoDB 存储引擎在分布式事务的情况下一般会用到SERIALIZABLE(可串行化)隔离级别。

## 不可重复读和幻读区别是什么？可以举个例子吗？
不可重复读的重点是修改，幻读的重点在于新增或者删除。
例1（同样的条件, 你读取过的数据, 再次读取出来发现值不一样了）：
事务1中的A先生读取自己的工资为 1000的操作还没完成，事务2中的B先生就修改了A的工资为2000，导致A再读自己的工资时工资变为 2000；这就是不可重复读。
例2（同样的条件, 第1次和第2次读出来的记录数不一样 ）
假某工资单表中工资大于3000的有4人，事务1读取了所有工资大于3000的人，共查到4条记录
这时事务2 又插入了一条工资大于3000的记录，事务1再次读取时查到的记录就变为了5条，这样就导致了幻读。


## 数据库三大范式精讲
# 第一范式
在任何一个关系数据库中，第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF）的数据库就不是关系数据库
所谓第一范式（1NF）是指数据库表的每一列都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。
如果出现重复的属性，就可能需要定义一个新的实体，新的实体由重复的属性构成，新实体与原实体之间为一对多关系。在第一范式（1NF）中表的每一行只包含一个实例的信息。
简而言之，第一范式就是无重复的列。

# 第二范式
第二范式（2NF）是在第一范式（1NF）的基础上建立起来的，即满足第二范式（2NF）必须先满足第一范式（1NF）。第二范式（2NF）要求数据库表中的每个实例或行必须可以被惟一地区分。
为实现区分通常需要为表加上一个列，以存储各个实例的惟一标识。这个惟一属性列被称为主关键字或主键、主码。 第二范式（2NF）要求实体的属性完全依赖于主关键字。
所谓完全依赖是指不能存在仅依赖主关键字一部分的属性，如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列，以存储各个实例的惟一标识。
简而言之，第二范式就是非主属性非部分依赖于主关键字。

# 第三范式
满足第三范式（3NF）必须先满足第二范式（2NF）。简而言之，第三范式（3NF）要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。
例如，存在一个部门信息表，其中每个部门有部门编号（dept_id）、部门名称、部门简介等信息。那么在员工信息表中列出部门编号后就不能再将部门名称、部门简介等与部门有关的信息再加入员工信息表中。如果不存在部门信息表，则根据第三范式（3NF）也应该构建它，否则就会有大量的数据冗余。
简而言之，第三范式就是属性不依赖于其它非主属性。

## 数据库三大范式精要总结
简单归纳：
第一范式（1NF）：字段不可分
第二范式（2NF）：有主键，非主键字段依赖主键
第三范式（3NF）：非主键字段不能相互依赖。

##解释：
1NF：原子性。 字段不可再分,否则就不是关系数据库;
2NF：唯一性 。一个表只说明一个事物
3NF：每列都与主键有直接关系，不存在传递依赖。

## 事务四大特性（ACID）原子性、一致性、隔离性、持久性？
第一种回答

# 原子性：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。
事务在执行过程中发生错误，会被恢复（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 
# 一致性：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 
# 隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致
事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）
# 持久性：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

第二种回答
# 原子性（Atomicity）
原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。

# 一致性（Consistency）
事务开始前和结束后，数据库的完整性约束没有被破坏。比如A向B转账，不可能A扣了钱，B却没收到。

# 隔离性（Isolation）
隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。
同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。
比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。

# 持久性（Durability）
持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。


## 数据库如何保证一致性:事务开始前和结束后，数据库的完整性约束没有被破坏。
分为两个层面来说。
从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。
也就是说ACID四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。
数据库必须要实现AID三大特性，才有可能实现一致性。例如，原子性无法保证，显然一致性也无法保证。
从应用层面，通过代码判断数据库数据是否有效，然后决定回滚还是提交数据！

## 数据库如何保证原子性:一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。
主要是利用 Innodb 的undo log。
undo log名为回滚日志，是实现原子性的关键，当事务回滚时能够撤销所有已经成功执行的SQL语句，他需要记录你要回滚的相应日志信息。
例如
当你delete一条数据的时候，就需要记录这条数据的信息，回滚的时候，insert这条旧数据
当你update一条数据的时候，就需要记录之前的旧值，回滚的时候，根据旧值执行update操作
当年insert一条数据的时候，就需要这条记录的主键，回滚的时候，根据主键执行delete操作
undo log记录了这些回滚需要的信息，当事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。

## 数据库如何保证持久性？

##主要是利用Innodb的redo log。重写日志 正如之前说的，MySQL是先把磁盘上的数据加载到内存中，在内存中对数据进行修改，再写回到磁盘上。
如果此时突然宕机，内存中的数据就会丢失。 怎么解决这个问题？ 简单啊，事务提交前直接把数据写入磁盘就行啊。 
这么做有什么问题？
只修改一个页面里的一个字节，就要将整个页面刷入磁盘，太浪费资源了。毕竟一个页面16kb大小，你只改其中一点点东西，就要将16kb的内容刷入磁盘，听着也不合理。
毕竟一个事务里的SQL可能牵涉到多个数据页的修改，而这些数据页可能不是相邻的，也就是属于随机IO。显然操作随机IO，速度会比较慢。
于是，决定采用redo log解决上面的问题
## 当做数据修改的时候，不仅在内存中操作，还会在redo log中记录这次操作 ##
当事务提交的时候，会将redo log日志进行刷盘(redo log一部分在内存中，一部分在磁盘上)。
当数据库宕机重启的时候，会将redo log中的内容恢复到数据库中，再根据undo log和bin log内容决定回滚数据还是提交数据。

##采用redo log的好处？
其实好处就是将redo log进行刷盘 比 对数据页刷盘效率高，具体表现如下：
redo log体积小，毕竟只记录了哪一页修改了啥# 因此体积小，刷盘快# 
redo log是一直往末尾进行追加，# 属于顺序I O#效率显然比随机IO来的快。

## 聚集索引与非聚集索引的区别是什么?
# 非聚集索引和聚集索引的区别在于
通过聚集索引可以查到需要查找的数据
而通过非聚集索引可以查到记录对应的主键值
再使用主键的值通过聚集索引查找到需要的数据

聚集索引和非聚集索引的根本区别是表记录的排列顺序和与索引的排列顺序是否一致。

## 聚集索引（Innodb）的叶节点就是数据节点，而非聚集索引(MyisAM)的叶节点仍然是索引节点，只不过其包含一个指向对应数据块的指针。

48、为什么MySQL索引要使用B+树，而不是B树或者红黑树？
我们在MySQL中的数据一般是放在磁盘中的，读取数据的时候肯定会有访问磁盘的操作，磁盘中有两个机械运动的部分，分别是盘片旋转和磁臂移动。盘片旋转就是我们市面上所提到的多少转每分钟，而磁盘移动则是在盘片旋转到指定位置以后，移动磁臂后开始进行数据的读写。那么这就存在一个定位到磁盘中的块的过程，而定位是磁盘的存取中花费时间比较大的一块，毕竟机械运动花费的时候要远远大于电子运动的时间。当大规模数据存储到磁盘中的时候，显然定位是一个非常花费时间的过程，但是我们可以通过B树进行优化，提高磁盘读取时定位的效率。

为什么B类树可以进行优化呢？我们可以根据B类树的特点，构造一个多阶的B类树，然后在尽量多的在结点上存储相关的信息，保证层数（树的高度）尽量的少，以便后面我们可以更快的找到信息，磁盘的I/O操作也少一些，而且B类树是平衡树，每个结点到叶子结点的高度都是相同，这也保证了每个查询是稳定的。

特别地：只有B-树和B+树，这里的B-树是叫B树，不是B减树，没有B减树的说法。

## 为什么MySQL索引适用用B+树而不用hash表和B树？

# 利用Hash需要把数据全部加载到内存中，如果数据量大，是一件很消耗内存的事
而采用B+树，是基于# 按照节点分段加载，由此减少内存消耗 #

# 和业务场景有关，对于唯一查找（查找一个值），Hash确实更快
但数据库中经常查询多条数据，这时候由于B+数据的有序性，与叶子节点又有链表相连，他的查询效率会比Hash快的多。

b+树的非叶子节点不保存数据，只保存子树的临界值（最大或者最小）
# 所以同样大小的节点，b+树相对于b树能够有更多的分支，使得这棵树更加矮胖，查询时做的IO操作次数也更少。

## 既然Hash比B+树更快，为什么MySQL用B+树来存储索引呢？

MySQL中存储索引用到的数据结构是B+树，B+树的查询时间跟树的高度有关，是log(n)，如果用hash存储，那么查询时间是O(1)。
采用Hash来存储确实要更快，但是采用B+树来存储索引的原因主要有以下两点：
# 从内存角度上说，数据库中的索引一般是在磁盘上，数据量大的情况可能无法一次性装入内存，B+树的设计可以允许数据分批加载。
# 从业务场景上说，如果只选择一个数据那确实是hash更快，但是数据库中经常会选中多条，这时候由于B+树索引有序，并且又有链表相连，它的查询效率比hash就快很多了。

## 增加B+树的路数可以降低树的高度，那么无限增加树的路数是不是可以有最优的查找效率？
不可以。因为这样会形成一个有序数组，文件系统和数据库的索引都是存在硬盘上的，并且如果数据量大的话，不一定能一次性加载到内存中。
有序数组没法一次性加载进内存，这时候B+树的多路存储威力就出来了，可以每次加载B+树的一个结点，然后一步步往下找，

## 说一下数据库表锁和行锁吧
# 表锁
不会出现死锁，发生锁冲突几率高，并发低。
MyISAM在执行查询语句（select）前，会自动给涉及的所有表加读锁，在执行增删改操作前，会自动给涉及的表加写锁。
MySQL的表级锁有两种模式：表共享读锁和表独占写锁。
读锁会阻塞写，写锁会阻塞读和写
对MyISAM表的读操作，不会阻塞其它进程对同一表的读请求，但会阻塞对同一表的写请求。只有当读锁释放后，才会执行其它进程的写操作。
对MyISAM表的写操作，会阻塞其它进程对同一表的读和写操作，只有当写锁释放后，才会执行其它进程的读写操作。
MyISAM不适合做写为主表的引擎，因为写锁后，其它线程不能做任何操作，大量的更新会使查询很难得到锁，从而造成永远阻塞。

# 行锁
会出现死锁，发生锁冲突几率低，并发高。
在MySQL的InnoDB引擎支持行锁，与Oracle不同，MySQL的行锁是通过索引加载的，也就是说，行锁是加在索引响应的行上的
要是对应的SQL语句没有走索引，则会全表扫描，行锁则无法实现，取而代之的是表锁，此时其它事务无法对当前表进行更新或插入操作。

## 行锁的实现需要注意：
行锁必须有索引才能实现，否则会自动锁全表，那么就不是行锁了。
两个事务不能锁同一个索引。
insert，delete，update在事务中都会自动默认加上排它锁。
行锁的适用场景：
A用户消费，service层先查询该用户的账户余额，若余额足够，则进行后续的扣款操作；这种情况查询的时候应该对该记录进行加锁。
否则，B用户在A用户查询后消费前先一步将A用户账号上的钱转走，而此时A用户已经进行了用户余额是否足够的判断，则可能会出现余额已经不足但却扣款成功的情况。
为了避免此情况，需要在A用户操作该记录的时候进行for update加锁

## 你知道哪些数据库结构优化的手段？
# 范式优化： 比如消除冗余（节省空间。。）
# 反范式优化：比如适当加冗余等（减少join）
# 限定数据的范围： 务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内。
# 读/写分离： 经典的数据库拆分方案，主库负责写，从库负责读；
# 拆分表：分区将数据在物理上分隔开，不同分区的数据可以制定保存在处于不同磁盘上的数据文件里。
这样，当对这个表进行查询时，只需要在表分区中进行扫描，而不必进行全表扫描，明显缩短了查询时间，另外处于不同磁盘的分区也将对这个表的数据传输分散在不同的磁盘I/O
一个精心设置的分区可以将数据传输对磁盘I/O竞争均匀地分散开。对数据量大的时时表可采取此方法。可按月自动建表分区。


## 一道场景题：假如你所在的公司选择MySQL数据库作数据存储，一天五万条以上的增量，预计运维三年，你有哪些优化手段？
设计良好的数据库结构，允许部分数据冗余，尽量避免join查询，提高效率。
选择合适的表字段数据类型和存储引擎，适当的添加索引。
MySQL库主从读写分离。
找规律分表，减少单表中的数据量提高查询速度。
添加缓存机制，比如Memcached，Apc等。
不经常改动的页面，生成静态页面。
书写高效率的SQL。比如 SELECT * FROM TABEL 改为 SELECT field_1, field_2, field_3 FROM TABLE。


## MySQL优化了解吗？说一下从哪些方面可以做到性能优化？
为搜索字段创建索引
避免使用 Select *，列出需要查询的字段
垂直分割分表
选择正确的存储引擎

## 数据库高并发是我们经常会遇到的，你有什么好的解决方案吗？
# 在web服务框架中加入缓存。在服务器与数据库层之间加入缓存层，将高频访问的数据存入缓存中，减少数据库的读取负担。
# 增加数据库索引，进而提高查询速度。（不过索引太多会导致速度变慢，并且数据库的写入会导致索引的更新，也会导致速度变慢）
# 主从读写分离，让主服务器负责写，从服务器负责读。
# 将数据库进行拆分，使得数据库的表尽可能小，提高查询的速度。
# 使用分布式架构，分散计算压力。


## 使用索引的注意事项
#在经常需要搜索的列上，可以加快搜索的速度；

# 在经常使用在where子句中的列上面创建索引，加快条件的判断速度。

# 将打算加索引的列设置为NOT NULL，否则将导致引擎放弃使用索引而进行全表扫描

# 在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间

# 避免where子句中对字段施加函数，这会造成无法命中索引

# 在中到大型表索引都是非常有效的，但是特大型表的维护开销会很大，不适合建索引，建立用逻辑索引

# 在经常用到连续的列上，这些列主要是由一些外键，可以加快连接的速度

# 与业务无关时多使用逻辑主键，也就是自增主键在使用InnoDB时使用与业务无关的自增主键作为主键，即使用逻辑主键，而不要使用业务主键。

# 删除长期未使用的索引，不用的索引的存在会造成不必要的性能损耗

# 在使用limit offset查询缓存时，可以借助索引来提高性能。

## 创建索引时需要注意什么？

# 非空字段：应该指定列为NOT NULL，除非你想存储NULL。
在 MySQL 中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；

# 取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；

# 索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。

## 唯一、不为空、经常被查询的字段 的字段适合建索引 ## 

## MySQL 索引使用的注意事项
MySQL 索引通常是被用于提高 WHERE 条件的数据行匹配时的搜索速度，在索引的使用过程中，存在一些使用细节和注意事项。

## 函数，运算，否定操作符，连接条件，多个单列索引，最左前缀原则，范围查询，不会包含有NULL值的列，like语句不要在列上使用函数和进行运算
# 不要在列上使用函数，这将导致索引失效而进行全表扫描。
select * from news where year(publish_time) < 2017
为了使用索引，防止执行全表扫描，可以进行改造。
select * from news where publish_time < '2017-01-01'

# 不要在列上进行运算，这也将导致索引失效而进行全表扫描。
select * from news where id / 100 = 1
为了使用索引，防止执行全表扫描，可以进行改造。
select * from news where id = 1 * 100

# 尽量避免使用 != 或 not in或 <> 等否定操作符 应该尽量避免在 where 子句中使用 != 或 not in 或 <> 操作符，因为这几个操作符都会导致索引失效而进行全表扫描
# 尽量避免使用 or 来连接条件 应该尽量避免在 where 子句中使用 or 来连接条件，因为这会导致索引失效而进行全表扫描。
select * from news where id = 1 or id = 2

# 多个单列索引并不是最佳选择 
MySQL 只能使用一个索引，会从多个索引中选择一个限制最为严格的索引
因此，为多个列创建单列索引，并不能提高 MySQL 的查询性能。 
假设，有两个单列索引，分别为 news_year_idx(news_year) 和 news_month_idx(news_month)
现在，有一个场景需要针对资讯的年份和月份进行查询，那么，SQL 语句可以写成：
select * from news where news_year = 2017 and news_month = 1
事实上，MySQL 只能使用一个单列索引。为了提高性能，可以使用复合索引 news_year_month_idx(news_year, news_month) 保证 news_year 和 news_month 两个列都被索引覆盖。

# 复合索引的最左前缀原则 复合索引遵守“最左前缀”原则，即在查询条件中使用了复合索引的第一个字段，索引才会被使用。
因此，在复合索引中索引列的顺序至关重要。如果不是按照索引的最左列开始查找，则无法使用索引。
假设，有一个场景只需要针对资讯的月份进行查询，那么，SQL 语句可以写成：

select * from news where news_month = 1
此时，无法使用 news_year_month_idx(news_year, news_month) 索引，因为遵守“最左前缀”原则，在查询条件中没有使用复合索引的第一个字段，索引是不会被使用的。

# 覆盖索引的好处 如果一个索引包含所有需要的查询的字段的值，直接根据索引的查询结果返回数据，而无需读表，能够极大的提高性能。
因此，可以定义一个让索引包含的额外的列，即使这个列对于索引而言是无用的。

# 范围查询对多列查询的影响 查询中的某个列有范围查询，则其右边所有列都无法使用索引优化查找。
举个例子，假设有一个场景需要查询本周发布的资讯文章，其中的条件是必须是启用状态，且发布时间在这周内。那么，SQL 语句可以写成：
select * from news where publish_time >= '2017-01-02' and publish_time <= '2017-01-08' and enable = 1
这种情况下，因为范围查询对多列查询的影响，将导致 news_publish_idx(publish_time, enable) 索引中 publish_time 右边所有列都无法使用索引优化查找
换句话说，news_publish_idx(publish_time, enable) 索引等价于 news_publish_idx(publish_time) 
对于这种情况，我的建议：对于范围查询，务必要注意它带来的副作用，并且尽量少用范围查询，可以通过曲线救国的方式满足业务场景
例如，上面案例的需求是查询本周发布的资讯文章，因此可以创建一个news_weekth 字段用来存储资讯文章的周信息，使得范围查询变成普通的查询，SQL 可以改写成：
select * from news where news_weekth = 1 and enable = 1
然而，并不是所有的范围查询都可以进行改造，对于必须使用范围查询但无法改造的情况
我的建议：不必试图用 SQL 来解决所有问题，可以使用其他数据存储技术控制时间轴，例如 Redis 的 SortedSet 有序集合保存时间，或者通过缓存方式缓存查询结果从而提高性能。

# 索引不会包含有NULL值的列 只要列中包含有 NULL 值都将不会被包含在索引中，复合索引中只要有一列含有 NULL值，那么这一列对于此复合索引就是无效的
因此，在数据库设计时，除非有一个很特别的原因使用 NULL 值，不然尽量不要让字段的默认值为 NULL。

# 隐式转换的影响 当查询条件左右两侧类型不匹配的时候会发生隐式转换，隐式转换带来的影响就是可能导致索引失效而进行全表扫描
下面的案例中，date_str 是字符串，然而匹配的是整数类型，从而发生隐式转换。
select * from news where date_str = 201701
因此，要谨记隐式转换的危害，时刻注意通过同类型进行比较

# like 语句的索引失效问题 like 的方式进行查询，在 like “value%” 可以使用索引，但是对于 like “%value%” 这样的方式，执行全表查询，这在数据量小的表，不存在性能问题，
但是对于海量数据，全表扫描是非常可怕的事情。
所以，根据业务需求，考虑使用 ElasticSearch 或 Solr 是个不错的方案。
