
#### #ECDHE 握手过程
* 使用了 ECDHE，在 TLS 第四次握手前，客户端就已经发送了加密的 HTTP 数据，而对于 RSA 握手过程，必须要完成 TLS 四次握手，才能传输应用数据。

所以，ECDHE 相比 RSA 握手过程省去了一个消息往返的时间，
这个有点「抢跑」的意思，它被称为是「TLS False Start」，跟「TCP Fast Open」有点像
都是在还没连接完全建立前，就发送了应用数据，这样便提高了传输的效率。

* TLS 第一次握手
客户端首先会发一个「Client Hello」消息，消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的随机数（Client Random）。

* TLS 第二次握手
服务端收到客户端的「打招呼」，同样也要回礼，会返回「Server Hello」消息，
* 消息面有服务器确认的 TLS 版本号，也给出了一个随机数（Server Random），然后从客户端的密码套件列表选择了一个合适的密码套件。
不过，这次选择的密码套件就和 RSA 不一样了，我们来分析一下这次的密码套件的意思。
「 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384」

**密钥协商算法使用 ECDHE；**
签名算法使用 RSA；
握手后的通信使用 AES 对称算法，密钥长度 256 位，分组模式是 GCM；
摘要算法使用 SHA384；
接着，服务端为了证明自己的身份，发送「Certificate」消息，会把证书也发给客户端。

这一步就和 RSA 握手过程有很大到区别了，因为服务端选择了 ECDHE 密钥协商算法，所以会在发送完证书后，发送「Server Key Exchange」消息。

这个过程服务器做了三件事：

* 选择了名为 x25519 的椭圆曲线，选好了椭圆曲线相当于椭圆曲线基点 G 也定好了，这些都会公开给客户端；
* 生成随机数作为服务端椭圆曲线的私钥，保留到本地；
* 根据基点 G 和私钥计算出服务端的椭圆曲线公钥，这个会公开给客户端。
* 为了保证这个椭圆曲线的公钥不被第三方篡改，服务端会用 RSA 签名算法给服务端的椭圆曲线公钥做个签名。

随后，就是「Server Hello Done」消息，服务端跟客户端表明：“这些就是我提供的信息，打招呼完毕”。

至此，TLS 两次握手就已经完成了，目前客户端和服务端通过明文共享了这几个信息
Client Random、Server Random 、使用的椭圆曲线、椭圆曲线基点 G、服务端椭圆曲线的公钥，这几个信息很重要，是后续生成会话密钥的材料。

* TLS 第三次握手
客户端收到了服务端的证书后，自然要校验证书是否合法，如果证书合法，那么服务端到身份就是没问题的。
* 校验证书的过程会走证书链逐级验证，确认证书的真实性，再用证书的公钥验证签名，这样就能确认服务端的身份了，确认无误后，就可以继续往下走。

客户端会生成一个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前面给的信息，
生成客户端的椭圆曲线公钥，然后用「Client Key Exchange」消息发给服务端。

至此，双方都有对方的椭圆曲线公钥、自己的椭圆曲线私钥、椭圆曲线基点 G。于是，双方都就计算出点（x，y），
其中 x 坐标值双方都是一样的，前面说 ECDHE 算法时候，说 x 是会话密钥，但实际应用中，x 还不是最终的会话密钥。

还记得 TLS 握手阶段，客户端和服务端都会生成了一个随机数传递给对方吗？

最终的会话密钥，就是用「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料生成的。
之所以这么麻烦，是因为 TLS 设计者不信任客户端或服务器「伪随机数」的可靠性，为了保证真正的完全随机，
把三个不可靠的随机数混合起来，那么「随机」的程度就非常高了，足够让黑客计算不出最终的会话密钥，安全性更高。
算好会话密钥后，客户端会发一个「Change Cipher Spec」消息，告诉服务端后续改用对称算法加密通信。

接着，客户端会发「Encrypted Handshake Message」消息，
把之前发送的数据做一个摘要，再用对称密钥加密一下，让服务端做个验证，验证下本次生成的对称密钥是否可以正常使用。

* TLS 第四次握手
最后，服务端也会有一个同样的操作，发「Change Cipher Spec」和「Encrypted Handshake Message」消息，
* 如果双方都验证加密和解密没问题，那么握手正式完成。于是，就可以正常收发加密的 HTTP 请求和响应了。

#### RSA算法原理？

#### HTTPS密钥细节

#### http的报文格式 ，说几个头部
HTTP的请求报文由四部分组成：请求行(request line)、请求头部(header)、空行和请求数据(request data)

#### http和https的区别? https加密实现?

#### 数字证书有哪些？

#### 对称加密、非对称加密常用的算法

#### 浏览器访问服务器的流程

#### 三次握手、四次挥手、为什么四次



#### 在命令行ping网址的时候TTL是什么东西？ ping原理
#### 计算机网络

#### TCP拥塞控制

#### TCP连接建立后把网线拔了会怎么样，客户端会发生什么

### 在山区里信号很差用手机上网，没有彻底断开会发生什么，什么时候会发生重传

* HTTP各个版本 (1.0，1.1，2.0，3.0)
  --1.1 长连接、管道网络运输
  --2.0头部压缩HPACK算法、二进制格式、并发传输、服务器主动推送资源
  --3.0无队头阻塞、更快的链接建立、连接迁移

* HTTP2.0之前怎么实现服务器推送机制
* 是否了解过Websocket
* 保证TCP传输的可靠性的实现
  -序列号、确认应答、超时重传、拥塞控制、浏览控制
* 计算机网络五层模型
* http请求报文和响应报文包含了哪些

* https和http区别是什么
  --HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
  --HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
  --HTTP 的端口号是 80，HTTPS 的端口号是 443。
  --HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

* post请求了解吗其和get请求的区别是什么
  --GET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。
  --POST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。

#### 如何使得UDP可靠传输


* 问看没看过 tcp 源码，答：只看过协议首部

* tcp udp 区别
  -连接、服务对象、可靠性、拥塞控制和流量控制、首部开销、传输方式、分片不同

#### tcp timewait 作用
  --防止历史连接中的数据被后面相同的四元组接受
  --保证被动关闭连接能被正确关闭

#### 服务端上的timewait过多会产生什么问题？
* 占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等；
* 占用端口资源，端口资源也是有限的，一般可以开启的端口为 32768～61000，也可以通过 net.ipv4.ip_local_port_range参数指定范围。
客户端和服务端 TIME_WAIT 过多，造成的影响是不同的。
如果客户端（主动发起关闭连接方）的 TIME_WAIT 状态过多，占满了所有端口资源，
* 那么就无法对「目的 IP+ 目的 PORT」都一样的服务器发起连接了，
* 但是被使用的端口，还是可以继续对另外一个服务器发起连接的。
因此，客户端（发起连接方）都是和「目的 IP+ 目的 PORT 」都一样的服务器建立连接的话，
* 当客户端的 TIME_WAIT 状态连接过多的话，就会受端口资源限制，如果占满了所有端口资源，那么就无法再跟「目的 IP+ 目的 PORT」都一样的服务器建立连接了。
不过，即使是在这种场景下，只要连接的是不同的服务器，端口是可以重复使用的，所以客户端还是可以向其他服务器发起连接的，
* 这是因为内核在定位一个连接的时候，是通过四元组（源IP、源端口、目的IP、目的端口）信息来定位的，并不会因为客户端的端口一样，而导致连接冲突。

如果服务端（主动发起关闭连接方）的 TIME_WAIT 状态过多，并不会导致端口资源受限，
因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等


#### 有什么办法避免timewait过多？如何优化 TIME_WAIT？
* 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；
* net.ipv4.tcp_max_tw_buckets
* 程序中使用 SO_LINGER ，应用强制使用 RST 关闭。
* net.ipv4.tcp_tw_reuse 和 tcp_timestamps

如下的 Linux 内核参数开启后，则可以复用处于 TIME_WAIT 的 socket 为新的连接所用。

有一点需要注意的是，tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，
在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用。
net.ipv4.tcp_tw_reuse = 1
使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持，即

net.ipv4.tcp_timestamps=1（默认即为 1）
这个时间戳的字段是在 TCP 头部的「选项」里，它由一共 8 个字节表示时间戳，其中第一个 4 字节字段用来保存发送该数据包的时间，
第二个 4 字节字段用来保存最近一次接收对方发送到达数据的时间。

由于引入了时间戳，我们在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。

* net.ipv4.tcp_max_tw_buckets

这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置，这个方法比较暴力。

* ：程序中使用 SO_LINGER

我们可以通过设置 socket 选项，来设置调用 close 关闭连接行为。

struct linger so_linger;
so_linger.l_onoff = 1;
so_linger.l_linger = 0;
setsockopt(s, SOL_SOCKET, SO_LINGER, &so_linger,sizeof(so_linger));
* 如果l_onoff为非 0， 且l_linger值为 0，那么调用close后，会立该发送一个RST标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了TIME_WAIT状态，直接关闭。
但这为跨越TIME_WAIT状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。
#### 为什么 TIME_WAIT 等待的时间是 2MSL？
MSL 是 Maximum Segment Lifetime，**报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃**。
因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，
当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。
MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。
**所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。**
TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，
如果超过了，就认为报文已经消失在网络中了。

TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 
网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。
比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 FIN 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方，
一来一去正好 2 个 MSL。
**可以看到 2MSL时长 这其实是相当于至少允许报文丢失一次。**
比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。
为什么不是 4 或者 8 MSL 的时长呢？
你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。
2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。
如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。

在 Linux 系统里 2MSL 默认是 60 秒，那么一个 MSL 也就是 30 秒。Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒。
#### tcp 粘包拆包和解决思路

* https可以防止DNS劫持吗？

#### HTTP中POST和GET的区别
get是获取数据，post是修改数据
get把请求的数据放在url上， 以?分割URL和传输数据，参数之间以&相连，所以get不太安全。而post把数据放在HTTP的包体内（requrest body）

get提交的数据最大是2k（ 限制实际上取决于浏览器）， post理论上没有限制。

GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200(返回数据);
POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)。

GET请求会被浏览器主动缓存，而POST不会，除非手动设置。

本质区别：GET是幂等的，而POST不是幂等的

这里的幂等性：幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。
，所以不应该且不能用get请求做数据的增删改这些有副作用的操作。
因为get请求是幂等的，在网络不好的隧道中会尝试重试。
如果用get请求增数据，会有重复操作的风险，而这种重复操作可能会导致副作用（浏览器和操作系统并不知道你会用get请求去做增操作）。

#### GET 方法的长度限制是怎么回事？
网络上都会提到浏览器地址栏输入的参数是有限的。
首先说明一点，HTTP 协议没有 Body 和 URL 的长度限制，对 URL 限制的大多是浏览器和服务器的原因。
浏览器原因就不说了，服务器是因为处理长 URL 要消耗比较多的资源，为了性能和安全（防止恶意构造长 URL 来攻击）考虑，会给 URL 长度加限制。

#### POST 方法比 GET 方法安全？
有人说POST 比 GET 安全，因为数据在地址栏上不可见。
然而，从传输的角度来说，他们都是不安全的，因为 HTTP 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文。
要想安全传输，就只有加密，也就是 HTTPS。

#### POST 方法会产生两个 TCP 数据包？你了解吗？
有些文章中提到，POST 会将 header 和 body 分开发送，先发送 header，服务端返回 100 状态码再发送 body。
HTTP 协议中没有明确说明 POST 会产生两个 TCP 数据包，而且实际测试(Chrome)发现，header 和 body 不会分开发送。
所以，header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为

#### 输入一个 url 回车到获得响应，经过哪些层，分别涉及什么协议？
* Https流程

#### Https如何防止篡改(数字签名)

#### 三次握手建立起来的连接，在操作系统层面表现的是什么？


#### 499
* HTTP 请求在指定的时间内没能拿到响应而关闭了连接，就会发生 Nginx 记录 499 错误的情况



#### udp和connect和tcp的connect有什么区别
#### 五元组是哪五元？

* Udp和tcp的区别？旨在让我回答第一个问题，而不是单纯问八股

* 为什么udp没有connect？一步步引导……
   我们知道UDP是无连接的，它可以给多个IP发送数据包，包括广播地址或者多播通信的实现，而这些是TCP/IP无法实现的。
   但是UDP提供了这样的一个connect（）方法，它有两种使用方式，当使用了这个方法之后，那么就限定了这个socket的使用范围：
* 只允许从这个指定的SocketAddress 上获得数据包和向这个指定的SocketAddress 发送数据包， 
* 当你一旦通过这个socket向别的地址发送了数据包，
* 或者接收到了不是这个地址发送来的数据包，那么程序就会抛出IllegalArgumentException 异常， 
* 特殊的是如果指定的这个SocketAddress 是个多播地址或者广播地址，那么只允许向这个地址发送数据包，不允许从这个地址接收数据包。

// SocketAddress 其实就是IP地址+端口号 ， 而InetAddress 只有IP地址
connect(InetAddress address, int port)
connect(SocketAddress addr)

UDP通过这样的方式，限定了单向的通信，但是注意的是，这里的限定只是仅限于一方，而并没有限制另外一方，另外一方依旧是可以向多个IP地址发送数据包的，因此这和TCP/IP 是极大的不同。
TCP/IP的connect()是要有一个三次握手的过程的，而UDP的connect显然没有，它只是将IP地址和端口号进行了存储，对要进行通信的对象做了一个限制。
而且 TCP/IP的connect()只可以进行一次，但是UDP的connect()可以调用多次， 每次重新调用connect(SocketAddress )，就是将原来限制通信的对象修改为新的这个地址的对象， 
或者调用disConnect() 方法，就会解除对通信对象的限制，这样这个socket就又可以多向的通信了。

当我们进行UDP通信的对象只有一个时，建议使用connect()方法，使用了这个方法之后有一个极大的好处：
当我们使用了connect(SocketAddress addr) 方法时，那么在socket对象里面就会将发送方的地址设置为此地址，
那么发送的数据包对象就不用显式的标明 IP地址和 Port ，这样在调用send（packet）方法时，就不会对数据包再进行 IP地址和Port的安全检查，要发送的数据包少时优势体现不出来，但是当数据包多时，可以节省大量的时间。
* 除了sendto、send，还有什么api实现传输？Write

* Fork一个进程的整个过程

* 两个进程管道通信的详细描述

* Fork出来的进程和原来进程是同一块地址映射，怎么样做到子进程更改不影响父进程

* 网络路由转发的过程

* 两个单独的机房怎么实现通信

* 隧道了解吗？隧道协议等一系列巴拉巴拉

#### 观察者模式了解吗？
   观察者模式（又被称为发布-订阅（Publish/Subscribe）模式，属于行为型模式的一种
* 它定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。
* 这个主题对象在状态变化时，会通知所有的观察者对象，使他们能够自动更新自己。

#### TCP协议三次握手，如果第二三次握手失败了会怎么样？
#### 第一次握手丢失了，会发生什么？
当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，然后进入到 SYN_SENT 状态。
在这之后，如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），
* 就会触发「超时重传」机制，重传 SYN 报文，而且重传的 SYN 报文的序列号都是一样的。
* 当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，然后断开 TCP 连接。
#### 如果第二次握手丢了，就会发生比较有意思的事情，具体会怎么样呢？
因为第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，
* 那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是客户端就会触发超时重传机制，重传 SYN 报文。

然后，因为第二次握手中包含服务端的 SYN 报文，所以当客户端收到后，需要给服务端发送 ACK 确认报文（第三次握手）
，服务端才会认为该 SYN 报文被客户端收到了。
那么，如果第二次握手丢失了，服务端就收不到第三次握手，于是服务端这边会触发超时重传机制，重传 SYN-ACK 报文。

#### 第三次握手丢失了，会发生什么？
客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 ESTABLISH 状态。
因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，
如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。



### 第一次挥手丢失了，会发生什么？
当客户端（主动关闭方）调用 close 函数后，就会向服务端发送 FIN 报文，试图与服务端断开连接，此时客户端的连接进入到 FIN_WAIT_1 状态。
正常情况下，如果能及时收到服务端（被动关闭方）的 ACK，则会很快变为 FIN_WAIT2状态。

如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，
重传 FIN 报文，重发次数由 tcp_orphan_retries 参数控制。

当客户端重传 FIN 报文的次数超过 tcp_orphan_retries 后，就不再发送 FIN 报文，
则会在等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到第二次挥手，那么直接进入到 close 状态。

* 客户端收到第二次挥手，也就是收到服务端发送的 ACK 报文后，客户端就会处于 FIN_WAIT2 状态，
* 在这个状态需要等服务端发送第三次挥手，也就是服务端的 FIN 报文。

#### 第二次挥手丢失了，会发生什么？
当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 CLOSE_WAIT 状态。

在前面我们也提了，ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文
直到收到服务端的第二次挥手，或者达到最大的重传次数。

对于 close 函数关闭的连接，由于无法再发送和接收数据，所以FIN_WAIT2 状态不可以持续太久，
而 tcp_fin_timeout 控制了这个状态下连接的持续时长，默认值是 60 秒。

这意味着对于调用 close 关闭的连接，如果在 60 秒后还没有收到 FIN 报文，客户端（主动关闭方）的连接就会直接关闭

* 如果主动关闭方使用 shutdown 函数关闭连接，指定了只关闭发送方向，而接收方向并没有关闭，那么意味着主动关闭方还是可以接收数据的。

此时，如果主动关闭方一直没收到第三次挥手，那么主动关闭方的连接将会一直处于 FIN_WAIT2 状态（tcp_fin_timeout 无法控制 shutdown 关闭的连接）。

#### 第三次挥手丢失了，会发生什么？
当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，
同时连接处于 CLOSE_WAIT 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。

此时，内核是没有权利替代进程关闭连接，必须由进程主动调用 close 函数来触发服务端发送 FIN 报文。

服务端处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭。

如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，
这与客户端重发 FIN 报文的重传次数控制方式是一样的。

#### 当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 TIME_WAIT 状态。

在 Linux 系统，TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。

然后，服务端（被动关闭方）没有收到 ACK 报文前，还是处于 LAST_ACK 状态。

如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制。



#### TCP服务端一直没用收到数据之后的状态变化

#### http和rpc的区别？

#### http和rpc分别运行的协议，http和rpc的序列化？

#### 三次握手，为什么三次，第一次和第二次握手能不能携带数据，为什么

#### 长连接和短连接，长连接中的链路检测机制

#### TCP粘包和拆包
粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。

一般有三种方式分包的方式：

固定长度的消息；
特殊字符作为边界；
自定义消息结构。
* 固定长度的消息
  这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。
  但是这种方式灵活性不高，实际中很少用。

* 特殊字符作为边界
  我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。
  HTTP 是一个非常好的例子。
  HTTP 通过设置回车符、换行符作为 HTTP 报文协议的边界。
  有一点要注意，这个作为边界点的特殊字符，如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。

* 自定义消息结构
  我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。
  比如这个消息结构体，首先 4 个字节大小的变量来表示数据长度，真正的数据则在后面。
```
struct {
    u_int32_t message_length;
    char message_data[];
} message;
```
当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。
* 拆包：一个完整的业务可能会被TCP拆分成多个包进行发送

* 粘包：也有可能把多个小的包封装成一个大的数据包发送
#### 原因
* 应用程序写入数据的字节大小大于套接字发送缓冲区的大小.
* 进行MSS大小的TCP分段。( MSS=TCP报文段长度-TCP首部长度)
* 以太网的payload大于MTU进行IP分片。（ MTU指：一种通信协议的某一层上面所能通过的最大数据包大小。）

#### 解决方案
* 消息定长。
* 在包尾部增加回车或者空格符等特殊字符进行分割
* 将消息分为消息头和消息尾
* 使用其它复杂的协议，如RTMP协议等。

#### HTTP2.0与HTTP3.0的区别？
这次主要介绍了关于 HTTP/2 是如何提升性能的几个方向，它相比 HTTP/1 大大提高了传输效率、吞吐能力。
* 对于常见的 HTTP 头部通过静态表和 Huffman 编码的方式，将体积压缩了近一半，而且针对后续的请求头部，还可以建立动态表，
将体积压缩近 90%，大大提高了编码效率，同时节约了带宽资源。
* 动态表并非可以无限增大， 因为动态表是会占用内存的，动态表越大，内存也越大，容易影响服务器总体的并发能力，
* 因此服务器需要限制 HTTP/2 连接时长或者请求次数。
* HTTP/2 实现了 Stream 并发，多个 Stream 只需复用 1 个 TCP 连接，节约了 TCP 和 TLS 握手时间，
* 以及减少了 TCP 慢启动阶段对流量的影响
* 。不同的 Stream ID 可以并发，即使乱序发送帧也没问题，比如发送 A 请求帧1-> B 请求帧1-> A 请求帧2 -> B 请求帧2，
* 但是同一个 Stream 里的帧必须严格有序。

另外，可以根据资源的渲染顺序来设置 Stream 的优先级，从而提高用户体验。

* 服务器支持主动推送资源，大大提升了消息的传输性能，服务器推送资源时，会先发送 PUSH_PROMISE 帧，
* 告诉客户端接下来在哪个 Stream 发送资源，然后用偶数号 Stream 发送资源给客户端。
HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。
HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。


#### 基于QUIC的0RTT怎么实现的？
* TLSv1.3 还有个更厉害到地方在于会话恢复机制，在重连 TLvS1.3 只需要 0-RTT，
* 用“pre_shared_key”和“early_data”扩展，在 TCP 连接后立即就建立安全连接发送加密消息

* QUIC怎么实现可靠传输？

* QUIC发生丢包重传后包序号跟偏移量？

* TCP的timewati与close wait产生原因是什么？

select语句的存储引擎执行过程

#### 服务器挂掉了，客户端会怎么做
* 如果「客户端进程崩溃」，客户端的进程在发生崩溃的时候，内核会发送 FIN 报文，与服务端进行四次挥手。
但是，「客户端主机宕机」，那么是不会发生四次挥手的，具体后续会发生什么？还要看服务端会不会发送数据？
如果服务端会发送数据，由于客户端已经不存在，收不到数据报文的响应报文，服务端的数据报文会超时重传，
* 当重传总间隔时长达到一定阈值（内核会根据 tcp_retries2 设置的值计算出一个阈值）后，会断开 TCP 连接；
如果服务端一直不会发送数据，再看服务端有没有开启 TCP keepalive 机制？
如果有开启，服务端在一段时间没有进行数据交互时，会触发 TCP keepalive 机制，探测对方是否存在，
* 如果探测到对方已经消亡，则会断开自身的 TCP 连接；
如果没有开启，服务端的 TCP 连接会一直存在，并且一直保持在 ESTABLISHED 状态。


tcp三次握手和accept函数
虚拟内存、请求调页的具体过程
#### 继续往下说网络层怎么转发数据包
#### arp地址解析用到了吗，路由器转发出去，这个mac地址是谁的，怎么得到
#### 能不能静态arp（没答上去）
HTTPS RSA握手
HTTP3.0的特性，解释队头堵塞

（讲3.0的时候忘了提保持连接的特性）四元组标识TCP连接，那么对于QUIC而言，当四元组当中有一个东西变了需要重新建立连接吗？

#### TCP和UDP可以监听同一个端口吗？
讲一下select和epoll的区别和适用的场景。
你觉得对于服务器和客户端而言，支持的TCP连接数受到什么影响？
http请求头的一些参数：host,agent,ref


### 为什么seq要是随机值呢？

### 通常用什么来标识一个TCP连接？

### 一台机器到另外一台机器最多能有多少个TCP连接？



### 前后端分离时，cookie在什么情况下是有效的？
虽然我们可以在cookie中指定domain来解决,但是cookie必须针对性的设置作用域，这对于有多个不同域要共享cookie时,可操作性差,难以维护。
#### 前后端分离的状态如何维护？（jwt）
在传统的项目中我们利用,session+cookie来保持用户的登录状态,但这在前后端分离项⽬目中出现了问题
sessionid是使用cookie存储在客户端的,而cookie遵守同源策略,只在同源的请求中有效,这就导致了问题出现
前后端分离后静态资源完全可能(而且经常…)部署到另一个域下,导致cookie失效。

JWT可以对用户信息进行加密生成一个字符串,下发到客户端,客户端在后续请求中携带该字符串,
服务器解析后取出用户信息,从而完成用户身份的识别

#### jwt在前后端交互过程中通常被存储在哪里？在传输过程中是存放在什么中传输？（HTTP的header中）
token对比session
这种基于token的认证方式相比传统的session认证方式更节约服务器资源，并且对移动端和分布式更加友好。其优点如下：
**支持跨域访问：cookie是无法跨域的，而token由于没有用到cooki**e(前提是将token放到请求头中)，所以跨域后不会存在信息丢失问题
**无状态：token机制在服务端不需要存储session信息，因为token自身包含了所有登录用户的信息，所以可以减轻服务端压力**
更适用CDN：可以通过内容分发网络请求服务端的所有资料
**更适用于移动端：当客户端是非浏览器平台时，cookie是不支持的，采用token认证方式会简单很多**
**无需考虑CSRF：由于不再依赖cookie，所以采用token认证方式不会发生CSRF，所以也就无需考虑CSRF的防御**

* jwt是token的一种实现方式，它将用户信息加密到token里，服务器不保存任何用户信息。
  服务器通过使用保存的密钥验证token的正确性，只要正确即通过验证。
* 可以通过URL、POST参数或者在HTTP header发送，因为数据量小，传输速度也很快

#### 四次挥手 2msl 为什么不是1msl或者3msl？
MSL 是 Maximum Segment Lifetime，**报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃**。
因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，
当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。
MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。
**所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。**
TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，
如果超过了，就认为报文已经消失在网络中了。

TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是：
网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。
比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 FIN 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方，
一来一去正好 2 个 MSL。
**可以看到 2MSL时长 这其实是相当于至少允许报文丢失一次。**
比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。
为什么不是 4 或者 8 MSL 的时长呢？
你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。
2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。
如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。

在 Linux 系统里 2MSL 默认是 60 秒，那么一个 MSL 也就是 30 秒。Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒。
  四次挥手释放连接时，等待2MSL的意义?
  MSL是Maximum Segment Lifetime的英文缩写，可译为“最长报文段寿命”，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

为了保证客户端发送的最后一个ACK报文段能够到达服务器。
因为这个ACK有可能丢失，从而导致处在LAST-ACK状态的服务器收不到对FIN-ACK的确认报文。
服务器会超时重传这个FIN-ACK，接着客户端再重传一次确认，重新启动时间等待计时器。
最后客户端和服务器都能正常的关闭。假设客户端不等待2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，
服务器就无法正常的进入关闭连接状态。

#### 保证客户端发送的最后一个ACK报文段能够到达服务端。 
* 这个ACK报文段有可能丢失，使得处于LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认，
* 服务端超时重传FIN+ACK报文段，而客户端能在2MSL时间内收到这个重传的FIN+ACK报文段，接着客户端重传一次确认，
* 重新启动2MSL计时器，最后客户端和服务端都进入到CLOSED状态，若客户端在TIME-WAIT状态不等待一段时间，
* 而是发送完ACK报文段后立即释放连接，则无法收到服务端重传的FIN+ACK报文段，所以不会再发送一次确认报文段，则服务端无法正常进入到CLOSED状态。
#### 防止“已失效的连接请求报文段”出现在本连接中。
* 客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，
* 使下一个新的连接中不会出现这种旧的连接请求报文段


#### CSRF攻击？你知道吗？
跨站点请求伪造，指攻击者通过跨站请求，以合法的用户的身份进行非法操作。
可以这么理解CSRF攻击：攻击者盗用你的身份，以你的名义向第三方网站发送恶意请求。
CRSF能做的事情包括利用你的身份发邮件，发短信，进行交易转账，甚至盗取账号信息。

##### 如何防范CSRF攻击
安全框架，例如Spring Security。 
token机制。在HTTP请求中进行token验证，如果请求中没有token或者token内容不正确，则认为CSRF攻击而拒绝该请求。 
验证码。通常情况下，验证码能够很好的遏制CSRF攻击，但是很多情况下，出于用户体验考虑，验证码只能作为一种辅助手段，而不是最主要的解决方案。
referer识别。在HTTP Header中有一个字段Referer，它记录了HTTP请求的来源地址。
* 如果Referer是其他网站，就有可能是CSRF攻击，则拒绝该请求。
* 但是，服务器并非都能取到Referer。很多用户出于隐私保护的考虑，限制了Referer的发送。
* 在某些情况下，浏览器也不会发送Referer，例如HTTPS跳转到HTTP。
* 1）验证请求来源地址； 2）关键操作添加验证码； 3）在请求地址添加 token 并验证

####  ARP协议工作原理？ARP攻击？如何解决？
ARP（Address Resolution Protocol，地址解析协议）是一个位于TCP/IP协议栈中的底层协议，负责将某个IP地址解析成对应的MAC地址。
* 而ARP攻击就是通过伪造IP地址和MAC地址实现ARP欺骗，能够在网络中产生大量的ARP通信量使网络阻塞，攻击者只要持续不断的发出伪造的ARP响应包就能更改目标主机ARP缓存中的IP-MAC条目，
* 造成网络中断或中间人攻击。这是一种“中间人”（MAN-IN-MIDDLE）攻击技术
  ARP攻击是指攻击者利用ARP协议的缺陷，发送ARP响应报文，把网关对应的MAC地址变成欺骗的MAC地址，从而导致网络中断或数据劫持的目的。
  二.ARP攻击的防御方法
  可以在客户端设置静态的ARP映射表，这样就不会受到ARP的欺骗；也可以在交换机上设置访问控制，对于所有流经交换机但IP地址和MAC地址与网关不匹配的情况进行过滤，从而避免了ARP的攻击

DNS的解析过程
* HTTPS ,客户端如何验证证书，HTTPS不能防止什么攻击
  HTTPS因为增加了CA证书，可以在会话前通过证书验证证明通信的彼此就是所声称的人，因此可以防范中间人攻击。这种防范中间人攻击的前提是在HTTPs协议的双向认证上。如果仅仅实现了HTTPs的单向认证，如不验证客户端，只验证服务器，这种情况下还是不能抵御中间人攻击的，这种情况下就会出现SSL剥离攻击（SSLTrip）和SSL劫持攻击（使用各种代理软件，如burpsuit或Filder等）。
  SSL剥离攻击剥离SSL协议，表现为用户和攻击者之间使用HTTP，攻击者和服务器之间使用https协议。
  SSL劫持攻击表现为用户和攻击者之间使用攻击者伪造的CA证书使用其https协议进行通信，（其中重要的步骤是把burpsuit的CA根证书导入用户浏览器，这样用户浏览器就能信任假CA发给中间人的证书(即信任中间人burpsuit)，建立客户端和中间人之间的会话信道）。而攻击者和服务器之间使用真正的CA证书创建的对称秘钥进行加密，攻击者收到客户端信息先用前者会话秘钥解密，再使用后者之间的会话秘钥加密。这样使得客户端和服务器都以为是和真正的对方通信。
  为了防止SSL剥离攻击，可以（1）在服务器上开启HSTS(HTTP Strict Transport Security, HTTP 严格传输安全)，使服务器只接收使用HTTPS的连接。（2）将 HSTS 站点列表内置到浏览器中，这样只要浏览器离线判断该站点启用了 HSTS，就会跳过原先的 HTTP 重定向，直接发起 HTTPS 请求。
  为了防止SSL劫持攻击，目前我只能想到使用https双向认证，其他还没想到。

#### #### Time wait和Close wait的区别
常用的三个状态是：ESTABLISHED 表示正在通信，TIME_WAIT 表示主动关闭，CLOSE_WAIT 表示被动关闭。

TCP协议规定，对于已经建立的连接，网络双方要进行四次握手才能成功断开连接，如果缺少了其中某个步骤，将会使连接处于假死状态，连接本身占用的资源不会被释放。网络服务器程序要同时管理大量连接，所以很有必要保证无用连接完全断开，否则大量僵死的连接会浪费许多服务器资源。在众多TCP状态中，最值得注意的状态有两个：CLOSE_WAIT和TIME_WAIT。
TIME_WAIT

TIME_WAIT 是主动关闭链接时形成的，等待2MSL时间，约4分钟。主要是防止最后一个ACK丢失。
由于TIME_WAIT 的时间会非常长，因此server端应尽量减少主动关闭连接
CLOSE_WAIT

CLOSE_WAIT是被动关闭连接是形成的。
根据TCP状态机，服务器端收到客户端发送的FIN，则按照TCP实现发送ACK，因此进入CLOSE_WAIT状态。
但如果服务器端不执行close()，就不能由CLOSE_WAIT迁移到LAST_ACK，则系统中会存在很多CLOSE_WAIT状态的连接。
此时，可能是系统忙于处理读、写操作，而未将已收到FIN的连接，进行close。此时，recv/read已收到FIN的连接socket，会返回0。
为什么需要 TIME_WAIT 状态？

假设最终的ACK丢失，server将重发FIN，client必须维护TCP状态信息以便可以重发最终的ACK
否则会发送RST，结果server认为发生错误。TCP实现必须可靠地终止连接的两个方向(全双工关闭)，
client必须进入 TIME_WAIT 状态，因为client可能面 临重发最终ACK的情形。

为什么 TIME_WAIT 状态需要保持 2MSL 这么长的时间？

如果 TIME_WAIT 状态保持时间不足够长(比如小于2MSL)，第一个连接就正常终止了。第二个拥有相同相关五元组的连接出现，而第一个连接的重复报文到达，干扰了第二个连接。TCP实现必须防止某个连接的重复报文在连接终止后出现，所以让TIME_WAIT状态保持时间足够长(2MSL)，连接相应方向上的TCP报文要么完全响应完毕，要么被 丢弃。建立第二个连接的时候，不会混淆。
TIME_WAIT 和CLOSE_WAIT状态socket过多
如果服务器出了异常，百分之八九十都是下面两种情况：
1.服务器保持了大量TIME_WAIT状态
2.服务器保持了大量CLOSE_WAIT状态，简单来说CLOSE_WAIT数目过大是由于被动关闭连接处理不当导致的。

因为linux分配给一个用户的文件句柄是有限的，而TIME_WAIT和CLOSE_WAIT两种状态如果一直被保持，
那么意味着对应数目的通道就一直被占着，而且是“占着茅坑不使劲”，一旦达到句柄数上限，新的请求就无法被处理了，
接着就是大量Too Many Open Files异常，Tomcat崩溃。


####   Dos和XSS攻击是什么？如何防止？

### 中间人攻击知道吗？怎么做https的抓包？https怎么篡改？

浏览器输入网址，返回error：服务不存在，如何排查？

#### 浏览器输入URL到页面打开的过程如何加速
使用http3.0协议（多路复用、tcp连接换成udp连接减少三次握手时间、0-RTT建连，向前纠错机制减少重传）
数据压缩，减少传输时间和次数
CDN服务器，地域分布式缓存静态资源
页面先呈现静态资源及框架，动态资源延迟加载，从使用者角度加速
每次打开做好缓存，例如DNS缓存、静态资源缓存
自己理解，有错请纠


#### udp，报文结构、优缺点。

第三部分：计算机网络

* TCP、UDP可以绑定相同的端口吗？
  -TCP 和 UDP 传输协议，在内核中是由两个完全独立的软件模块实现的。当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP
  -所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。
  -因此，TCP/UDP 各自的端口号也相互独立，互不影响。

* 多个TCP进程可以绑定同一个端口吗？
  如果两个 TCP 服务进程同时绑定的 IP 地址和端口都相同，那么执行 bind() 时候就会出错，错误是“Address already in use”。
  如果两个 TCP 服务进程绑定的端口都相同，而 IP 地址不同，那么执行 bind() 不会出错。

* 什么情况下，可以重新利用这个端口？

* 如何解决服务端重启时，报错“Address already in use”的问题？
  当我们重启 TCP 服务进程的时候，意味着通过服务器端发起了关闭连接操作，于是就会经过四次挥手，而对于主动关闭方，会在 TIME_WAIT 这个状态里停留一段时间，这个时间大约为 2MSL。
  当 TCP 服务进程重启时，服务端会出现 TIME_WAIT 状态的连接，TIME_WAIT 状态的连接使用的 IP+PORT 仍然被认为是一个有效的 IP+PORT 组合，相同机器上不能够在该 IP+PORT 组合上进行绑定，那么执行
  bind() 函数的时候，就会返回了 Address already in use 的错误。
  要解决这个问题，我们可以对 socket 设置 SO_REUSEADDR 属性。
  这样即使存在一个和绑定 IP+PORT 一样的 TIME_WAIT 状态的连接，依然可以正常绑定成功，因此可以正常重启成功。

* 如果没有开启 net.ipv4.tcp_tw_reuse 内核参数，那么内核就会选择下一个端口，然后继续判断，直到找到一个没有被相同四元组的连接使用的端口
* 如果端口资源耗尽还是没找到，那么 connect 函数就会返回错误。
  如果开启了 net.ipv4.tcp_tw_reuse 内核参数，就会判断该四元组的连接状态是否处于 TIME_WAIT 状态，如果连接处于 TIME_WAIT 状态并且该状态持续的时间超过了 1 秒，
* 那么就会重用该连接，于是就可以使用 2222 端口了，这时 connect 就会返回成功。
  再次提醒一次**，开启了 net.ipv4.tcp_tw_reuse 内核参数，是客户端（连接发起方） 在调用 connect() 函数时才起作用**，所以在服务端开启这个参数是没有效果的。

* 客户端的端口可以重复使用吗？
  -在客户端执行 connect 函数的时候，只要客户端连接的服务器不是同一个，内核允许端口重复使用。
  -TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接的。
  -所以，如果客户端已使用端口 64992 与服务端 A 建立了连接，那么客户端要与服务端 B 建立连接，还是可以使用端口 64992 的，因为内核是通过四元祖信息来定位一个 TCP
  连接的，并不会因为客户端的端口号相同，而导致连接冲突的问题。

* 客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？
  -要看客户端是否都是与同一个服务器（目标地址和目标端口一样）建立连接。
  -如果客户端都是与同一个服务器（目标地址和目标端口一样）建立连接，那么如果客户端 TIME_WAIT
  状态的连接过多，当端口资源被耗尽，就无法与这个服务器再建立连接了。即使在这种状态下，还是可以与其他服务器建立连接的，只要客户端连接的服务器不是同一个，那么端口是重复使用的。

* 如何解决客户端 TCP 连接 TIME_WAIT 过多，导致无法与同一个服务器建立连接的问题？
  -打开 net.ipv4.tcp_tw_reuse 这个内核参数。
  -因为开启了这个内核参数后，客户端调用 connect 函数时，如果选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态。
  -如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了。

* 介绍一下time_wait是一个什么状态，为什么需要这个状态，有什么作用？

* time_wait状态会带来什么副作用吗？
  --如果客户端（发起连接方）的 TIME_WAIT 状态过多，占满了所有端口资源
  --那么就无法对「目的 IP+ 目的 PORT」都一样的服务器发起连接了，但是被使用的端口，还是可以继续对另外一个服务器发起连接的。

* 但是 TIME_WAIT 状态也不是摆设作用，它的作用有两个：
  --防止具有相同四元组的旧数据包被收到，也就是防止历史连接中的数据，被后面的连接接受，否则就会导致后面的连接收到一个无效的数据，
  --保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭;

* Linux 操作系统提供了两个可以系统参数来快速回收处于 TIME_WAIT 状态的连接，这两个参数都是默认关闭的：
* net.ipv4.tcp_tw_reuse
  --如果开启该选项的话，客户端（连接发起方） 在调用 connect() 函数时，如果内核选择到的端口，已经被相同四元组的连接占用的时候
  --就会判断该连接是否处于 TIME_WAIT 状态，如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了。
  --所以该选项只适用于连接发起方。
* net.ipv4.tcp_tw_recycle
  --如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收；
  --要使得这两个选项生效，有一个前提条件，就是要打开 TCP 时间戳，即 net.ipv4.tcp_timestamps=1（默认即为 1)）。
* 同步IO和异步IO介绍一下？

* PAWS
  --PAWS 就是为了避免这个问题而产生的，在开启 tcp_timestamps 选项情况下，一台机器发的所有 TCP 包都会带上发送时的时间戳，
  --PAWS 要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 Recent TSval 值做比较，
  --如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包。

* 那什么是 per-host 的 PAWS 机制呢？

per-host 是对「对端 IP 做 PAWS 检查」，而非对「IP + 端口」四元组做 PAWS 检查。

但是如果客户端网络环境是用了 NAT 网关，那么客户端环境的每一台机器通过 NAT 网关后，都会是相同的 IP 地址，在服务端看来，就好像只是在跟一个客户端打交道一样，无法区分出来。

Per-host PAWS 机制利用TCP option里的 timestamp 字段的增长来判断串扰数据，而 timestamp 是根据客户端各自的 CPU tick 得出的值。

当客户端 A 通过 NAT 网关和服务器建立 TCP 连接，然后服务器主动关闭并且快速回收 TIME-WAIT 状态的连接后
客户端 B 也通过 NAT 网关和服务器建立 TCP 连接，注意客户端 A 和 客户端 B 因为经过相同的 NAT 网关，
所以是用相同的 IP 地址与服务端建立 TCP 连接，如果客户端 B 的 timestamp 比 客户端 A 的 timestamp 小，
那么由于服务端的 per-host 的 PAWS 机制的作用，服务端就会丢弃客户端主机 B 发来的 SYN 包。

因此，tcp_tw_recycle 在使用了 NAT 的网络下是存在问题的，
如果它是对 TCP 四元组做 PAWS 检查，而不是对「相同的 IP 做 PAWS 检查」，那么就不会存在这个问题了。

tcp_tw_recycle 在 Linux 4.12 版本后，直接取消了这一参数。

#### accpet 队列满了

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

半连接队列，也称 SYN 队列；
全连接队列，也称 accepet 队列；
服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列
并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，内核会把连接从半连接队列移除
然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。

#### 半连接队列满了

当服务器造成syn攻击，就有可能导致 TCP 半连接队列满了，这时后面来的 syn 包都会被丢弃。

但是，如果开启了syncookies 功能，即使半连接队列满了，也不会丢弃syn 包。

syncookies 是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。

syncookies 参数主要有以下三个值：

0 值，表示关闭该功能；
1 值，表示仅当 SYN 半连接队列放不下时，再启用它；
2 值，表示无条件开启功能；
那么在应对 SYN 攻击时，只需要设置为 1 即可：

#### 这里给出几种防御 SYN 攻击的方法：

* 增大半连接队列；
* 开启 tcp_syncookies 功能
* 减少 SYN+ACK 重传次数
  方式一：增大半连接队列

要想增大半连接队列，我们得知不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大全连接队列。否则，只单纯增大 tcp_max_syn_backlog 是无效的。
增大 tcp_max_syn_backlog 和 somaxconn 的方法是修改 Linux 内核参数：
增大 backlog 的方式，每个 Web 服务都不同，比如 Nginx 增大 backlog 的方法如下：
最后，改变了如上这些参数后，要重启 Nginx 服务，因为半连接队列和全连接队列都是在 listen() 初始化的。

方式二：开启 tcp_syncookies 功能

开启 tcp_syncookies 功能的方式也很简单，修改 Linux 内核参数：

方式三：减少 SYN+ACK 重传次数

当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。

那么针对 SYN 攻击的场景，我们可以减少 SYN+ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。

#### 全连接队列满了

在服务端并发处理大量请求时，如果 TCP accpet 队列过小，或者应用程序调用 accept() 不及时，就会造成 accpet 队列满了
这时后续的连接就会被丢弃，这样就会出现服务端请求数量上不去的现象。

我们可以通过 ss 命令来看 accpet 队列大小，在「LISTEN 状态」时，Recv-Q/Send-Q 表示的含义如下：

Recv-Q：当前 accpet 队列的大小，也就是当前已完成三次握手并等待服务端 accept() 的 TCP 连接个数；
Send-Q：当前 accpet 最大队列长度，上面的输出结果说明监听 8088 端口的 TCP 服务进程，accpet 队列的最大长度为 128；
如果 Recv-Q 的大小超过 Send-Q，就说明发生了 accpet 队列满的情况。

要解决这个问题，我们可以：

调大 accpet 队列的最大长度，调大的方式是通过调大 backlog 以及 somaxconn 参数。
检查系统或者代码为什么调用 accept() 不及时；

