#### RSA算法原理？

#### HTTPS密钥细节

#### http的报文格式 ，说几个头部
HTTP的请求报文由四部分组成：请求行(request line)、请求头部(header)、空行和请求数据(request data)

#### http和https的区别? https加密实现?


#### 数字证书有哪些？

#### 对称加密、非对称加密常用的算法

#### 浏览器访问服务器的流程

#### 三次握手、四次挥手、为什么四次



#### 在命令行ping网址的时候TTL是什么东西？ ping原理
#### 计算机网络

#### TCP拥塞控制

#### TCP连接建立后把网线拔了会怎么样，客户端会发生什么

### 在山区里信号很差用手机上网，没有彻底断开会发生什么，什么时候会发生重传

* HTTP各个版本 (1.0，1.1，2.0，3.0)
  --1.1 长连接、管道网络运输
  --2.0头部压缩HPACK算法、二进制格式、并发传输、服务器主动推送资源
  --3.0无队头阻塞、更快的链接建立、连接迁移

* HTTP2.0之前怎么实现服务器推送机制
* 是否了解过Websocket
* 保证TCP传输的可靠性的实现
  -序列号、确认应答、超时重传、拥塞控制、浏览控制
* 计算机网络五层模型
* http请求报文和响应报文包含了哪些

* https和http区别是什么
  --HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
  --HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
  --HTTP 的端口号是 80，HTTPS 的端口号是 443。
  --HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

* post请求了解吗其和get请求的区别是什么
  --GET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。
  --POST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。

#### 如何使得UDP可靠传输


* 问看没看过 tcp 源码，答：只看过协议首部

* tcp udp 区别
  -连接、服务对象、可靠性、拥塞控制和流量控制、首部开销、传输方式、分片不同

#### tcp timewait 作用
  --防止历史连接中的数据被后面相同的四元组接受
  --保证被动关闭连接能被正确关闭

#### 服务端上的timewait过多会产生什么问题？
* 占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等；
* 占用端口资源，端口资源也是有限的，一般可以开启的端口为 32768～61000，也可以通过 net.ipv4.ip_local_port_range参数指定范围。
客户端和服务端 TIME_WAIT 过多，造成的影响是不同的。
如果客户端（主动发起关闭连接方）的 TIME_WAIT 状态过多，占满了所有端口资源，
* 那么就无法对「目的 IP+ 目的 PORT」都一样的服务器发起连接了，
* 但是被使用的端口，还是可以继续对另外一个服务器发起连接的。
因此，客户端（发起连接方）都是和「目的 IP+ 目的 PORT 」都一样的服务器建立连接的话，
* 当客户端的 TIME_WAIT 状态连接过多的话，就会受端口资源限制，如果占满了所有端口资源，那么就无法再跟「目的 IP+ 目的 PORT」都一样的服务器建立连接了。
不过，即使是在这种场景下，只要连接的是不同的服务器，端口是可以重复使用的，所以客户端还是可以向其他服务器发起连接的，
* 这是因为内核在定位一个连接的时候，是通过四元组（源IP、源端口、目的IP、目的端口）信息来定位的，并不会因为客户端的端口一样，而导致连接冲突。

如果服务端（主动发起关闭连接方）的 TIME_WAIT 状态过多，并不会导致端口资源受限，
因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等


#### 有什么办法避免timewait过多？如何优化 TIME_WAIT？
* 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；
* net.ipv4.tcp_max_tw_buckets
* 程序中使用 SO_LINGER ，应用强制使用 RST 关闭。
* net.ipv4.tcp_tw_reuse 和 tcp_timestamps

如下的 Linux 内核参数开启后，则可以复用处于 TIME_WAIT 的 socket 为新的连接所用。

有一点需要注意的是，tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，
在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用。
net.ipv4.tcp_tw_reuse = 1
使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持，即

net.ipv4.tcp_timestamps=1（默认即为 1）
这个时间戳的字段是在 TCP 头部的「选项」里，它由一共 8 个字节表示时间戳，其中第一个 4 字节字段用来保存发送该数据包的时间，
第二个 4 字节字段用来保存最近一次接收对方发送到达数据的时间。

由于引入了时间戳，我们在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。

* net.ipv4.tcp_max_tw_buckets

这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置，这个方法比较暴力。

* ：程序中使用 SO_LINGER

我们可以通过设置 socket 选项，来设置调用 close 关闭连接行为。

struct linger so_linger;
so_linger.l_onoff = 1;
so_linger.l_linger = 0;
setsockopt(s, SOL_SOCKET, SO_LINGER, &so_linger,sizeof(so_linger));
* 如果l_onoff为非 0， 且l_linger值为 0，那么调用close后，会立该发送一个RST标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了TIME_WAIT状态，直接关闭。
但这为跨越TIME_WAIT状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。
#### 为什么 TIME_WAIT 等待的时间是 2MSL？
MSL 是 Maximum Segment Lifetime，**报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃**。
因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，
当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。
MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。
**所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。**
TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，
如果超过了，就认为报文已经消失在网络中了。

TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 
网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。
比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 FIN 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方，
一来一去正好 2 个 MSL。
**可以看到 2MSL时长 这其实是相当于至少允许报文丢失一次。**
比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。
为什么不是 4 或者 8 MSL 的时长呢？
你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。
2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。
如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。

在 Linux 系统里 2MSL 默认是 60 秒，那么一个 MSL 也就是 30 秒。Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒。
#### tcp 粘包拆包和解决思路

* https可以防止DNS劫持吗？

#### HTTP中POST和GET的区别
get是获取数据，post是修改数据
get把请求的数据放在url上， 以?分割URL和传输数据，参数之间以&相连，所以get不太安全。而post把数据放在HTTP的包体内（requrest body）

get提交的数据最大是2k（ 限制实际上取决于浏览器）， post理论上没有限制。

GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200(返回数据);
POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)。

GET请求会被浏览器主动缓存，而POST不会，除非手动设置。

本质区别：GET是幂等的，而POST不是幂等的

这里的幂等性：幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。
，所以不应该且不能用get请求做数据的增删改这些有副作用的操作。
因为get请求是幂等的，在网络不好的隧道中会尝试重试。
如果用get请求增数据，会有重复操作的风险，而这种重复操作可能会导致副作用（浏览器和操作系统并不知道你会用get请求去做增操作）。

#### GET 方法的长度限制是怎么回事？
网络上都会提到浏览器地址栏输入的参数是有限的。
首先说明一点，HTTP 协议没有 Body 和 URL 的长度限制，对 URL 限制的大多是浏览器和服务器的原因。
浏览器原因就不说了，服务器是因为处理长 URL 要消耗比较多的资源，为了性能和安全（防止恶意构造长 URL 来攻击）考虑，会给 URL 长度加限制。

#### POST 方法比 GET 方法安全？
有人说POST 比 GET 安全，因为数据在地址栏上不可见。
然而，从传输的角度来说，他们都是不安全的，因为 HTTP 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文。
要想安全传输，就只有加密，也就是 HTTPS。

#### POST 方法会产生两个 TCP 数据包？你了解吗？
有些文章中提到，POST 会将 header 和 body 分开发送，先发送 header，服务端返回 100 状态码再发送 body。
HTTP 协议中没有明确说明 POST 会产生两个 TCP 数据包，而且实际测试(Chrome)发现，header 和 body 不会分开发送。
所以，header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为

#### 输入一个 url 回车到获得响应，经过哪些层，分别涉及什么协议？


* Https流程

#### Https如何防止篡改(数字签名)

#### 三次握手建立起来的连接，在操作系统层面表现的是什么？


#### 499
* HTTP 请求在指定的时间内没能拿到响应而关闭了连接，就会发生 Nginx 记录 499 错误的情况



#### udp和connect和tcp的connect有什么区别
#### 五元组是哪五元？

* Udp和tcp的区别？旨在让我回答第一个问题，而不是单纯问八股

* 为什么udp没有connect？一步步引导……
   我们知道UDP是无连接的，它可以给多个IP发送数据包，包括广播地址或者多播通信的实现，而这些是TCP/IP无法实现的。
   但是UDP提供了这样的一个connect（）方法，它有两种使用方式，当使用了这个方法之后，那么就限定了这个socket的使用范围：
* 只允许从这个指定的SocketAddress 上获得数据包和向这个指定的SocketAddress 发送数据包， 当你一旦通过这个socket向别的地址发送了数据包，或者接收到了不是这个地址发送来的数据包，那么程序就会抛出IllegalArgumentException 异常， 特殊的是如果指定的这个SocketAddress 是个多播地址或者广播地址，那么只允许向这个地址发送数据包，不允许从这个地址接收数据包。

// SocketAddress 其实就是IP地址+端口号 ， 而InetAddress 只有IP地址
connect(InetAddress address, int port)
connect(SocketAddress addr)

UDP通过这样的方式，限定了单向的通信，但是注意的是，这里的限定只是仅限于一方，而并没有限制另外一方，另外一方依旧是可以向多个IP地址发送数据包的，因此这和TCP/IP 是极大的不同。TCP/IP的connect()是要有一个三次握手的过程的，而UDP的connect显然没有，它只是将IP地址和端口号进行了存储，对要进行通信的对象做了一个限制。
而且 TCP/IP的connect()只可以进行一次，但是UDP的connect()可以调用多次， 每次重新调用connect(SocketAddress )，就是将原来限制通信的对象修改为新的这个地址的对象， 
或者调用disConnect() 方法，就会解除对通信对象的限制，这样这个socket就又可以多向的通信了。

当我们进行UDP通信的对象只有一个时，建议使用connect()方法，使用了这个方法之后有一个极大的好处：
当我们使用了connect(SocketAddress addr) 方法时，那么在socket对象里面就会将发送方的地址设置为此地址，
那么发送的数据包对象就不用显式的标明 IP地址和 Port ，这样在调用send（packet）方法时，就不会对数据包再进行 IP地址和Port的安全检查，要发送的数据包少时优势体现不出来，但是当数据包多时，可以节省大量的时间。
* 除了sendto、send，还有什么api实现传输？Write

* Fork一个进程的整个过程

* 两个进程管道通信的详细描述

*  Fork出来的进程和原来进程是同一块地址映射，怎么样做到子进程更改不影响父进程

* 网络路由转发的过程

*  两个单独的机房怎么实现通信

*  隧道了解吗？隧道协议等一系列巴拉巴拉

*  观察者模式了解吗？多对一


#### TCP协议三次握手，如果第二三次握手失败了会怎么样？

#### TCP服务端一直没用收到数据之后的状态变化
#### http和rpc的区别？
#### http和rpc分别运行的协议，http和rpc的序列化？

#### 三次握手，为什么三次，第一次和第二次握手能不能携带数据，为什么

#### 长连接和短连接，长连接中的链路检测机制

#### TCP粘包和拆包
粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。

一般有三种方式分包的方式：

固定长度的消息；
特殊字符作为边界；
自定义消息结构。
* 固定长度的消息
  这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。
  但是这种方式灵活性不高，实际中很少用。

* 特殊字符作为边界
  我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。
  HTTP 是一个非常好的例子。
  HTTP 通过设置回车符、换行符作为 HTTP 报文协议的边界。
  有一点要注意，这个作为边界点的特殊字符，如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。

* 自定义消息结构
  我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。
  比如这个消息结构体，首先 4 个字节大小的变量来表示数据长度，真正的数据则在后面。
```
struct {
    u_int32_t message_length;
    char message_data[];
} message;
```
当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。
* 拆包：一个完整的业务可能会被TCP拆分成多个包进行发送

* 粘包：也有可能把多个小的包封装成一个大的数据包发送
#### 原因
* 应用程序写入数据的字节大小大于套接字发送缓冲区的大小.
* 进行MSS大小的TCP分段。( MSS=TCP报文段长度-TCP首部长度)
* 以太网的payload大于MTU进行IP分片。（ MTU指：一种通信协议的某一层上面所能通过的最大数据包大小。）

#### 解决方案
* 消息定长。
* 在包尾部增加回车或者空格符等特殊字符进行分割
* 将消息分为消息头和消息尾
* 使用其它复杂的协议，如RTMP协议等。

#### HTTP2.0与HTTP3.0的区别？
这次主要介绍了关于 HTTP/2 是如何提升性能的几个方向，它相比 HTTP/1 大大提高了传输效率、吞吐能力。
* 对于常见的 HTTP 头部通过静态表和 Huffman 编码的方式，将体积压缩了近一半，而且针对后续的请求头部，还可以建立动态表，
将体积压缩近 90%，大大提高了编码效率，同时节约了带宽资源。
* 动态表并非可以无限增大， 因为动态表是会占用内存的，动态表越大，内存也越大，容易影响服务器总体的并发能力，
* 因此服务器需要限制 HTTP/2 连接时长或者请求次数。
* HTTP/2 实现了 Stream 并发，多个 Stream 只需复用 1 个 TCP 连接，节约了 TCP 和 TLS 握手时间，
* 以及减少了 TCP 慢启动阶段对流量的影响
* 。不同的 Stream ID 可以并发，即使乱序发送帧也没问题，比如发送 A 请求帧1-> B 请求帧1-> A 请求帧2 -> B 请求帧2，
* 但是同一个 Stream 里的帧必须严格有序。

另外，可以根据资源的渲染顺序来设置 Stream 的优先级，从而提高用户体验。

* 服务器支持主动推送资源，大大提升了消息的传输性能，服务器推送资源时，会先发送 PUSH_PROMISE 帧，
* 告诉客户端接下来在哪个 Stream 发送资源，然后用偶数号 Stream 发送资源给客户端。
HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。
HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。


#### 基于QUIC的0RTT怎么实现的？
* TLSv1.3 还有个更厉害到地方在于会话恢复机制，在重连 TLvS1.3 只需要 0-RTT，
* 用“pre_shared_key”和“early_data”扩展，在 TCP 连接后立即就建立安全连接发送加密消息

* QUIC怎么实现可靠传输？

* QUIC发生丢包重传后包序号跟偏移量？

* TCP的timewati与close wait产生原因是什么？

select语句的存储引擎执行过程

* 服务器挂掉了，客户端会怎么做
tcp三次握手和accept函数
虚拟内存、请求调页的具体过程
#### 继续往下说网络层怎么转发数据包
#### arp地址解析用到了吗，路由器转发出去，这个mac地址是谁的，怎么得到
#### 能不能静态arp（没答上去）
HTTPS RSA握手
HTTP3.0的特性，解释队头堵塞

（讲3.0的时候忘了提保持连接的特性）四元组标识TCP连接，那么对于QUIC而言，当四元组当中有一个东西变了需要重新建立连接吗？

#### TCP和UDP可以监听同一个端口吗？
讲一下select和epoll的区别和适用的场景。
你觉得对于服务器和客户端而言，支持的TCP连接数受到什么影响？
http请求头的一些参数：host,agent,referer等