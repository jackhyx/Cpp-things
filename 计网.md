
#### #ECDHE 握手过程
* 使用了 ECDHE，在 TLS 第四次握手前，客户端就已经发送了加密的 HTTP 数据，而对于 RSA 握手过程，必须要完成 TLS 四次握手，才能传输应用数据。

所以，ECDHE 相比 RSA 握手过程省去了一个消息往返的时间，
这个有点「抢跑」的意思，它被称为是「TLS False Start」，跟「TCP Fast Open」有点像
都是在还没连接完全建立前，就发送了应用数据，这样便提高了传输的效率。

* TLS 第一次握手
客户端首先会发一个「Client Hello」消息，消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的随机数（Client Random）。

* TLS 第二次握手
服务端收到客户端的「打招呼」，同样也要回礼，会返回「Server Hello」消息，
* 消息面有服务器确认的 TLS 版本号，也给出了一个随机数（Server Random），然后从客户端的密码套件列表选择了一个合适的密码套件。
不过，这次选择的密码套件就和 RSA 不一样了，我们来分析一下这次的密码套件的意思。
「 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384」

**密钥协商算法使用 ECDHE；**
签名算法使用 RSA；
握手后的通信使用 AES 对称算法，密钥长度 256 位，分组模式是 GCM；
摘要算法使用 SHA384；
接着，服务端为了证明自己的身份，发送「Certificate」消息，会把证书也发给客户端。

这一步就和 RSA 握手过程有很大到区别了，因为服务端选择了 ECDHE 密钥协商算法，所以会在发送完证书后，发送「Server Key Exchange」消息。

这个过程服务器做了三件事：

* 选择了名为 x25519 的椭圆曲线，选好了椭圆曲线相当于椭圆曲线基点 G 也定好了，这些都会公开给客户端；
* 生成随机数作为服务端椭圆曲线的私钥，保留到本地；
* 根据基点 G 和私钥计算出服务端的椭圆曲线公钥，这个会公开给客户端。
* 为了保证这个椭圆曲线的公钥不被第三方篡改，服务端会用 RSA 签名算法给服务端的椭圆曲线公钥做个签名。

随后，就是「Server Hello Done」消息，服务端跟客户端表明：“这些就是我提供的信息，打招呼完毕”。

至此，TLS 两次握手就已经完成了，目前客户端和服务端通过明文共享了这几个信息
Client Random、Server Random 、使用的椭圆曲线、椭圆曲线基点 G、服务端椭圆曲线的公钥，这几个信息很重要，是后续生成会话密钥的材料。

* TLS 第三次握手
客户端收到了服务端的证书后，自然要校验证书是否合法，如果证书合法，那么服务端到身份就是没问题的。
* 校验证书的过程会走证书链逐级验证，确认证书的真实性，再用证书的公钥验证签名，这样就能确认服务端的身份了，确认无误后，就可以继续往下走。

客户端会生成一个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前面给的信息，
生成客户端的椭圆曲线公钥，然后用「Client Key Exchange」消息发给服务端。

至此，双方都有对方的椭圆曲线公钥、自己的椭圆曲线私钥、椭圆曲线基点 G。于是，双方都就计算出点（x，y），
其中 x 坐标值双方都是一样的，前面说 ECDHE 算法时候，说 x 是会话密钥，但实际应用中，x 还不是最终的会话密钥。

还记得 TLS 握手阶段，客户端和服务端都会生成了一个随机数传递给对方吗？

最终的会话密钥，就是用「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料生成的。
之所以这么麻烦，是因为 TLS 设计者不信任客户端或服务器「伪随机数」的可靠性，为了保证真正的完全随机，
把三个不可靠的随机数混合起来，那么「随机」的程度就非常高了，足够让黑客计算不出最终的会话密钥，安全性更高。
算好会话密钥后，客户端会发一个「Change Cipher Spec」消息，告诉服务端后续改用对称算法加密通信。

接着，客户端会发「Encrypted Handshake Message」消息，
把之前发送的数据做一个摘要，再用对称密钥加密一下，让服务端做个验证，验证下本次生成的对称密钥是否可以正常使用。

* TLS 第四次握手
最后，服务端也会有一个同样的操作，发「Change Cipher Spec」和「Encrypted Handshake Message」消息，
* 如果双方都验证加密和解密没问题，那么握手正式完成。于是，就可以正常收发加密的 HTTP 请求和响应了。

#### RSA算法原理？

#### HTTPS密钥细节

#### http的报文格式 ，说几个头部
HTTP的请求报文由四部分组成：请求行(request line)、请求头部(header)、空行和请求数据(request data)

#### http和https的区别? https加密实现?

#### 数字证书有哪些？

#### 对称加密、非对称加密常用的算法

#### 浏览器访问服务器的流程

#### 三次握手、四次挥手、为什么四次



#### 在命令行ping网址的时候TTL是什么东西？ ping原理
#### 计算机网络

#### TCP拥塞控制

#### TCP连接建立后把网线拔了会怎么样，客户端会发生什么

### 在山区里信号很差用手机上网，没有彻底断开会发生什么，什么时候会发生重传

* HTTP各个版本 (1.0，1.1，2.0，3.0)
  --1.1 长连接、管道网络运输
  --2.0头部压缩HPACK算法、二进制格式、并发传输、服务器主动推送资源
  --3.0无队头阻塞、更快的链接建立、连接迁移

* HTTP2.0之前怎么实现服务器推送机制
* 是否了解过Websocket
* 保证TCP传输的可靠性的实现
  -序列号、确认应答、超时重传、拥塞控制、浏览控制
* 计算机网络五层模型
* http请求报文和响应报文包含了哪些

* https和http区别是什么
  --HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
  --HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
  --HTTP 的端口号是 80，HTTPS 的端口号是 443。
  --HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

* post请求了解吗其和get请求的区别是什么
  --GET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。
  --POST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。

#### 如何使得UDP可靠传输


* 问看没看过 tcp 源码，答：只看过协议首部

* tcp udp 区别
  -连接、服务对象、可靠性、拥塞控制和流量控制、首部开销、传输方式、分片不同

#### tcp timewait 作用
  --防止历史连接中的数据被后面相同的四元组接受
  --保证被动关闭连接能被正确关闭

#### 服务端上的timewait过多会产生什么问题？
* 占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等；
* 占用端口资源，端口资源也是有限的，一般可以开启的端口为 32768～61000，也可以通过 net.ipv4.ip_local_port_range参数指定范围。
客户端和服务端 TIME_WAIT 过多，造成的影响是不同的。
如果客户端（主动发起关闭连接方）的 TIME_WAIT 状态过多，占满了所有端口资源，
* 那么就无法对「目的 IP+ 目的 PORT」都一样的服务器发起连接了，
* 但是被使用的端口，还是可以继续对另外一个服务器发起连接的。
因此，客户端（发起连接方）都是和「目的 IP+ 目的 PORT 」都一样的服务器建立连接的话，
* 当客户端的 TIME_WAIT 状态连接过多的话，就会受端口资源限制，如果占满了所有端口资源，那么就无法再跟「目的 IP+ 目的 PORT」都一样的服务器建立连接了。
不过，即使是在这种场景下，只要连接的是不同的服务器，端口是可以重复使用的，所以客户端还是可以向其他服务器发起连接的，
* 这是因为内核在定位一个连接的时候，是通过四元组（源IP、源端口、目的IP、目的端口）信息来定位的，并不会因为客户端的端口一样，而导致连接冲突。

如果服务端（主动发起关闭连接方）的 TIME_WAIT 状态过多，并不会导致端口资源受限，
因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等


#### 有什么办法避免timewait过多？如何优化 TIME_WAIT？
* 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；
* net.ipv4.tcp_max_tw_buckets
* 程序中使用 SO_LINGER ，应用强制使用 RST 关闭。
* net.ipv4.tcp_tw_reuse 和 tcp_timestamps

如下的 Linux 内核参数开启后，则可以复用处于 TIME_WAIT 的 socket 为新的连接所用。

有一点需要注意的是，tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，
在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用。
net.ipv4.tcp_tw_reuse = 1
使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持，即

net.ipv4.tcp_timestamps=1（默认即为 1）
这个时间戳的字段是在 TCP 头部的「选项」里，它由一共 8 个字节表示时间戳，其中第一个 4 字节字段用来保存发送该数据包的时间，
第二个 4 字节字段用来保存最近一次接收对方发送到达数据的时间。

由于引入了时间戳，我们在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。

* net.ipv4.tcp_max_tw_buckets

这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置，这个方法比较暴力。

* ：程序中使用 SO_LINGER

我们可以通过设置 socket 选项，来设置调用 close 关闭连接行为。

struct linger so_linger;
so_linger.l_onoff = 1;
so_linger.l_linger = 0;
setsockopt(s, SOL_SOCKET, SO_LINGER, &so_linger,sizeof(so_linger));
* 如果l_onoff为非 0， 且l_linger值为 0，那么调用close后，会立该发送一个RST标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了TIME_WAIT状态，直接关闭。
但这为跨越TIME_WAIT状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。
#### 为什么 TIME_WAIT 等待的时间是 2MSL？
MSL 是 Maximum Segment Lifetime，**报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃**。
因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，
当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。
MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。
**所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。**
TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，
如果超过了，就认为报文已经消失在网络中了。

TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 
网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。
比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 FIN 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方，
一来一去正好 2 个 MSL。
**可以看到 2MSL时长 这其实是相当于至少允许报文丢失一次。**
比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。
为什么不是 4 或者 8 MSL 的时长呢？
你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。
2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。
如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。

在 Linux 系统里 2MSL 默认是 60 秒，那么一个 MSL 也就是 30 秒。Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒。
#### tcp 粘包拆包和解决思路

* https可以防止DNS劫持吗？

#### HTTP中POST和GET的区别
get是获取数据，post是修改数据
get把请求的数据放在url上， 以?分割URL和传输数据，参数之间以&相连，所以get不太安全。而post把数据放在HTTP的包体内（requrest body）

get提交的数据最大是2k（ 限制实际上取决于浏览器）， post理论上没有限制。

GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200(返回数据);
POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)。

GET请求会被浏览器主动缓存，而POST不会，除非手动设置。

本质区别：GET是幂等的，而POST不是幂等的

这里的幂等性：幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。
，所以不应该且不能用get请求做数据的增删改这些有副作用的操作。
因为get请求是幂等的，在网络不好的隧道中会尝试重试。
如果用get请求增数据，会有重复操作的风险，而这种重复操作可能会导致副作用（浏览器和操作系统并不知道你会用get请求去做增操作）。

#### GET 方法的长度限制是怎么回事？
网络上都会提到浏览器地址栏输入的参数是有限的。
首先说明一点，HTTP 协议没有 Body 和 URL 的长度限制，对 URL 限制的大多是浏览器和服务器的原因。
浏览器原因就不说了，服务器是因为处理长 URL 要消耗比较多的资源，为了性能和安全（防止恶意构造长 URL 来攻击）考虑，会给 URL 长度加限制。

#### POST 方法比 GET 方法安全？
有人说POST 比 GET 安全，因为数据在地址栏上不可见。
然而，从传输的角度来说，他们都是不安全的，因为 HTTP 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文。
要想安全传输，就只有加密，也就是 HTTPS。

#### POST 方法会产生两个 TCP 数据包？你了解吗？
有些文章中提到，POST 会将 header 和 body 分开发送，先发送 header，服务端返回 100 状态码再发送 body。
HTTP 协议中没有明确说明 POST 会产生两个 TCP 数据包，而且实际测试(Chrome)发现，header 和 body 不会分开发送。
所以，header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为

#### 输入一个 url 回车到获得响应，经过哪些层，分别涉及什么协议？


* Https流程

#### Https如何防止篡改(数字签名)

#### 三次握手建立起来的连接，在操作系统层面表现的是什么？


#### 499
* HTTP 请求在指定的时间内没能拿到响应而关闭了连接，就会发生 Nginx 记录 499 错误的情况



#### udp和connect和tcp的connect有什么区别
#### 五元组是哪五元？

* Udp和tcp的区别？旨在让我回答第一个问题，而不是单纯问八股

* 为什么udp没有connect？一步步引导……
   我们知道UDP是无连接的，它可以给多个IP发送数据包，包括广播地址或者多播通信的实现，而这些是TCP/IP无法实现的。
   但是UDP提供了这样的一个connect（）方法，它有两种使用方式，当使用了这个方法之后，那么就限定了这个socket的使用范围：
* 只允许从这个指定的SocketAddress 上获得数据包和向这个指定的SocketAddress 发送数据包， 当你一旦通过这个socket向别的地址发送了数据包，或者接收到了不是这个地址发送来的数据包，那么程序就会抛出IllegalArgumentException 异常， 特殊的是如果指定的这个SocketAddress 是个多播地址或者广播地址，那么只允许向这个地址发送数据包，不允许从这个地址接收数据包。

// SocketAddress 其实就是IP地址+端口号 ， 而InetAddress 只有IP地址
connect(InetAddress address, int port)
connect(SocketAddress addr)

UDP通过这样的方式，限定了单向的通信，但是注意的是，这里的限定只是仅限于一方，而并没有限制另外一方，另外一方依旧是可以向多个IP地址发送数据包的，因此这和TCP/IP 是极大的不同。TCP/IP的connect()是要有一个三次握手的过程的，而UDP的connect显然没有，它只是将IP地址和端口号进行了存储，对要进行通信的对象做了一个限制。
而且 TCP/IP的connect()只可以进行一次，但是UDP的connect()可以调用多次， 每次重新调用connect(SocketAddress )，就是将原来限制通信的对象修改为新的这个地址的对象， 
或者调用disConnect() 方法，就会解除对通信对象的限制，这样这个socket就又可以多向的通信了。

当我们进行UDP通信的对象只有一个时，建议使用connect()方法，使用了这个方法之后有一个极大的好处：
当我们使用了connect(SocketAddress addr) 方法时，那么在socket对象里面就会将发送方的地址设置为此地址，
那么发送的数据包对象就不用显式的标明 IP地址和 Port ，这样在调用send（packet）方法时，就不会对数据包再进行 IP地址和Port的安全检查，要发送的数据包少时优势体现不出来，但是当数据包多时，可以节省大量的时间。
* 除了sendto、send，还有什么api实现传输？Write

* Fork一个进程的整个过程

* 两个进程管道通信的详细描述

* Fork出来的进程和原来进程是同一块地址映射，怎么样做到子进程更改不影响父进程

* 网络路由转发的过程

* 两个单独的机房怎么实现通信

* 隧道了解吗？隧道协议等一系列巴拉巴拉

#### 观察者模式了解吗？
   观察者模式（又被称为发布-订阅（Publish/Subscribe）模式，属于行为型模式的一种
* 它定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。
* 这个主题对象在状态变化时，会通知所有的观察者对象，使他们能够自动更新自己。

#### TCP协议三次握手，如果第二三次握手失败了会怎么样？
#### 第一次握手丢失了，会发生什么？
当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，然后进入到 SYN_SENT 状态。
在这之后，如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），
* 就会触发「超时重传」机制，重传 SYN 报文，而且重传的 SYN 报文的序列号都是一样的。
* 当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，然后断开 TCP 连接。
#### 如果第二次握手丢了，就会发生比较有意思的事情，具体会怎么样呢？
因为第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，
* 那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是客户端就会触发超时重传机制，重传 SYN 报文。

然后，因为第二次握手中包含服务端的 SYN 报文，所以当客户端收到后，需要给服务端发送 ACK 确认报文（第三次握手）
，服务端才会认为该 SYN 报文被客户端收到了。
那么，如果第二次握手丢失了，服务端就收不到第三次握手，于是服务端这边会触发超时重传机制，重传 SYN-ACK 报文。

#### 第三次握手丢失了，会发生什么？
客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 ESTABLISH 状态。
因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，
如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。



### 第一次挥手丢失了，会发生什么？
当客户端（主动关闭方）调用 close 函数后，就会向服务端发送 FIN 报文，试图与服务端断开连接，此时客户端的连接进入到 FIN_WAIT_1 状态。
正常情况下，如果能及时收到服务端（被动关闭方）的 ACK，则会很快变为 FIN_WAIT2状态。

如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，
重传 FIN 报文，重发次数由 tcp_orphan_retries 参数控制。

当客户端重传 FIN 报文的次数超过 tcp_orphan_retries 后，就不再发送 FIN 报文，
则会在等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到第二次挥手，那么直接进入到 close 状态。

* 客户端收到第二次挥手，也就是收到服务端发送的 ACK 报文后，客户端就会处于 FIN_WAIT2 状态，
* 在这个状态需要等服务端发送第三次挥手，也就是服务端的 FIN 报文。

#### 第二次挥手丢失了，会发生什么？
当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 CLOSE_WAIT 状态。

在前面我们也提了，ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文
直到收到服务端的第二次挥手，或者达到最大的重传次数。

对于 close 函数关闭的连接，由于无法再发送和接收数据，所以FIN_WAIT2 状态不可以持续太久，
而 tcp_fin_timeout 控制了这个状态下连接的持续时长，默认值是 60 秒。

这意味着对于调用 close 关闭的连接，如果在 60 秒后还没有收到 FIN 报文，客户端（主动关闭方）的连接就会直接关闭

* 如果主动关闭方使用 shutdown 函数关闭连接，指定了只关闭发送方向，而接收方向并没有关闭，那么意味着主动关闭方还是可以接收数据的。

此时，如果主动关闭方一直没收到第三次挥手，那么主动关闭方的连接将会一直处于 FIN_WAIT2 状态（tcp_fin_timeout 无法控制 shutdown 关闭的连接）。

#### 第三次挥手丢失了，会发生什么？
当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，
同时连接处于 CLOSE_WAIT 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。

此时，内核是没有权利替代进程关闭连接，必须由进程主动调用 close 函数来触发服务端发送 FIN 报文。

服务端处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭。

如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，
这与客户端重发 FIN 报文的重传次数控制方式是一样的。

#### 当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 TIME_WAIT 状态。

在 Linux 系统，TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。

然后，服务端（被动关闭方）没有收到 ACK 报文前，还是处于 LAST_ACK 状态。

如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制。



#### TCP服务端一直没用收到数据之后的状态变化

#### http和rpc的区别？

#### http和rpc分别运行的协议，http和rpc的序列化？

#### 三次握手，为什么三次，第一次和第二次握手能不能携带数据，为什么

#### 长连接和短连接，长连接中的链路检测机制

#### TCP粘包和拆包
粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。

一般有三种方式分包的方式：

固定长度的消息；
特殊字符作为边界；
自定义消息结构。
* 固定长度的消息
  这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。
  但是这种方式灵活性不高，实际中很少用。

* 特殊字符作为边界
  我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。
  HTTP 是一个非常好的例子。
  HTTP 通过设置回车符、换行符作为 HTTP 报文协议的边界。
  有一点要注意，这个作为边界点的特殊字符，如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。

* 自定义消息结构
  我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。
  比如这个消息结构体，首先 4 个字节大小的变量来表示数据长度，真正的数据则在后面。
```
struct {
    u_int32_t message_length;
    char message_data[];
} message;
```
当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。
* 拆包：一个完整的业务可能会被TCP拆分成多个包进行发送

* 粘包：也有可能把多个小的包封装成一个大的数据包发送
#### 原因
* 应用程序写入数据的字节大小大于套接字发送缓冲区的大小.
* 进行MSS大小的TCP分段。( MSS=TCP报文段长度-TCP首部长度)
* 以太网的payload大于MTU进行IP分片。（ MTU指：一种通信协议的某一层上面所能通过的最大数据包大小。）

#### 解决方案
* 消息定长。
* 在包尾部增加回车或者空格符等特殊字符进行分割
* 将消息分为消息头和消息尾
* 使用其它复杂的协议，如RTMP协议等。

#### HTTP2.0与HTTP3.0的区别？
这次主要介绍了关于 HTTP/2 是如何提升性能的几个方向，它相比 HTTP/1 大大提高了传输效率、吞吐能力。
* 对于常见的 HTTP 头部通过静态表和 Huffman 编码的方式，将体积压缩了近一半，而且针对后续的请求头部，还可以建立动态表，
将体积压缩近 90%，大大提高了编码效率，同时节约了带宽资源。
* 动态表并非可以无限增大， 因为动态表是会占用内存的，动态表越大，内存也越大，容易影响服务器总体的并发能力，
* 因此服务器需要限制 HTTP/2 连接时长或者请求次数。
* HTTP/2 实现了 Stream 并发，多个 Stream 只需复用 1 个 TCP 连接，节约了 TCP 和 TLS 握手时间，
* 以及减少了 TCP 慢启动阶段对流量的影响
* 。不同的 Stream ID 可以并发，即使乱序发送帧也没问题，比如发送 A 请求帧1-> B 请求帧1-> A 请求帧2 -> B 请求帧2，
* 但是同一个 Stream 里的帧必须严格有序。

另外，可以根据资源的渲染顺序来设置 Stream 的优先级，从而提高用户体验。

* 服务器支持主动推送资源，大大提升了消息的传输性能，服务器推送资源时，会先发送 PUSH_PROMISE 帧，
* 告诉客户端接下来在哪个 Stream 发送资源，然后用偶数号 Stream 发送资源给客户端。
HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。
HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。


#### 基于QUIC的0RTT怎么实现的？
* TLSv1.3 还有个更厉害到地方在于会话恢复机制，在重连 TLvS1.3 只需要 0-RTT，
* 用“pre_shared_key”和“early_data”扩展，在 TCP 连接后立即就建立安全连接发送加密消息

* QUIC怎么实现可靠传输？

* QUIC发生丢包重传后包序号跟偏移量？

* TCP的timewati与close wait产生原因是什么？

select语句的存储引擎执行过程

#### 服务器挂掉了，客户端会怎么做
* 如果「客户端进程崩溃」，客户端的进程在发生崩溃的时候，内核会发送 FIN 报文，与服务端进行四次挥手。
但是，「客户端主机宕机」，那么是不会发生四次挥手的，具体后续会发生什么？还要看服务端会不会发送数据？
如果服务端会发送数据，由于客户端已经不存在，收不到数据报文的响应报文，服务端的数据报文会超时重传，
* 当重传总间隔时长达到一定阈值（内核会根据 tcp_retries2 设置的值计算出一个阈值）后，会断开 TCP 连接；
如果服务端一直不会发送数据，再看服务端有没有开启 TCP keepalive 机制？
如果有开启，服务端在一段时间没有进行数据交互时，会触发 TCP keepalive 机制，探测对方是否存在，
* 如果探测到对方已经消亡，则会断开自身的 TCP 连接；
如果没有开启，服务端的 TCP 连接会一直存在，并且一直保持在 ESTABLISHED 状态。


tcp三次握手和accept函数
虚拟内存、请求调页的具体过程
#### 继续往下说网络层怎么转发数据包
#### arp地址解析用到了吗，路由器转发出去，这个mac地址是谁的，怎么得到
#### 能不能静态arp（没答上去）
HTTPS RSA握手
HTTP3.0的特性，解释队头堵塞

（讲3.0的时候忘了提保持连接的特性）四元组标识TCP连接，那么对于QUIC而言，当四元组当中有一个东西变了需要重新建立连接吗？

#### TCP和UDP可以监听同一个端口吗？
讲一下select和epoll的区别和适用的场景。
你觉得对于服务器和客户端而言，支持的TCP连接数受到什么影响？
http请求头的一些参数：host,agent,ref


### 为什么seq要是随机值呢？

### 通常用什么来标识一个TCP连接？

### 一台机器到另外一台机器最多能有多少个TCP连接？



### 前后端分离时，cookie在什么情况下是有效的？
虽然我们可以在cookie中指定domain来解决,但是cookie必须针对性的设置作用域，这对于有多个不同域要共享cookie时,可操作性差,难以维护。
#### 前后端分离的状态如何维护？（jwt）
在传统的项目中我们利用,session+cookie来保持用户的登录状态,但这在前后端分离项⽬目中出现了问题
sessionid是使用cookie存储在客户端的,而cookie遵守同源策略,只在同源的请求中有效,这就导致了问题出现
前后端分离后静态资源完全可能(而且经常…)部署到另一个域下,导致cookie失效。

JWT可以对用户信息进行加密生成一个字符串,下发到客户端,客户端在后续请求中携带该字符串,
服务器解析后取出用户信息,从而完成用户身份的识别

#### jwt在前后端交互过程中通常被存储在哪里？在传输过程中是存放在什么中传输？（HTTP的header中）
token对比session
这种基于token的认证方式相比传统的session认证方式更节约服务器资源，并且对移动端和分布式更加友好。其优点如下：
**支持跨域访问：cookie是无法跨域的，而token由于没有用到cooki**e(前提是将token放到请求头中)，所以跨域后不会存在信息丢失问题
**无状态：token机制在服务端不需要存储session信息，因为token自身包含了所有登录用户的信息，所以可以减轻服务端压力**
更适用CDN：可以通过内容分发网络请求服务端的所有资料
**更适用于移动端：当客户端是非浏览器平台时，cookie是不支持的，采用token认证方式会简单很多**
**无需考虑CSRF：由于不再依赖cookie，所以采用token认证方式不会发生CSRF，所以也就无需考虑CSRF的防御**

* jwt是token的一种实现方式，它将用户信息加密到token里，服务器不保存任何用户信息。
  服务器通过使用保存的密钥验证token的正确性，只要正确即通过验证。
* 可以通过URL、POST参数或者在HTTP header发送，因为数据量小，传输速度也很快
* 
  四次挥手 2msl 为什么不是1msl或者3msl？