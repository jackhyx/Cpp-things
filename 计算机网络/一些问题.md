#### MTU和MSS分别是什么？
* MTU：maximum transmission unit，最大传输单元，由硬件规定，如以太网的MTU为1500字节。
* MSS：maximum segment size，最大分节大小，为TCP数据包每次传输的最大数据分段大小，一般由发送端向对端TCP通知对端在每个分节中能发送的最大TCP数据
* MSS值为MTU值减去IPv4 Header（20 Byte）和TCP header（20 Byte）得到。


#### 什么是TCP粘包/拆包？发生的原因？
* 拆包：一个完整的业务可能会被TCP拆分成多个包进行发送
* 粘包：也有可能把多个小的包封装成一个大的数据包发送
#### 原因
* 应用程序写入数据的字节大小大于套接字发送缓冲区的大小.
* 进行MSS大小的TCP分段。( MSS=TCP报文段长度-TCP首部长度)
* 以太网的payload大于MTU进行IP分片。（ MTU指：一种通信协议的某一层上面所能通过的最大数据包大小。）

#### 解决方案
* 消息定长。
* 在包尾部增加回车或者空格符等特殊字符进行分割
* 将消息分为消息头和消息尾
* 使用其它复杂的协议，如RTMP协议等。

#### 为什么服务器会有 # 缓存 #这一项功能？如何实现的？
* 缓解服务器压力；
* 降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快
并且缓存服务器在地理位置上也有可能比源服务器来得近，例如# 浏览器缓存。
#### 实现方法
* 让代理服务器进行缓存；
* 让客户端浏览器进行缓存。

#### HTTP请求方法你知道多少？

* 客户端发送的# 请求报文 # 第一行为 # 请求行 #包含了方法字段。

根据 HTTP 标准，HTTP 请求可以使用多种请求方法。

* HTTP1.0 定义了三种请求方法： GET, POST 和 HEAD方法。
* GET	请求指定的页面信息，并返回实体主体。
* HEAD	类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头
* POST	向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。

#### HTTP1.1 新增了六种请求方法：OPTIONS、PUT、PATCH、DELETE、TRACE 和 CONNECT 方法。

序 号	方法	描述
1	GET	请求指定的页面信息，并返回实体主体。
2	HEAD	类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头
3	POST	向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。
4	PUT	从客户端向服务器传送的数据取代指定的文档的内容。
5	DELETE	请求服务器删除指定的页面。
6	CONNECT	HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。
7	OPTIONS	允许客户端查看服务器的性能。
8	TRACE	回显服务器收到的请求，主要用于测试或诊断。
9	PATCH	是对 PUT 方法的补充，用来对已知资源进行局部更新 。

####HTTPS和HTTP的区别
* http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
* HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全
* HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。
* https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。 

#### HTTPS是如何保证数据传输的安全，整体的流程是什么？（SSL是怎么工作保证安全的）
SSL/TLS协议的基本思路是采用 # 公钥加密法 #
客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。
* 客户端向服务器端发起SSL连接请求；
* 服务器把公钥发送给客户端，并且服务器端保存着唯一的私钥
* 客户端用公钥对双方通信的对称秘钥进行加密，并发送给服务器端
* 服务器利用自己唯一的私钥对客户端发来的对称秘钥进行解密

* 进行数据传输，服务器和客户端双方用公有的相同的对称秘钥对数据进行加密解密，可以保证在数据收发过程中的安全，即是第三方获得数据包，也无法对其进行加密，解密和篡改。
* 因为数字签名、摘要是证书防伪非常关键的武器。
* “摘要”就是对传输的内容，通过hash算法计算出一段固定长度的串。然后，通过发送方的私钥对这段摘要进行加密，加密后得到的结果就是“数字签名”

#### 什么是RARP？工作原理
概括： 反向地址转换协议，网络层协议，RARP与ARP工作方式相反
RARP: 知道自己硬件地址的主机能够知道其IP地址。RARP发出要反向解释的物理地址并希望返回其IP地址，应答包括能够提供所需信息的RARP服务器发出的IP地址
#### 原理：
##网络上的每台设备都会有一个独一无二的硬件地址，通常是由设备厂商分配的MAC地址
主机从网卡上读取MAC地址，然后在网络上发送一个RARP请求的广播数据包，请求RARP服务器回复该主机的IP地址。
* RARP服务器收到了RARP请求数据包，为其分配IP地址，并将RARP回应发送给主机。
* PC1收到RARP回应后，就使用得到的IP地址进行通讯。

#### 端口有效范围是多少到多少？
* 0-1023为知名端口号，比如其中HTTP是80，FTP是20（数据端口）、21（控制端口）
UDP和TCP报头使用两个字节存放端口号，所以端口号的有效范围是从0到65535
* 动态端口的范围是从1024到65535

#### 为何需要把 TCP/IP 协议栈分成 5 层（或7层）？开放式回答。
* ARPANET 的研制经验表明，对于复杂的计算机网络协议，其结构应该是层次式的。

#### 分层的好处：

* 隔层之间是独立的
* 灵活性好
* 结构上可以分隔开
* 易于实现和维护
* 能促进标准化工作。

#### HTTP中缓存的私有和公有字段？知道吗？
private 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在# 用户浏览器中 #
Cache-Control: private

public 指令规定了将资源作为公共缓存，可以被多个用户使用，一般存储在# 代理服务器中 #
Cache-Control: public

#### GET 方法参数写法是固定的吗？
在约定中，我们的参数是写在 ? 后面，用 & 分割。
我们知道，解析报文的过程是通过获取 TCP 数据，用正则等工具从数据中获取 Header 和 Body，从而提取参数。
比如header请求头中添加token，来验证用户是否登录等权限问题。
也就是说# 我们可以自己约定参数的写法，只要服务端能够解释出来就行，万变不离其宗 #

#### GET 方法的长度限制是怎么回事？
网络上都会提到浏览器地址栏输入的参数是有限的。

首先说明一点# HTTP 协议没有 Body 和 URL 的长度限制，对 URL 限制的大多是浏览器和服务器的原因# 
浏览器原因就不说了，服务器是因为处理长 URL 要消耗比较多的资源，为了性能和安全（防止恶意构造长 URL 来攻击）考虑，会给 URL 长度加限制。

#### POST 方法比 GET 方法安全？
有人说POST 比 GET 安全，因为数据在地址栏上不可见。
然而，从传输的角度来说，他们都是不安全的，因为 HTTP 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文。
要想安全传输，就只有加密，也就是 HTTPS。

#### POST 方法会产生两个 TCP 数据包？你了解吗？
有些文章中提到# POST 会将 header 和 body 分开发送，先发送 header，服务端返回 100 状态码再发送 body #
HTTP 协议中没有明确说明 POST 会产生两个 TCP 数据包，而且实际测试(Chrome)发现，header 和 body 不会分开发送。
所以，header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为。


#### UDP的特点
UDP是无连接的；
UDP使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）；
UDP是面向报文的；
UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）；
UDP支持一对一、一对多、多对一和多对多的交互通信；
UDP的首部开销小，只有8个字节，比TCP的20个字节的首部要短。

####  TCP的特点
TCP是面向连接的。
每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）；
TCP提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达；
TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据
TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；
面向字节流。TCP中的“流”（stream）指的是流入进程或从进程流出的字节序列。
“面向字节流”的含义是：虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。

####  UDP是面向报文的，发送方的UDP对应用层交下来的报文，不合并，不拆分，只是在其上面加上首部后就交给了下面的网络层
无论应用层交给UDP多长的报文，它统统发送，一次发送一个。
而对接收方，接到后直接去除首部，交给上面的应用层就完成任务了。
因此，它需要应用层控制报文的大小

#### TCP是面向字节流的，它把上面应用层交下来的数据看成无结构的字节流会发送，
发送方TCP会将数据放入“蓄水池”（缓存区），等到可以发送的时候就发送，不能发送就等着TCP会根据# 当前网络的拥塞状态来确定每个报文段的大小 #

####  封包和拆包你听说过吗？它是基于TCP还是UDP的？

封包和拆包都是基于TCP的概念。

* 因为TCP是无边界的流传输，所以需要对TCP进行封包和拆包，确保发送和接收的数据不粘连 

封包：封包就是在发送数据报的时候为每个TCP数据包加上一个包头，将数据报分为包头和包体两个部分# 包头是一个固定长度的结构体，里面包含该数据包的总长度 #
拆包：接收方在接收到报文后提取包头中的长度信息进行截取


#### TCP 协议如何保证可靠传输？

第一种回答
* 确认和重传：接收方收到报文就会确认，发送方发送一段时间后没有收到确认就会重传。
* 数据校验：TCP报文头有校验和，用于校验报文是否损坏。
## 数据合理分片和排序：tcp会按最大传输单元(MTU)合理分片，接收方会缓存未按序到达的数据，重新排序后交给应用层
而UDP：IP数据报大于1500字节，大于MTU。这个时候发送方的IP层就需要分片，把数据报分成若干片，是的每一片都小于MTU。而接收方IP层则需要进行数据报的重组
由于UDP的特性，某一片数据丢失时，接收方便无法重组数据报，导致丢弃整个UDP数据报。
*  流量控制：当接收方来不及处理发送方的数据，能通过滑动窗口，提示发送方降低发送的速率，防止包丢失。
*  拥塞控制：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失。

第二种回答
建立连接（标志位）：通信前确认通信实体存在。
序号机制（序号、确认号）：确保了数据是按序、完整到达。
数据校验（校验和）：CRC校验全部数据。

第三种回答
首部校验 这个校验机制能够确保数据传输不会出错吗？ 答案是不能。
原因
TCP协议中规定，TCP的首部字段中有一个字段是校验和，发送方将伪首部、TCP首部、TCP数据使用累加和校验的方式计算出一个数字
然后存放在首部的校验和字段里，接收者收到TCP包后重复这个过程，然后将计算出的校验和和接收到的首部中的校验和比较，如果不一致则说明数据在传输过程中出错。
这就是TCP的数据校验机制。 但是这个机制能够保证检查出一切错误吗？显然不能。
因为这种校验方式是累加和，也就是将一系列的数字（TCP协议规定的是数据中的每16个比特位数据作为一个数字）求和后取末位。
但是小学生都知道A+B=B+A，假如在传输的过程中有前后两个16比特位的数据前后颠倒了（至于为什么这么巧合？我不知道，也许路由器有bug？也许是宇宙中的高能粒子击中了电缆？反正这个事情的概率不为零，就有可能会发生），那么校验和的计算结果和颠倒之前是一样的，那么接收端肯定无法检查出这是错误的数据。

解决方案
传输之前先使用MD5加密数据获得摘要，跟数据一起发送到服务端，服务端接收之后对数据也进行MD5加密，如果加密结果和摘要一致，则认为没有问题

#### 你了解流量控制原理吗？
目的是接收方通过TCP头窗口字段告知发送方本方可接收的最大数据量，用以解决发送速率过快导致接收方不能接收的问题。所以流量控制是点对点控制。

TCP是双工协议，双方可以同时通信，所以发送方接收方各自维护一个发送窗和接收窗。

* 发送窗：用来限制发送方可以发送的数据大小，其中发送窗口的大小由接收端返回的TCP报文段中窗口字段来控制，接收方通过此字段告知发送方自己的缓冲（受系统、硬件等限制）大小。

* 接收窗：用来标记可以接收的数据大小。

TCP是流数据，发送出去的数据流可以被分为以下四部分：已发送且被确认部分 | 已发送未被确认部分 | 未发送但可发送部分 | 不可发送部分
其中发送窗 = 已发送未确认部分 + 未发但可发送部分
接收到的数据流可分为：已接收 | 未接收但准备接收 | 未接收不准备接收。接收窗 = 未接收但准备接收部分。

发送窗内数据只有当接收到接收端某段发送数据的ACK响应时才移动发送窗，左边缘紧贴刚被确认的数据。接收窗也只有接收到数据且最左侧连续时才移动接收窗口。

#### TCP四大拥塞控制算法总结？（极其重要）
四大算法
拥塞控制主要是四个算法：
* 慢启动
* 拥塞避免
* 拥塞发生
* 快速恢复
这四个算法不是一天都搞出来的，这个四算法的发展经历了很多时间，到今天都还在优化中。

慢热启动算法 – Slow Start
所谓慢启动，也就是TCP连接刚建立，一点一点地提速，试探一下网络的承受能力，以免直接扰乱了网络通道的秩序。
慢启动算法：
* 连接建好的开始先初始化拥塞窗口cwnd大小为1，表明可以传一个MSS大小的数据。
* 每当收到一个ACK，cwnd大小加一，呈线性上升。
* 每当过了一个往返延迟时间RTT(Round-Trip Time)，cwnd大小直接翻倍，乘以2，呈指数上升；
* 还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”

拥塞避免算法 – Congestion Avoidance
如同前边说的，当拥塞窗口大小cwnd大于等于慢启动阈值ssthresh后，就进入拥塞避免算法。算法如下：
* 收到一个ACK，则cwnd = cwnd + 1 / cwnd
* 每当过了一个往返延迟时间RTT，cwnd大小加一。

* 过了慢启动阈值后，拥塞避免算法可以避免窗口增长过快导致窗口拥塞，而是缓慢的增加，调整到网络的最佳值。

#### 拥塞发生状态时的算法
一般来说，TCP拥塞控制默认认为网络丢包是由于网络拥塞导致的，所以一般的TCP拥塞控制算法以丢包为网络进入拥塞状态的信号
* 对于丢包有两种判定方式
* 一种是超时重传RTO[Retransmission Timeout] # 
*  另一个是收到三个重复确认ACK #

* 超时重传是TCP协议保证数据可靠性的一个重要机制，其原理是在发送一个数据以后就开启一个计时器
在一定时间内如果没有得到发送数据报的ACK报文，那么就重新发送数据，直到发送成功为止 #

#### 但是如果发送端接收到3个以上的重复ACK，TCP就意识到数据发生丢失，需要重传
这个机制不需要等到重传定时器超时，所以叫做快速重传，而快速重传后没有使用慢启动算法，而是拥塞避免算法，所以这又叫做快速恢复算法。

超时重传RTO[Retransmission Timeout]，TCP会重传数据包。TCP认为这种情况比较糟糕，反应也比较强烈：

由于发生丢包，将慢启动阈值ssthresh设置为当前cwnd的一半，即ssthresh = cwnd / 2.
cwnd重置为1
进入慢启动过程
最为早期的TCP Tahoe算法就只使用上述处理办法，但是由于一丢包就一切重来，导致cwnd又重置为1，十分不利于网络数据的稳定传递。

所以，TCP Reno算法进行了优化。当收到三个重复确认ACK时，TCP开启快速重传Fast Retransmit算法，而不用等到RTO超时再进行重传：

cwnd大小缩小为当前的一半
ssthresh设置为缩小后的cwnd大小
然后进入快速恢复算法Fast Recovery。

#### 快速恢复算法 – Fast Recovery
TCP Tahoe是早期的算法，所以没有快速恢复算法，而Reno算法有。在进入快速恢复之前，cwnd和ssthresh已经被更改为原有cwnd的一半
快速恢复算法的逻辑如下：
cwnd = cwnd + 3 MSS，加3 MSS的原因是因为收到3个重复的ACK。
重传DACKs指定的数据包。
如果再收到DACKs，那么cwnd大小增加一。
如果收到新的ACK，表明重传的包成功了，那么退出快速恢复算法。将cwnd设置为ssthresh，然后进入拥塞避免算法。
如图所示，第五个包发生了丢失，所以导致接收方接收到三次重复ACK，也就是ACK5
所以将ssthresh设置当当时cwnd的一半，也就是6/2 = 3，cwnd设置为3 + 3 = 6。然后重传第五个包
当收到新的ACK时，也就是ACK11，则退出快速恢复阶段，将cwnd重新设置为当前的ssthresh，也就是3，然后进入拥塞避免算法阶段。

#### 为何快速重传是选择3次ACK？

主要的考虑还是要区分包的丢失是由于## 链路故障还是乱序等其他因素引发 #

两次duplicated ACK时很可能是乱序造成的！三次duplicated ACK时很可能是丢包造成的
四次duplicated ACK更更更可能是丢包造成的，但是这样的响应策略太慢。丢包肯定会造成三次duplicated ACK!综上是选择收到三个重复确认时窗口减半效果最好，这是实践经验。

在没有fast retransmit / recovery 算法之前，重传依靠发送方的retransmit timeout，就是在timeout内如果没有接收到对方的ACK，默认包丢了，发送方就重传，包的丢失原因
1）包checksum 出错
2）网络拥塞
3）网络断，包括路由重收敛
但是发送方无法判断是哪一种情况，于是采用最笨的办法，就是将自己的发送速率减半，即CWND 减为1/2，这样的方法对2是有效的，可以缓解网络拥塞
3则无所谓，反正网络断了，无论发快发慢都会被丢
但对于1来说，丢包是因为偶尔的出错引起，一丢包就对半减速不合理。

#### 于是有了fast retransmit 算法，基于在反向还可以接收到ACK，可以认为网络并没有断

否则也接收不到ACK，如果在timeout 时间内没有接收到> 2 的duplicated ACK，则概率大事件为乱序，乱序无需重传，接收方会进行排序工作；

#而如果接收到三个或三个以上的duplicated ACK，则大概率是丢包
可以逻辑推理，发送方可以接收ACK，则网络是通的，可能是1、2造成的，先不降速，重传一次，如果接收到正确的ACK，则一切OK，流速依然（包出错被丢）。
#而如果依然接收到duplicated ACK，则认为是网络拥塞造成的，此时降速则比较合理。

超时重传（定时器）：保证因链路故障未能到达数据能够被多次重发。
窗口机制（窗口）：提供流量控制，避免过量发送。
拥塞控制：同上。

#### 网络层常见协议？可以说一下吗？
协议	名称	作用
* IP	网际协议	IP协议不但定义了# 数据传输时的基本单元和格式，还定义了数据报的递交方法和路由选择 # 
* ICMP	Internet控制报文协议	ICMP就是一个“错误侦测与回报机制”，其目的就是让我们能够检测网路的连线状况﹐也能确保连线的准确性，是ping和traceroute的工作协议
* RIP	路由信息协议	使用“跳数”(即metric)来衡量到达目标地址的路由距离
* IGMP	Internet组管理协议	用于实现组播、广播等通信

#### 应用层常见协议知道多少？了解几个？
协议	名称	默认端口	底层协议
*  HTTP	超文本传输协议	80	TCP
*  HTTPS	超文本传输安全协议	443	TCP
* Telnet	远程登录服务的标准协议	23	TCP
* FTP	文件传输协议	20传输和21连接	TCP
* TFTP	简单文件传输协议	69	UDP
* SMTP	简单邮件传输协议（发送用）	25	TCP
* POP	邮局协议（接收用）	110	TCP
* DNS	域名解析服务	53	服务器间进行域传输的时候用TCP
* 客户端查询DNS服务器时用 UDP
