### 同步异步 vs 阻塞非阻塞
* 同步：调用发出后，等待结果返回
* 异步：调用发出后，可以做别的，等待处理完通知（回调通知获取结果
* 阻塞：调用结果返回前，挂起线程
* 非阻塞：调用结果返回前，不阻塞线程，每隔一段时间检测，没有就绪就做别的
  同步、异步：是否需要内核空间到用户空间的拷贝
  阻塞、非阻塞：是否需要等待所需的I/O存在

### 同步 互斥

互斥解决了并发进程/线程对临界区的使用问题。
这种基于临界区控制的交互作用是比较简单的，**只要一个进程/线程进入了临界区，
其他试图想进入临界区的进程/线程都会被阻塞着，直到第一个进程/线程离开了临界区。**
互斥：对资源竞争，彼此不知道对方的存在，执行顺序乱序
同步：协调多个相互关联线程合作完成任务，彼此知道对方存在；执行顺序往往有序
所谓同步，就是并发进程/线程在一些关键点上**可能需要互相等待与互通消息**，这种相互制约的等待与互通信息称为进程/线程同步。
为了实现进程/线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：

锁：加锁、解锁操作；
信号量：P、V 操作；
在单处理器上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。
否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。

PV 操作的函数是由操作系统管理和实现的，所以操作系统已经使得执行 PV 函数时是具有原子性的。
为每类共享资源设置一个信号量 s，其初值为 1，表示该临界资源未被占用。
只要把进入临界区的操作置于 P(s) 和 V(s) 之间，即可实现进程/线程互斥：


### 用户态 内核态
用户态：CPU受限的访问内存（只能访问用户空间），不允许访问外围设备，不允许独占；
内核态：CPU可以访问任意数据，CPU可以从一个程序切换到另一个程序，占用CPU不会发生抢占 特权级0
进程的切换只能发生在内核态

### 用户态->内核态
系统调用
异常
外中断

### 中断处理过程的五个阶段：
1、中断请求阶段；
2、中断判优阶段，有硬件判优和软件判优两种方法；
3、中断响应阶段，CPU向中断源发出中断响应信号；
4、中断服务阶段；
5、中断返回阶段，返回到原程序的断点处，恢复硬件现场，继续执行原程序
### 外中断 vs 异常
外中断：CPU执行指令的外部事件（输入输出、时钟中断
异常：CPU执行指令的内部时间（地址越界溢出

### CPU中断？
定义：系统内发生了急需处理的事件，CPU转去处理相应的处理程序，处理完毕后返回中断处继续执行
作用：系统及时响应外部事件，多个外设同时工作，提高了CPU利用率；处理硬件故障

### 一个程序从开始到可执行文件？
预编译：处理#开头的内容
编译：词法分析，语法分析，语义分析 x.c->x.i
汇编：汇编指令翻译成机器码 x.i->x.o
链接：目标文件链接成可执行程序 x.o->可执行

### 静态链接 vs 动态链接

编译链接时将代码拷贝到调用处   不直接拷贝代码，需要的时候加载到内存，多个程序调用一个时共享内存
运行速度块 多个程序共享一段代码
浪费空间 更新困难  运行时加载 速度慢

### 进程 线程 协程
进程：运行中的程序
* 就绪->运行：被OS的进程调度器选中， 分配CPU时间片
* 运行->就绪：时间片用完
虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。
挂起状态：进程没有占用实际的物理内存空间的状态
阻塞状态：阻塞状态是等待某个事件的返回。
另外，挂起状态可以分为两种：
阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；
* PCB：进程控制块 进程存在的唯一标识 通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列
* cpu上下文：cpu寄存器、程序计数器：存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置
* 进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源
* 进程上下文切换场景：
时间片耗尽
系统资源不足
sleep主动挂起
更高优先级进程
硬件中断

进程：资源分配的最小单位 私有地址空间 私有堆栈 上下文切换需要切换虚拟地址空间

线程：资源调度的基本单位 共有地址空间 公有堆 私有栈 上下文切换只需要切换少量寄存器

同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源
但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立
优点：一个进程存在多个线程；各个线程并发执行；共享地址空间和文件等资源
缺点：进程中一个线程崩溃，导致所有线程崩溃；
### 线程是调度的基本单位，而进程则是资源拥有的基本单位。

### 线程 vs 进程

进程：资源分配的单位， 线程：资源调度的基本单位，CPU调度的单位
完整的资源平台    独享：栈 寄存器
线程创建块，切换块，同一个页表，共享内存和文件资源
线程上下文切换的是什么？
当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；
当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；

### 用户线程：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；
整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。
优点：TCB线程控制块，跟踪记录线程状态信息，用户级线程库函数维护，可用于不支持线程技术的操作系统；
线程切换也有线程库函数完成，无需用户态和内核切换

缺点：线程运行后，除非主动交出CPU使用权，否则其他线程无法运行。

### 内核线程
由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。
### 轻量级进程（Light-weight process，LWP）是内核支持的用户线程

非抢占式调度算法挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，
就是说不会理时钟中断这个事情。
抢占式调度算法挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，
接着调度程序从就绪队列挑选另外一个进程。
这种抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把 CPU 控制返回给调度程序进行调度，也就是常说的时间片机制。
调度原则：
CPU利用率，系统吞吐率，周转时间，等待时间，响应时间


协程：用户态轻量线程 上下文切换有开发者决定

### 为什么有？
进程：提升CPU利用率
线程：进程上下文切换开销大 切换虚拟地址空间 切换内核栈和硬件上下文 导致TLB失效 
线程共享资源节省空间（ 共享堆 地址空间 全局变量 静态变量； 私有栈，寄存器，程序计数器）
协程：**线程是抢占式任务**，有操作系统控制，不知道什么时候被抢走，需要加锁；
协程是异步机制，需要代码编写者主动让出控制权，不需要上下文切换

### 为什么虚拟地址切换耗时（为什么线程比进程切换块
把虚拟地址映射成物理地址需要页表，页表查找慢，用TLB缓存地址映射加速
每个进程有自己的虚拟空间，进程有自己的页表，切换时页表也发生切换TLB失效，缓存命中率底，查找慢，程序运行慢

### 进程状态切换？
就绪->运行：调度算法选择
运行->就绪：时间片用完
运行->阻塞：发生等待时间进入阻塞
阻塞->就绪：等待时间已经发生

### 进程切换场景：
进度调用时间片被耗尽，系统挂起
系统资源不足，等满足后再运行
睡眠函数主动挂起
更高优先级的进程需要运行
硬件中断，当前进程挂起

### 进程间通信
int pipe(int fd[2])
内核里面的一串缓存

* 匿名管道：内核中的一段缓存，单向，半双工 父子关系进程 效率底，容量有限
* 有名管道：半双工 不相关的进程也可以相互通信 mkfifo
* 共享内存：不同进程拿出一段地址空间，映射到相同物理地址，效率最高，同时修改存在冲突
* 消息队列：消息链表: 消息队列是保存在内核中的消息链表
消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在
而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。
消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制
消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销
* 信号量：整型计数器，进程间互斥和同步PV操作 原子操作
P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。
信号初始化为 1，就代表着是互斥信号量
信号初始化为 0，就代表着是同步信号量
* 信号：通知某个事件已经发生，异步通信 SIGCLD 子进程退出SIGKILL用户终止进程
* 对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。
信号是进程间通信机制中唯一的异步通信机制 默认操作、捕捉信号、忽略信号
套接字：不同主机进程间通信
int socket(int domain, int type, int protocal)
* domain 参数用来指定协议族
* type 参数用来指定通信特性
* protocal 参数原本是用来指定通信协议的，但现在基本废弃
### 进程内存布局
地址高--->低
栈
文件映射区
堆
bss段未初始化的全局变量
数据段 初始化的全局变量、静态变量
代码段：常量，二进制代码

### 有了进程，为什么还需要线程
进程切换开销大，线程切换仅需要保存和设置少量寄存器内容
适合高并发
节省空间：线程共享地址空间和堆等资源 无需拷贝
节省事件：进程切换需要切换虚拟内存，使TLB失效，

### 线程通信
共享内存、消息传递、管道流

### 线程崩溃会怎么样？
线程崩溃触发segment fault 触发信号SIGSEGV
不屏蔽信号，所有线程崩溃
屏蔽信号，线程私有栈，崩溃位置是栈，屏蔽后不影响其他线程
线程共有堆、全局变量，崩溃位置是堆、全局变量，屏蔽后崩溃影响其他线程

### 为什么有协程？
现有协程->进程->线程
线程：抢占式任务，操作系统控制，不知道什么时候被抢走，要加锁，同步
协程：代码编写者主动让出控制全，无需操作系统内核上下文切换，用户态，不加锁，异步

### 孤儿进程 僵尸进程 守护进程
原因：子进程 有父进程创建，但是父子进程退出是无序的

孤儿进程：父进程先退出，子进程托孤给init进程
僵尸进程：子进程已经终止，父进程还没有通过waitwaitpid获取状态，子进程残留状态信息
避免：fork()两次
调用wait waitpid获取子进程退出状态
捕获sigchld信号在捕获程序中调用wait waitpid
守护进程：运行在后台，不和任何终端关联，周期性执行某些任务，系统启动时就运行

### 什么时候多线程？什么时候多进程？ 进程线程场景
需要频繁创建和销毁：多线程
需要数据共享：多线程
cpu、计算密集型：多进程 IO密集型：多线程
弱相关：多进程 强相关：多线程
多机分布：多进程 多核分区：多线程
nginx chrome多进程

### 死锁
原因：资源分配不当，系统资源不足；程序推进的顺序不合适
必要条件：
**互斥**：一段时间某资源仅为一个进程占有 多个线程不能同时使用同一个资源。
**请求和保持：**已获取的资源保持不放 线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1。
**不抢占**：获得之后不能被抢占 在自己使用完之前不能被其他线程获取
**环路等待**：资源获取存在环形链 两个线程获取资源的顺序构成了环形链。
Linux 下，我们可以使用 pstack + gdb 工具
**使用资源有序分配法，来破环环路等待条件。**
### 分段？分页：
定义： 提高内存利用率，每个段连续分配，段和段之间离散分配   把内存分成大小相等且固定的块
信息的逻辑单位，根据用户需要划分   信息的物理单位，为了管理主存方便划分
大小不固定 可以动态改变  大小固定系统决定
地址空间:向用户提供二维地址空间  （段名 + 段地址  向用户提供一维地址空间
作用：分段能反应程序的逻辑结构 便于段的共享和保护  提高内存利用率，实现虚拟内存，获得更大的地址空间

### 互斥锁、自旋锁、读写锁、乐观锁、悲观锁
互斥锁加锁失败后，线程会释放 CPU ，给其他线程；
自旋锁加锁失败后，线程会忙等待，直到它拿到锁；
两次线程上下文切换的成本：
当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行；
接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。
如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。

自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，
不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。
一般加锁的过程，包含两个步骤：
第一步，查看锁的状态，如果锁是空闲的，则执行第二步；
第二步，将锁设置为当前线程持有；
**当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对。**

读优先锁对于读线程并发性更好，但也不是没有问题。我们试想一下，如果一直有读线程获取读锁，那么写线程将永远获取不到写锁，
这就造成了写线程「饥饿」的现象。
写优先锁可以保证写线程不会饿死，但是如果一直有写线程获取写锁，读线程也会被「饿死」。
既然不管优先读锁还是写锁，对方可能会出现饿死问题，那么我们就不偏袒任何一方，搞个「公平读写锁」。
公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，
这样读线程仍然可以并发，也不会出现「饥饿」的现象。

多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁。
乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。
只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁

### 内存管理
* malloc
* brk:堆 分配内存 < 128k
堆顶指针向高地址移动
* mmap：私有匿名映射 从文件映射区分配一块内存 分配内存 > 128k
* void* mmap(start, lenth, prot, flags, fd, offsize)
start:映射内存起始地址
length：多大
prot：映射区域保护方式
flags：映射区域特性
fd:映射文件描述符 匿名-1
offset 文件映射偏移量

#### malloc 申请的内存，free 释放内存会归还给操作系统吗？
malloc 通过 brk() 方式申请的内存 通过 free 释放内存后，堆内存还是存在的，并没有归还给操作系统。
如果 malloc 通过 mmap 方式申请的内存，free 释放内存后就会归归还给操作系统。

### 全部用mmap？
频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大。
为了改进这两个问题，malloc 通过 brk() 系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中。
等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗

### 全部用brk？导致内存碎片valgrind检测不出来

### free() 函数只传入一个内存地址，为什么能知道要释放多大的内存？
malloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节
保存了该内存块的描述信息，比如有该内存块的大小。


### 内存分配的过程是怎样的？
malloc -> 虚拟内存，读写时访问虚拟内存，发现没有映射到物理内存->产生缺页中断
从用户态切换到内核态 缺页中断函数处理page fault handler
缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。
如果没有空闲的物理内存，那么内核就会开始进行回收内存的工作，回收的方式主要是两种：直接内存回收和后台内存回收。
后台回收：kswapd线程，异步
直接回收：同步阻塞
OOM

### 哪些内存可以被回收？
文件页：内核缓存的磁盘数据和内核缓存的文件数据
直接释放，有需要再直接读
脏页，先写回磁盘再释放内存

匿名页：swap机制 ： 不常用的先写回磁盘，然后释放，再次访问时，从磁盘读取
LRU:维护活跃内存链表和不活跃内存链表

### 回收内存带来的性能影响
一种是后台内存回收，也就是唤醒 kswapd 内核线程，这种方式是异步回收的，不会阻塞进程。
一种是直接内存回收，这种方式是同步回收的，会阻塞进程，这样就会造成很长时间的延迟，以及系统的 CPU 利用率会升高，最终引起系统负荷飙高。
可被回收的内存类型有文件页和匿名页：
文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，
这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。
匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。
回收内存的操作基本都会发生磁盘 I/O 的，如果回收内存的操作很频繁，意味着磁盘 I/O 次数会很多，这个过程势必会影响系统的性能，整个系统给人的感觉就是很卡。

### 调整文件页和匿名页的回收倾向
* swappiness 越大越积极使用swap回收匿名页，越小回收文件页
* 尽早触发 kswapd 内核线程异步回收内存
* sar -B pgscand ->直接回收
* 当剩余内存页（pages_free）小于页低阈值（pages_low），就会触发 kswapd 进行后台回收
* 在 NUMA 架构下，当某个 Node 内存不足时，系统可以从其他 Node 寻找空闲内存，也可以从本地内存中回收内存。
### OOM
* points = process_pages + oom_score_adj*totalpages/1000
用「系统总的可用页面数」乘以 「OOM 校准值 oom_score_adj」再除以 1000，
最后再加上进程已经使用的物理页面数，计算出来的值越大，那么这个进程被 OOM Kill 的几率也就越大
* 调整该进程的 oom_score_adj 


### 在 4GB 物理内存的机器上，申请 8G 内存会怎么样？
在 32 位操作系统，因为进程最大只能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。
在 64位 位操作系统，因为进程最大只能申请 128 TB 大小的虚拟内存，
即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：
如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；

### 缓存失效 or 缓存污染导致缓存命中率下降
redis实现LFU
mysql + linux 改进LRU
LRU 算法一般是用「链表」作为数据结构来实现的，链表头部的数据是最近使用的，而链表末尾的数据是最久没被使用的
* 应用程序利用 read 系统调动读取 4KB 数据，实际上内核使用预读机制（ReadaHead） 机制完成了 16KB 数据的读取，
* 也就是通过一次磁盘顺序读将多个 Page 数据装入 Page Cache。
这样下次读取 4KB 数据后面的数据的时候，就不用从磁盘读取了，直接在 Page Cache 即可命中数据。
* 因此，预读机制带来的好处就是减少了 磁盘 I/O 次数，提高系统磁盘 I/O 吞吐量。
MySQL Innodb 存储引擎的 Buffer Pool 也有类似的预读机制，MySQL 从磁盘加载页时，会提前把它相邻的页一并加载进来，目的是为了减少磁盘 IO
* 预读失效：提前加载的页，最后并没有被访问；
* 不被访问的预读页占用了LRU链表前排，而末尾淘汰的页可能是热点->降低缓存命中率
### Linux 是如何避免预读失效带来的影响？
维护两个链表 活跃链表和非活跃链表
预读页加入非活跃链表头，被访问时才插入活跃链表头，不会影响活跃链表的热点数据；
### MySQL 是如何避免预读失效带来的影响？
MySQL 的 Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域，young 区域 和 old 区域。
划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部

### 但是存在缓存污染：只要数据被访问一次，就将数据加入到活跃 LRU 链表头部（或者 young 区域）
如果这些大量的数据在很长一段时间都不会被访问的话，那么整个活跃 LRU 链表（或者 young 区域）就被污染
导致热点数据被替换掉，降低缓存命中率
### 避免：只要我们提高进入到活跃 LRU 链表（或者 young 区域）的门槛，就能有效地保证活跃 LRU 链表（或者 young 区域）里的热点数据不会被轻易替换掉。

Linux 操作系统：在内存页被访问第二次的时候，才将页从 inactive list 升级到 active list 里。
MySQL Innodb：在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行停留在 old 区域的时间判断：
如果第二次的访问时间与第一次访问的时间在 1 秒内（默认值），那么该页就不会被从 old 区域升级到 young 区域；
如果第二次的访问时间与第一次访问的时间超过 1 秒，那么该页就会从 old 区域升级到 young 区域；
提高了进入活跃 LRU 链表（或者 young 区域）的门槛后，就很好了避免缓存污染带来的影响。
在批量读取数据时候，如果这些大量数据只会被访问一次，那么它们就不会进入到活跃 LRU 链表（或者 young 区域），也就不会把热点数据淘汰，只会待在非活跃 LRU 链表（或者 old 区域）中，后续很快也会被淘汰。

### 虚拟内存的作用
虚拟内存使得进程运行内存超过物理内存大小
程序运行符合局部性原理，CPU访问内存会有明显的重复访问的倾向，对于没有经常访问的内存，我们可以换出到磁盘

每个进程有自己的页表，每个进程的虚拟内存空间是相互独立的，进程没有办法访问其他进程的页表->解决了多进程之间地址冲突的问题

页表的页表项除了物理地址，还有标记位，控制页的读写权限，内存访问方面，提供了更好的安全性

### 进程调度算法
* 先来先服务 对长作业有利 适合CPU繁忙型， 不适合IO繁忙型

* 最短作业有先 对长作业不利 提高系统吞吐量

* 高响应比有限  （等待时间 + 要求服务时间 ） / 要求服务时间

* 时间片轮转每个进程分配一个时间片 20-50ms

* 最高优先级调度算法
从就绪队列选择最高优先级进程

* 多级反馈队列 优先级越高，时间片越少

### 页面置换算法 缺页异常，需要调入新页面而内存已满，选择被置换的物理页面
选择一个物理页面换出磁盘，把需要访问的页面换入到物理页

* 最佳页面置换算法
置换未来最长时间不访问：衡量算法效率

* 先进先出 选择在内存中驻留时间最长的

* 最近最久未使用LRU： 选择最长时间没有被访问：维护一个所有页面的链表

* 时钟页面置换算法
所有页面保存在类似钟面的环形链表中一个表针指向最老的页面
缺页中断时，先检查表针页面
访问位为0淘汰，插入新页面，前移
访问位位1置为0 前移找到0

* 最不常用 选择访问频率最少的 维护一个计数器

### 磁盘调度算法
先来先服务
最短寻道优先
扫描算法
循环扫描算法
LOOK / C-LOOK

### 键盘敲入字母时，期间发生了什么
当用户输入键盘字符，键盘控制器产生扫描码数据——>缓冲在键盘控制器的寄存器中
键盘控制器通过总线给CPU发送中断请求

CPU收到中断请求后，操作系统保存被中断进程的CPU上下文，然后调用键盘的中断处理程序

中断处理程序在键盘驱动程序初始化时注册，功能：从键盘控制器寄存器的缓冲区读取扫描码，根据扫描码找到对应字符，
翻译成对应ASCII码

得到ASCII码，放到读缓冲队列
显示设备定时从读缓冲队列读取数据到写缓冲队列

最后把写缓冲队列的数据写入显示设备控制器的寄存器的数据缓冲区，最后显示在屏幕

恢复被中断进程的上下文

### 文件系统 
Linux 文件系统会为每个文件分配两个数据结构：
索引节点（index node）和目录项（directory entry），它们主要用来记录文件的元信息和目录层次结构。

索引节点，也就是 inode，用来**记录文件的元信息**
比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。
索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。
目录项，也就是 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。
多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是：
**目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存**。

**磁盘读写的最小单位是扇区，扇区的大小只有 512B 大小**
索引节点是存储在硬盘上的数据，那么为了加速文件的访问，通常会把索引节点加载到内存中。

另外，磁盘进行格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。

超级块，用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。
索引节点区，用来存储索引节点；
数据块区，用来存储文件或目录数据；
我们不可能把超级块和索引节点区全部加载到内存，
这样内存肯定撑不住，所以只有当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的：

超级块：当文件系统挂载时进入内存；
索引节点区：当文件被访问时进入内存；

文件存储：
**连续空间存放方式** 存放在磁盘「连续的」物理空间中 读写效率很高
文件头里需要指定「起始块的位置」和「长度」
连续空间存放的方式虽然读写效率高，但是有「磁盘空间碎片」和「文件长度不易扩展」的缺陷
**非连续空间存放方式**分为「链表方式」和「索引方式」。
链表的方式存放是离散的，不用连续的，于是就可以消除磁盘碎片，可大大提高磁盘空间的利用率，同时文件的长度可以动态扩展。
根据实现的方式的不同，链表可分为「隐式链表」和「显式链接」两种形式。
**「隐式链表」**：文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置
缺点：**在于无法直接访问数据块**，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间。
**分配的稳定性较差**，系统在运行过程中由于软件或者硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失。
如果取出每个磁盘块的指针，把它放在内存的一个表中，就可以解决上述隐式链表的两个不足。
**「显式链接」**：它指把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中，该表在整个磁盘仅设置一张，
每个表项中存放链接指针，指向下一个数据块号。
内存中的-->文件分配表：找记录的过程是在内存中进行提高了检索速度，而且大大减少了访问磁盘的次数。
主要的缺点是不适用于大磁盘。

链表的方式解决了连续分配的磁盘碎片和文件动态扩展的问题，但是不能有效支持直接访问（FAT除外）--->索引的方式
索引:每个文件创建一个「索引数据块」，里面存放的是指向文件数据块的指针列表，
文件头需要包含指向「索引数据块」的指针，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块。
索引的方式优点在于：

文件的创建、增大、缩小很方便；
不会有碎片的问题；
支持顺序读写和随机读写；

链表 + 索引--->「链式索引块」:在索引数据块留出一个存放下一个索引数据块的指针，于是当一个索引数据块的索引信息用完了
就可以通过指针的方式，找到下一个索引数据块的信息
链表方式的问题:万一某个指针损坏了，后面的数据也就会无法读取了

![img.png](img.png)
根据文件的大小，存放的方式会有所变化
对于小文件使用直接查找的方式可减少索引数据块的开销；
对于大文件则以多级索引的方式来支持，所以大文件在访问数据块时需要大量查询；

#### 空闲空间管理
空闲表法
空闲链表法
位图法
空闲表法就:为所有空闲空间建立一张表，表内容包括空闲区的第一个块号和该空闲区的块个数，连续分配的
空闲链表法:在主存中保存一个指针，令它指向第一个空闲块。其特点是简单，但不能随机访问，工作效率低，因为每当在链上增加或移动空闲块时需要做很多 I/O 操作，
空闲表法和空闲链表法都不适合用于大型文件系统，因为这会使空闲表或空闲链表太大。

位图是利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。

* 硬链接是多个目录项中的「索引节点」指向一个文件
* 硬链接是不可用于跨文件系统的
* 只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。

软链接相当于重新创建一个文件，这个文件有独立的 inode，但是这个文件的内容是另外一个文件的路径
可以跨文件系统的，甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。