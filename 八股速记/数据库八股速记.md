
### 数据库三范式
* 字段不可再分 无重复的列 原子性
实体中的某个属性不能有多个值或者不能有重复的属性 关系模式的基本要求
* 有主键，非主键字段依赖主键 唯一性  一个表只说明一个事物
* 非主键字段不能相互依赖 每列都与主键有直接关系，不存在传递依赖

### Mysql 日志
* undo log 回滚日志保证了原子性没提交之前，记录更新前的数据到undo log；

ReadView + undo log实现MVCC

快照读：普通select语句 
读提交：每个select语句生成readview
可重复读：启动事务时，生成一个readview
uodolog 通过redolog 持久化到硬盘

* bufferpool
读取数据，存在直接返回；
修改数据，存在直接修改，设置为脏页，后台线程刷盘

* redo log 是物理日志，记录了某个数据页做了什么修改
更新记录时，先更新内存，标记为脏页，记录redolog，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘
WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。

redo log 记录了此次事务「完成后」的数据状态，记录的是更新之后的值；
undo log 记录了此次事务「开始前」的数据状态，记录的是更新之前的值；
事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务

redo log，再通过 WAL 技术，InnoDB 就可以保证即使数据库发生异常重启，之前已提交的记录都不会丢失，
这个能力称为 crash-safe（崩溃恢复）
redo log 保证了事务四大特性中的持久性
### redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？
写入 redo log 的方式使用了追加操作， 所以磁盘操作是顺序写，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是随机写。

* 实现事务的持久性，让 MySQL 有 crash-safe 的能力，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；
* 将写操作从「随机写」变成了「顺序写」，提升 MySQL 写入磁盘的性能。
### 产生的 redo log 是直接写入磁盘的吗？
redo log 也有自己的缓存—— redo log buffer，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘
### redo log 什么时候刷盘？
MySQL 正常关闭时；
当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；
InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。
每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘
### innodb_flush_log_at_trx_commit 参数控制的是什么？
当设置该参数为 0 时，表示每次事务提交时，还是将 redo log 留在 redo log buffer中，该模式下在事务提交时不会主动触发写入磁盘的操作。
当设置该参数为 1 时，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘，这样可以保证 MySQL 异常重启之后数据不会丢失。
当设置该参数为 2 时，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，
 redo log文件」意味着写入到了操作系统的文件


### Mysql B+树
磁盘读写最小单位扇区 512B操作系统读写最小单位是块 Linux块 4 KB 8个块

* 二叉查找树：一个节点的左子树的所有节点都小于这个节点，右子树的所有节点都大于这个节点
* 每次插入的元素都是二叉查找树中最大的元素，二叉查找树就会退化成了一条链表，查找数据的时间复杂度变成了 O(n)
树的高度等于每次查询时的磁盘I0次数 高度越高，影响性能
退化成链表->On
插入元素越多，高度越高，IO次数越多，性能下降，不能范围查询

AVL树 自平衡二叉树 红黑树
在二叉搜索树的前提下，每个节点的左子树和右子树的高度差不能超过 1。O(logn)

都会随元素增多，树高度变高，磁盘I/0次数增多，影响效率

根本原因：都是二叉树
当树的节点越多的时候，并且树的分叉数 M 越大的时候，M 叉树的高度会远小于二叉树的高度。

B树 多叉树
但是 B 树的每个节点都包含数据（索引+记录），而用户的记录数据的大小很有可能远远超过了索引数据，这就需要花费更多的磁盘 I/O 操作次数来读到「有用的索引数据」。
而且，在我们查询位于底层的某个节点（比如 A 记录）过程中，「非 A 记录节点」里的记录数据会从磁盘加载到内存，但是这些记录数据是没用的，
我们只是想读取这些节点的索引数据来做比较查询，而「非 A 记录节点」里的记录数据对我们是没用的，这样不仅增多磁盘 I/O 操作次数，也占用内存资源。
范围查询需要中序遍历

B+ 树与 B 树差异的点，主要是以下这几点：

叶子节点才会存放实际数据（索引+记录），非叶子节点只会存放索引；

所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表；

非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。

非叶子节点中有多少个子节点，就有多少个索引；

B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，
B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少

B+ 树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，这样删除非常快，
B 树则不同，B 树没有冗余节点，删除节点的时候非常复杂，比如删除根节点中的数据，可能涉及复杂的树的变形，

B+ 树所有叶子节点间还有一个链表进行连接，这种设计对范围查找非常有帮助
是 Innodb 使用的  B+ 树有一些特别的点，比如：

B+ 树的叶子节点之间是用「双向链表」进行连接，这样的好处是既能向右遍历，也能向左遍历。

B+ 树点节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB

Innodb 根据索引类型不同，分为聚集和二级索引。他们区别在于，聚集索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚集索引的叶子节点，而二级索引的叶子节点存放的是主键值，而不是实际数据。
B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，
因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少。

B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；

B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，
因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。

### Redis 数据结构
string--SDS
list -- 双向链表 压缩列表 -- quicklist
hash --  哈希表 压缩列表 -- listpack
set -- 哈希表 整数集合
Zset -- 跳表 压缩列表 -- listpack

SDS：保存文本 + 二进制 （数据存放在buf[])
O1获取长度 
API安全拼接不会造成缓冲区溢出（检查空间，自动扩容）
* 数据类型：
LIST: 元素个数小于512 值小于64字节 压缩列表 
否则双向链表
HASH: 元素个数小于512 值小于64字节 压缩列表
否则哈希表
SET:元素个数小于512 整数集合
否则哈希表
ZSET：元素个数小于128 值小于64 压缩列表
否则跳表

redisObject
type : 对象类型
encoding ： 使用那种底层数据结构
void* ptr
* 底层
#### SDS:
len 字符串长度
alloc 分配的空间长度 alloc - len 计算剩余空间
flags sds类型 5种类型
buf[] 字节数组 字符串 + 二进制
扩容：所需sds长度小于1M  2倍 newlen
超过1M newlen + 1M
节省空间：设计不同类型的结构体，灵活保存，节省空间
取消结构体对齐


#### LIST
list : head tail len -> listNode 
优点：
listNode : prev + next O1获取前置后置
list : head + tail O1获取表头和表尾
O1获取len
保存不同类型的值
缺点：内存不连续，无法很好利用CPU缓存，内存开销大


#### 压缩列表
优点：连续内存，利用CPU缓存，针对不同长度编码，节省内存
缺点：不能保存过多元素，降低查询效率；新增或修改时，内存重新分配，引发连锁更新

查找第一个元素和最后一个元素 O1
其他元素On
* 节点entry：
prevlen：前一个节点长度
enconding:当前实际数据的类型和长度
data：实际数据
会根据数据的类型和长度进行空间分配
前一个节点长度小于254 1字节空间分配prevlen字段
大于254 5字节空间分配prevlen字段
整数： encoding 1字节
字符串 ： 根据长度 125字节编码encoding
* 连锁更新问题

#### 哈希表
* 开链法解决哈希冲突
* rehash:两个哈希表：
给哈希表2分配比哈希表1大2倍的空间
哈希表1迁移至哈希表2
哈希表1空间释放，哈希表2->1 新建哈希表1为下次
* 渐进式rehash
* 触发条件：负载因子：已保存节点数/哈希表大小
大于等于1，且没有执行rdb快照和aof重写时触发
大于等于5，强制触发

#### 整数集合
整数集合的升级操作：节省内存
不支持降级操作

#### 跳表
* 平均logN查找
* 哈希表只是用于以常数复杂度获取元素权重
* 结构：多层有序链表
* 跳表节点查询过程 该层下一个节点 Or 下一层 level数组

查找一个跳表节点的过程时，跳表会从头节点的最高层开始，逐一遍历每一层。
* 在遍历某一层的跳表节点时，会用跳表节点中的 SDS 类型的元素和元素的权重来进行判断，共有两个判断条件：

如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。
如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。
如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找。
* 跳表的相邻两层的节点数量最理想的比例是 2:1，查找复杂度可以降低到 O(logN)。

##### 那怎样才能维持相邻两层的节点数量的比例为 2 : 1 呢？
如果采用新增节点或者删除节点时，来调整跳表节点以维持比例的方法的话，会带来额外的开销。
Redis 则采用一种巧妙的方法是，跳表在创建节点的时候，随机生成每个节点的层数，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。
具体的做法是，跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），
那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。

#### 为什么用跳表而不用平衡树？ 内存 + 范围查找 + 算法实现
* 从内存占用上来比较，跳表比平衡树更灵活一些。
平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。
如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。

* 在做范围查找的时候，跳表比平衡树操作要简单。在平衡树上，我们找到指定范围的小值之后，
还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。
而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。
* 从算法实现难度上来比较，跳表比平衡树要简单得多。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速


#### quicklist 3.2 以后List
双向链表 + 压缩列表组合
本身是个链表，节点元素是压缩列表
* 通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。
* 因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能


#### listpack
它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。

* 压缩列表的 entry 保存 prevlen 是为了实现节点从后往前遍历，知道前一个节点的长度，就可以计算前一个节点的偏移量。
* listpack 一样可以支持从后往前遍历的


### 缓存问题
* 缓存雪崩:大量缓存数据同时过期或者redis宕机
* 大量缓存数据同时过期
均匀设置过期时间，加上随机数
互斥锁：发现数据不在redis加上互斥锁，保证同一时间只有一个请求来构建缓存，同时加上过期时间
双key：备用key不会过期，更新时同时更新
缓存永久有效，交由后台进程定时更新

* 在业务刚上线的时候，我们最好提前把数据缓起来，而不是等待用户访问才来触发缓存构建，这就是所谓的缓存预热
* redis宕机
服务熔断：直接返回错误；减少对业务影响，请求限流机制
主从节点的方式构建 Redis 缓存高可靠集群。

* 缓存击穿：热点数据过期
互斥锁，热点数据不过期

* 缓存穿透即不再缓存也不再数据库
业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；
黑客恶意攻击，故意大量访问某些读取不存在数据的业务；
API接口非法请求限制
缓存空值或默认值
我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在。

### 数据库和缓存一致性



### Redis 主从复制第一次同步
三个阶段：
* 建立连接， 协商同步
  从服务器：replicaof->psync:runID offset
  主：FULLRESYNC 全量复制

* 主服务器同步数据给从服务器
  主：bgsave:RDB 期间的写操作没有进来 造成主从服务器间数据不一致
  三个时间间隙写入replication buffer:
  主生成RDB
  主发送RDB给从
  从加载RDB

* 主服务器发送新写操作命令给从服务器
  从收到RDB 先清空 然后加载RDB
  主发送replication buffer 主从数据一致

### 基于长连接的命令传播

分摊主服务器的压力
两个方面 bgsave fork()子进程耗时阻塞主进程
传输RDB网络带宽
主服务器生成 RDB 和传输 RDB 的压力可以分摊到充当经理角色的从服务器。

### 增量复制： 网络断开又恢复
恢复网络后，从请求psync offset != -1
主：CONTINUE——> 发送从断线期间所执行的写命令
怎么知道发送那些增量数据：repl_backlog_buffer:默认1M 避免全量 应该尽可能大一些

从服务器要读取的数据还在里面 就增量复制——>写入replication buffer
不在了 就全量复制


### 怎么判断某个redis节点是否正常工作
心跳检测ping-pong 如果有一半以上节点Ping一个节点没有回应 集群就认为这个节点挂了

主：每个10s ping
从：每隔1s replconf ack{offset} 上报自身偏移量
实时检测主从节点网络状态；上报复制偏移量，检测复制数据是否丢失

#### 主从复制架构中，过期Key处理：
主节点处理或淘汰一个key后，模拟一条del命令发送给从

#### redis是同步复制还是异步复制
收到写命令后，先写到内部缓冲区，然后异步发送给从

#### replication buffer 、repl backlog buffer 区别如下：
repl backlog buffer：保存着最近传播的写命令。
出现的阶段不一样：
是在增量复制阶段出现，一个主节点只分配一个 repl backlog buffer；
在全量复制阶段和增量复制阶段都会出现，主节点会给每个新连接的从节点，分配一个 replication buffer；
这两个 Buffer 都有大小限制的，当缓冲区满了之后，发生的事情不一样：
当 repl backlog buffer 满了，因为是环形结构，会直接覆盖起始位置数据;
当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，重新开始全量复制。

### 为什么会出现主从数据不一致？ 异步复制 无法强一致性

### 如何应对主从数据不一致：
尽量保证主从节点间网络连接状况良好
开发一个外部程序监控主从间复制进度

得到双方复制进度-> 双方复制进度差值-> 大于阈值 不让客户端和这个从节点进行数据读取， 减少读到不一致数据的情况

### Redis单线程为什么这么快？

大部分操作在内存中完成，并且采用高效的数据结构因此Redis的瓶颈可能是机器的内存或者网络带宽，而并非CPU

单线程模型避免多线程竞争，省去多线程切换的时间和性能开销，不会死锁

I/O多路复用，处理大量的客户端socket请求，一个Redis线程处理多个IO流

### 6.0引入多线程，提高处理网络IO的并行度，命令的执行还是单线程

### Redis持久化
AOF：每执行一条写命令，就把该命令以追加的方式写入到文件
RDB：某一时间内存数据，以二进制写入硬盘
混合持久化

### AOF写回
always 同步写回
everySec 每秒写回
No 由操作系统控制写回

AOF过大->AOF重写
读取数据库所有键值对，每个键值对用一条命令记录到新的AOF文件上->压缩了AOF文件的体积

AOF重写过程：后台进程bgrewriteaof

重写期间，主进程仍可以处理命令请求，不会阻塞主进程
父子进程共享内存，只读；任意一方修改了共享内存，发生写时复制，父子进程就有了独立数据副本，不用加锁

### 数据不一致？
* AOF重写缓冲区
  AOF重写期间，主进程三个工作
  执行客户端发来的命令
  将执行后写命令追加到AOF缓冲区
  将执行后写命令追加到AOF重写缓冲区

子进程完成AOF重写工作后，向主进程发送信号，信号处理函数
将AOF重写缓冲区的内容追加到新的AOF文件，保证数据一致
新的AOF文件改名，覆盖现有AOF

### Mysql 锁
* 全局锁 FTWRL 全局逻辑备份->数据库引擎事务支持可重复读 替代
#### 表级锁
* 表锁 ：表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作
* 元数据锁MDL 不需要显式操作 表CRUD和结构更改时自动加上
申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作
为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，
如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。
* 意向锁
如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。
那么有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。
所以，意向锁的目的是为了快速判断表里是否有记录被加锁。
* AUTO_INC锁
表里的主键通常都会设置成自增的，这是通过对主键字段声明 AUTO_INCREMENT 属性实现的
锁不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放。
在插入数据时，会加一个表级别的 AUTO-INC 锁，然后为被 AUTO_INCREMENT 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。
轻量级锁->一样也是在插入数据的时候，会为被 AUTO_INCREMENT 修饰的字段加上轻量级锁，然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁。
* 当搭配 binlog 的日志格式是 statement 一起使用的时候，在「主从复制的场景」中会发生数据不一致的问题
 binlog 日志格式要设置为 row，这样在 binlog 里面记录的是主库分配的自增值，到备库执行的时候，主库的自增值是什么，从库的自增值就是什么。

#### 行级锁
行级锁的类型主要有三类：

* Record Lock，记录锁，也就是仅仅把一条记录锁上；
* Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；
只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。
* Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。
即能保护该记录，又能阻止其他事务将新纪录插入到被保护记录前面的间隙中。
next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。
* 插入意向锁
一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。
如果有的话，插入操作就会发生阻塞，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻）
在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新记录，但是现在处于等待状态。

### MySQL 是怎么加锁的
#### 什么 SQL 语句会加行级锁
* 普通的 select 语句是不会对记录加锁的，因为它属于快照读，是通过 MVCC（多版本并发控制）实现的
//对读取的记录加共享锁(S型锁)
select ... lock in share mode;
//对读取的记录加独占锁(X型锁)
select ... for update;
* 除了上面这两条锁定读语句会加行级锁之外，update 和 delete 操作都会加行级锁，且锁的类型都是独占锁(X型锁)。
//对操作的记录加独占锁(X型锁)
updaet table .... where id = 1;
//对操作的记录加独占锁(X型锁)
delete from table where id = 1;
* 共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。
#### MySQL 是怎么加行级锁的？
* 加锁的对象是索引，加锁的基本单位是 next-key lock，它是由记录锁和间隙锁组合而成的，
* next-key lock 是前开后闭区间，而间隙锁是前开后开区间。
* 在能使用记录锁或者间隙锁就能避免幻读现象的场景下， next-key lock 就会退化成退化成记录锁或间隙锁。
唯一索引等值查询

当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会退化成「记录锁」。
当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会退化成「间隙锁」
我们可以通过 select * from performance_schema.data_locks\G; 这条语句，查看事务执行 SQL 过程中加了什么锁。
加锁的对象是针对索引，因为这里查询语句扫描的 B+ 树是聚簇索引树，即主键索引树，所以是对主键索引加锁。将对应记录的主键索引加 记录锁后，就意味着其他事务无法对该记录进行更新和删除操作了。

唯一索引范围查询
当唯一索引进行范围查询时，会对每一个扫描到的索引加 next-key 锁，然后如果遇到下面这些情况，会退化成记录锁或者间隙锁：

情况一：针对「大于等于」的范围查询，因为存在等值查询的条件，那么如果等值查询的记录是存在于表中，那么该记录的索引中的 next-key 锁会退化成记录锁。
情况二：针对「小于或者小于等于」的范围查询，要看条件值的记录是否存在于表中：
当条件值的记录不在表中，那么不管是「小于」还是「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。
当条件值的记录在表中，如果是「小于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁；如果「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引 next-key 锁不会退化成间隙锁。其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。

* 在线上在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了
#### 加了什么锁，导致死锁的？
* 插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，
* 另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。所以，插入意向锁和间隙锁之间是冲突的。
插入意向锁的生成时机：
每插入一条新记录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，
* 如果已加间隙锁，此时会生成一个插入意向锁，然后锁的状态设置为等待状态
* 现象就是 Insert 语句会被阻塞。
* 如果两个事务分别向对方持有的间隙锁范围内插入一条记录，而插入操作为了获取到插入意向锁，
* 都在等待对方事务的间隙锁释放，于是就造成了循环等待，满足了死锁的四个条件：互斥、占有且等待、不可强占用、循环等待，因此发生了死锁。


### Mysql事务
* ACID
原子性：一个事务中的所有操作，要么全部完成，要么全部不完成 undo log
一致性：事务操作前后，数据满足完整性约束，数据库保持一致性状态 
隔离性：数据库允许多个并发事务同时对数据进行读写和修改的能力 mvcc 或锁
持久性：事务接受后，对数据的修改就是永久的 redo log

* 并行事务引发问题？
脏读：一个事务读到了另一个事务未提交的修改过的数据
不可重复读：一个事务内多次读取同一个数据，前后两次读到的数据不一致
幻读：一个事务多次查询符合条件的记录数量，前后两次查询的记录数量不一致

* 隔离级别
读未提交：一个事务还未提交，他做的变更就能被其他事务看到
读提交：一个事务提交后，他做的变更才能被其他事务看到
可重复读：一个事务执行过程中看到数据，一直跟这个事务启动时看到的数据是一致的
串行化：记录加读写锁，多个事务读写，发生冲突后访问的事务必须等前一个事务完成

* innodb默认可重复读->解决幻读
快照读：普通select语句：mvcc
当前读：select ..for update : next-key lock 间隙锁 + 记录锁

* 读提交：「每个语句执行前」都会重新生成一个 Read View
* 可重复读：「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。

* undo log 隐藏列：
trix_id:该事务的事务 id
roll_pointer指针，指向每一个旧版本记录
trx_id < min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。
trx_id >= max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。
trx_id 在 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中：
如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。
如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见

* 过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制



### 索引
#### 索引失效： 6 种
* 左、左右模糊匹配 like %xx 或者 like%xx%  type = ALL
原因：因为索引 **B+ 树是按照「索引值」有序排列存储**的，只能根据前缀进行比较
* 对索引使用函数
索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了
* 对索引进行表达式计算
* 隐式类型转换
MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。
* 联合索引非最左匹配
* 索引下推功能，可以在存储引擎层进行索引遍历过程中，对索引中包含的字段先做判断
直接过滤掉不满足条件的记录，再返还给 Server 层，从而减少回表次数。
原理是：截断的字段不会在 Server 层进行条件判断，而是会被下推到「存储引擎层」进行条件判断（因为 c 字段的值是在 (a, b, c) 联合索引里的）
然后过滤出符合条件的数据后再返回给 Server 层。由于在引擎层就过滤掉大量的数据，无需再回表读取数据来进行判断，减少回表次数，从而提升了性能。
 Extra=Using index condition 
* WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。

