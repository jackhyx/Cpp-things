* redis哨兵   热key    （不会没看过...）
#### 热点Key，怎么解决？
--什么是热Key？
在Redis中，我们把访问频率高的Key，称为热Key。
比如突然又几十万的请求去访问redis中某个特定的Key，那么这样会造成redis服务器短时间流量过于集中，
很可能导致redis的服务器宕机。那么接下来对这个Key的请求，都会直接请求到我们的后端数据库中，
数据库性能本来就不高，这样就可能直接压垮数据库，进而导致后端服务不可用。

--热Key产生的原因？
**用户消费的数据远大于生产的数据**，如商品秒杀、热点新闻、热点评论等读多写少的场景。
双十一秒杀商品，短时间内某个爆款商品可能被点击/购买上百万次，或者某条爆炸性新闻等被大量浏览，
此时会造成一个较大的请求Redis量，这种情况下就会造成热点Key问题。
**请求分片集中，超过单台Redis服务器的性能极限**。
在服务端读数据进行访问时，往往会对数据进行分片切分，
例如采用固定Hash分片，hash落入同一台redis服务器，如果瞬间访问量过大，超过机器瓶颈时，就会导致热点 Key 问题的产生。
--热点Key的危害？
* 缓存击穿，压垮redis服务器，导致大量请求直接发往后端服务，并且DB本身性能较弱，很可能进一步导致后端服务雪崩。
* 如何识别热点Key？
  --凭借个人经验，结合业务场景，判断哪些是热Key。
  比如，双十一大促的时候，苹果手机正在秒杀，那么我们可以判断苹果手机这个sku就是热Key。
* 使用redis之前，在**客户端写程序统计上报**。
  修改我们的业务代码，在操作redis之前，加入Key使用次数的统计逻辑，定时把收集到的数据上报到统一的服务进行聚合计算，
  这样我们就可以找到那些热点Key。缺点就是对我们的业务代码有一定的侵入性。
* **服务代理层上报**。
  这个要看具体公司redis集群架构是怎么样的，如果是在redis前面有一个代理层，
  那么我们可以在代理层进行收集上报，也是可以找到热点Key。
* **使用redis自带的命令**。
  例如monitor、redis-cli加上--hotkeys选项等，不过这种方式执行起来很慢，可能会降低redis的处理请求的性能，慎用。
  monitor命令：可以实时抓取出redis服务器接收到的命令，然后写代码统计出热Key，也有现成的分析工具可以使用。
* **redis节点抓包分析**。
  自己写程序监听端口，解析数据，进行分析。

* 如何解决热Key问题？
  --Redis集群扩容：增加分片副本，分摊客户端发过来的读请求；
  --使用二级缓存，即JVM本地缓存，减少Redis的读请求。
  例如使用Caffeine+redis 实现二级缓存，先从本地缓存中取，取不到再去redis中去取。当然也可以使用其它框架，如ehcache、甚至一个HashMap都可以。
#### 布隆过滤器
使用布隆过滤器快速判断数据是否存在
#### redis 的set 等集合最多可以存储多少个元素
  redis官方文档
  Strings类型：一个String类型的value最大可以存储512M
  Lists类型：list的元素个数最多为2^32-1个，也就是4294967295个。
  Sets类型：元素个数最多为2^32-1个，也就是4294967295个。
  Hashes类型：键值对个数最多为2^32-1个，也就是4294967295个。
  Sorted sets类型：跟Sets类型相似。
#### redis主从复制？
#### redis hash怎么实现,zset怎么实现？
#### redis为什么怎么快？
#### redis的大key如何处理？
* redis的数据结构？

* redis的主从了解吗？

* redis的持久化方式？

* redis查找aa为前缀的所有数据，怎么查出来？

* redis的分布式锁怎么实现？

* Redis持久化

* redis中zset的底层结构

* 跳表能解决什么问题

* redis本身就是内存操作，比较快，为什么还用跳表做空间换时间

* redis为什么使用单线程

* redis的过期删除策略，定期删除和惰性删除

* 是否了解过其他数据库(除了MySQL和redis)

* redis为什么这么快，IO模型

* Redis的zset，set，hash，list，string的底层数据结构，以及应用场景。

* 跳表原理，hash用在购物车会出现什么问题

* zset怎么使用，自己设计一个场景题使用zset

* set实现给帖子点赞如何设计key和value

* 堆排序如何实现

* 令牌桶算法了解吗
  redis为啥可以做缓存
#### redis做缓存一致性怎么解决
「先更新数据库，再删除缓存」的方案虽然保证了数据库与缓存的数据一致性
但是每次更新数据的时候，缓存的数据都会被删除，这样会对缓存的命中率带来影响。
所以，如果我们的业务对缓存命中率有很高的要求，我们可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况。

但是这个方案前面我们也分析过，在两个更新请求并发执行的时候，会出现数据不一致的问题，
因为更新数据库和更新缓存这两个操作是独立的，而我们又没有对操作做任何并发控制，那么当两个线程并发更新它们的话，
就会因为写入顺序的不同造成数据的不一致。
所以我们得增加一些手段来解决这个问题，这里提供两种做法：

在更新缓存前先加个分布式锁，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响。
在更新完缓存时，给缓存加上较短的过期时间，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的。
对了，针对「先删除缓存，再更新数据库」方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「延迟双删」。

延迟双删实现的伪代码如下：

#删除缓存
redis.delKey(X)
#更新数据库
db.update(X)
#睡眠
Thread.sleep(N)
#再删除缓存
redis.delKey(X)
加了个睡眠时间，主要是为了确保请求 A 在睡眠的时候，请求 B 能够在这这一段时间完成「从数据库读取数据，再把缺失的缓存写入缓存」的操作，然后请求 A 睡眠完，再删除缓存。

所以，请求 A 的睡眠时间就需要大于请求 B 「从数据库读取数据 + 写入缓存」的时间。
因此，还是比较建议用「先更新数据库，再删除缓存」的方案。
#### 引入 Redis 作为 MySQL 缓存层，但是这件事情并不是那么简单，因为还要考虑 Redis 和 MySQL 双写一致性的问题。
「先更新数据库，再删缓存」的策略，原因是这个策略即使在并发读写时，也能最大程度保证数据一致性。
「先更新数据库， 再删除缓存」其实是两个操作，这次客户投诉的问题就在于，
在删除缓存（第二个操作）的时候失败了，导致缓存中的数据是旧值，而数据库是最新值。
好在之前给缓存加上了过期时间，所以才会出现客户说的过一段时间才更新生效的现象
，假设如果没有这个过期时间的兜底，那后续的请求读到的就会一直是缓存中的旧数据，这样问题就更大了。
所以新的问题来了，如何保证「先更新数据库 ，再删除缓存」这两个操作能执行成功？

#### 如何保证两个操作都能执行成功？
这次用户的投诉是因为在删除缓存（第二个操作）的时候失败了，导致缓存还是旧值，而数据库是最新值，造成数据库和缓存数据不一致的问题，
会对敏感业务造成影响。
举个例子，来说明下。
应用要把数据 X 的值从 1 更新为 2，先成功更新了数据库，然后在 Redis 缓存中删除 X 的缓存，但是这个操作却失败了，这个时候数据库中 X 的新值为 2，Redis 中的 X 的缓存值为 1，出现了数据库和缓存数据不一致的问题。
那么，后续有访问数据 X 的请求，会先在 Redis 中查询，因为缓存并没有 诶删除，所以会缓存命中，但是读到的却是旧值 1。
其实不管是先操作数据库，还是先操作缓存，只要第二个操作失败都会出现数据一致的问题。

重试机制
我们可以引入消息队列，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。

如果应用删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是重试机制。
当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。
如果删除缓存成功，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。

#订阅 MySQL binlog，再操作缓存
「先更新数据库，再删缓存」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。

于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。

Canal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，
MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。


所以，如果要想保证「先更新数据库，再删缓存」策略第二个操作能执行成功，
我们可以使用「消息队列来重试缓存的删除
或者「订阅 MySQL binlog 再操作缓存」，
这两种方法有一个共同的特点，都是采用异步操作缓存。


* 实现排行榜的zset指令是什么（zrangebyscore）。

* redis雪崩、穿透、击穿
* Redis使用什么机制提高了数据读取和写入的效率？
  Redis怎么保证可用性？
  Redis缓存穿透，缓存击穿，缓存雪崩以及解决方案
  redis的zset是怎么实现的？（哈希表＋跳表），跳表的节点有什么内容？跳表的查询过程是什么样的？复杂度是多少？redis的跳表是双向的，这样设计是为什么？
  Redis用途，持久化（RDB和AOF），启动数据加载流程（回答反了）
  Mysql InnoDB和myISAM区别，事务隔离级别，幻读本质
redis怎么设置过期的？（答给每个数据添加一个属性，过期时间，到了过期时间就删除，猜的）。怎么检查？（周期检查，惰性检查）。

redis是单线程的，为什么这么设计呢？（基于内存，瓶颈不在cpu， 加锁反而会带来性能损失）。 
单线程一定比多线程好吗？
为什么新版本的redis还要变成多线程的？（答 读多写少的时候，加共享锁多线程性能更好）， 那不考虑这种场景，读写差不多的情况下呢？

锁在内核中是怎么实现的呢？（瞎说了个锁总线）

多线程竞争一把锁，会不会出现一个线程永远抢不到锁的情况？这种问题该怎么解决？（答的是 等待久的优先级提升）
Redis分布式锁

如何保证加锁和释放锁是同一个线程操作的

Redis分布式锁容灾问题，如果一个Redis挂了会不会重复拿到这个锁

Redis主从同步

怎么决定主从同步是否需要强同步、异步同步或半同步

#### netstat的原理
netstat是通过读取 /proc/net/路径下的tcp、udp、unix等文件来获取连接信息的。
#### chmod指令 777含义
chmod命令
chmod（change mode）命令是控制用户对文件的权限的命令
**chmod可以使用八进制数来指定权限，无需再使用指定的权限和用户的字母来进行标识，通过读写执行等3个权限的数字来进行设置**
777表示什么
读+写+执行
因为文件的权限分为3种用户，分别为u（文件所有者）、g（文件的组用户）、o（其他用户），所以777表示u、g、o都是777的权限

#### 数据库中索引一般用什么数据结构？

#### B树和B+树有什么区别？

#### 怎么实现分布式锁？

#### 如果当前线程申请了分布式锁，还没处理完就锁的时间要到期了怎么办？
MySQL事务的特性以及底层实现原理

MVCC实现原理

#### 两阶段提交
为什么需要两阶段提交？
* 事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。
举个例子，假设 id = 1 这行数据的字段 name 的值原本是 'jay'，然后执行 UPDATE t_user SET name = 'xiaolin' WHERE id = 1;
* 如果在持久化 redo log 和 binlog 两个日志的过程中，出现了半成功状态，那么就有两种情况：

如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入。
MySQL 重启后，通过 redo log 能将 Buffer Pool 中 id = 1 这行数据的 name 字段恢复到新值 xiaolin，但是 binlog 里面没有记录这条更新语句，
在主从架构中，binlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这一行 name 字段是旧值 jay，与主库的值不一致性；
如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入。
由于 redo log 还没写，崩溃恢复以后这个事务无效，所以 id = 1 这行数据的 name 字段还是旧值 jay，而 binlog 里面记录了这条更新语句，
在主从架构中，binlog 会被复制到从库，从库执行了这条更新语句，那么这一行 name 字段是新值 xiaolin，与主库的值不一致性；
可以看到，在持久化 redo log 和 binlog 这两份日志的时候，如果出现半成功的状态
就会造成主从环境的数据不一致性。
这是因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。

MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决，
* 两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。

两阶段提交把单个事务的提交拆分成了 2 个阶段
分别是「准备（Prepare）阶段」和「提交（Commit）阶段」
每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。
注意，不要把提交（Commit）阶段和 commit 语句混淆了，commit 语句执行的时候，会包含提交（Commit）阶段。

#### 两阶段提交的过程是怎样的？
在 MySQL 的 InnoDB 存储引擎中
开启 binlog 的情况下，MySQL 会同时维护 binlog 日志与 InnoDB 的 redo log
为了保证这两个日志的一致性，MySQL 使用了内部 XA 事务
内部 XA 事务由 binlog 作为协调者，存储引擎是参与者。

当客户端执行 commit 语句或者在自动提交的情况下，MySQL 内部开启一个 XA 事务，分两阶段来完成 XA 事务的提交，如下图：
事务的提交过程有两个阶段，就是将 redo log 的写入拆成了两个步骤：
prepare 和 commit，中间再穿插写入binlog，具体如下：
prepare 阶段：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，
然后将 redo log 刷新到硬盘；
commit 阶段：把 XID 写入到 binlog，然后将 binlog 刷新到磁盘，
接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件，
所以 commit 状态也是会刷盘的）；

#### 刷盘的策略

#### MySQL的锁

#### 什么时候会加意向锁

#### 多个线程同时去操作一行很热的记录肯定会对行锁去竞争，怎么优化

#### MySQL出现死锁怎么解决
在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态：
* 设置事务等待锁的超时时间。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。
在 InnoDB 中，参数 innodb_lock_wait_timeout 是用来设置超时时间的，默认值时 50 秒。
* 开启主动死锁检测。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。
* 将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑，默认就开启。

上面这个两种策略是「当有死锁发生时」的避免方式。
我们可以回归业务的角度来预防死锁，对订单做幂等性校验的目的是为了保证不会出现重复的订单
那我们可以直接将 order_no 字段设置为唯一索引列，利用它的唯一下来保证订单表不会出现重复的订单，
不过有一点不好的地方就是在我们插入一个已经存在的订单记录时就会抛出异常。

#### binlog有哪几种格式
binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：
* STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中
（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。
但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，
这种随时在变的函数会导致复制的数据不一致；
* ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。
* 但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，
* 使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；
* MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；


#### redo log 和 binlog 有什么区别？
这两个日志有四个区别。
* 适用对象不同：
binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；
redo log 是 Innodb 存储引擎实现的日志；
* 文件格式不同：
binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：
STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；
ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。
* 但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；
MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；
redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；
* 写入方式不同：
binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。
redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。
* 用途不同：
binlog 用于备份恢复、主从复制；
redo log 用于掉电等故障恢复。
如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？
不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复。
因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。
binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 binlog 上的数据，都可以恢复，
* 所以如果不小心整个数据库的数据被删除了，得用 binlog 文件恢复数据


### MySQL常见索引类型和使用场景

B+和B树的区别，B+树有什么好处

覆盖索引

最左前缀原则

MySQL主从同步的过程

explain语句
19、如果还需要是可重入锁呢？应该怎么设计？
MySql的执行流程
Innodb的行锁是怎么实现的，
隔离级别
Limit分页的执行流程
2.mysql如何查看最近慢查询。
3.mysql索引什么情况下会失效,  为什么会失效。
4.索引的数据结构，  巴拉巴拉说了一大堆。
5.锁的类型 巴拉巴拉又说了一大堆。
6.动态链接库，静态链接库
7.redis的数据类型。


#### 怎么保证数据库和缓存中的一致性
先删除缓存，再更新数据库，在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题
「先更新数据库 + 再删除缓存」
但是在实际中，这个问题出现的概率并不高。

因为缓存的写入通常要远远快于数据库的写入，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。

而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。

所以，「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的。
如果插入了新数据库，需要往缓存里存吗
先更新数据库， 再删除缓存」其实是两个操作，
前面的所有分析都是建立在这两个操作都能同时执行成功，
而这次客户投诉的问题就在于，在删除缓存（第二个操作）的时候失败了，导致缓存中的数据是旧值。

「先删除缓存，再更新数据库」方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「延迟双删」。

延迟双删实现的伪代码如下：

#删除缓存
redis.delKey(X)
#更新数据库
db.update(X)
#睡眠
Thread.sleep(N)
#再删除缓存
redis.delKey(X)
加了个睡眠时间，主要是为了确保请求 A 在睡眠的时候，
请求 B 能够在这这一段时间完成「从数据库读取数据，再把缺失的缓存写入缓存」的操作，
然后请求 A 睡眠完，再删除缓存。

所以，请求 A 的睡眠时间就需要大于请求 B 「从数据库读取数据 + 写入缓存」的时间。
#### 重试机制
我们可以引入消息队列，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。

如果应用删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是重试机制。
当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。
如果删除缓存成功，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。

#### 订阅 MySQL binlog，再操作缓存
「先更新数据库，再删缓存」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。
于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。
Canal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，
就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。

要想保证「先更新数据库，再删缓存」策略第二个操作能执行成功，
我们可以使用「消息队列来重试缓存的删除」，或者「订阅 MySQL binlog 再操作缓存」，
这两种方法有一个共同的特点，都是采用异步操作缓存。

#### 如果是更新数据库，然后更新缓存，会有什么问题
无论是「先更新数据库，再更新缓存」，还是「先更新缓存，再更新数据库」，这两个方案都存在并发问题，
当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象。

数据库：

性能调优

#### varchar类型的索引，可以前缀匹配吗
前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，
前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。

#### mysql主从复制了解吗

#### MYSQL

#### 数据库的join区别

数据库和缓存的一致性
#### InnoDB和myISARM的区别
####InnoDB
是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。
实现了四个标准的隔离级别，默认级别是可重复读(REPEATABLE READ)。
* 在可重复读隔离级别下，通过多版本并发控制(MVCC)+ 间隙锁(Next-Key Locking)防止幻影读。
* 主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。
* 内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。
支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。
#### MyISAM
设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。
提供了大量的特性，包括压缩表、空间数据索引等。
不支持事务。
不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁
。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入(CONCURRENT INSERT)。
#总结
事务: InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
并发: MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
外键: InnoDB 支持外键。
备份: InnoDB 支持在线热备份。
崩溃恢复: MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
其它特性: MyISAM 支持压缩表和空间数据索引。
事务：MyISAM不支持，InnoDB支持 
锁级别： MyISAM 表级锁，InnoDB 行级锁及外键约束 
MyISAM存储表的总行数；InnoDB不存储总行数；
MyISAM采用非聚集索引，B+树叶子存储指向数据文件的指针。InnoDB主键索引采用聚集索引，B+树叶子存储数据

适用场景： MyISAM适合： 插入不频繁，查询非常频繁，如果执行大量的SELECT，MyISAM是更好的选择， 没有事务。 
InnoDB适合： 可靠性要求比较高，或者要求事务； 表更新和查询都相当的频繁， 大量的INSERT或UPDATE

#### 事务四大特性（ACID）原子性、一致性、隔离性、持久性？

#### 了解索引吗？聚集索引和非聚集索引的区别?

你MySQL运用的场景有哪些？

建表的mysql语句？

索引用过吗？

举了一个联合索引，select * ..... 会不会走索引？

自己有没有设置表？用户表？有没有设计索引？

varchar了解吗？10的长度可以存20吗？
* mysql为什么用B+树，B+树为啥是m叉树不是二叉树

* 单列索引，如果查询的字段不是主键，一定会搜索两次吗？

* 事务的隔离界别，说一下幻读

* b+树的特点

* MySQL 的乐观锁和悲观锁

* 什么语句会加锁？

* 如果知道表的结构，执行 UPDATE 语句你能判断在大概在哪个位置吗？

* 一个事务执行 UPDATE 语句时，执行时间比较长，此时另外一个事务也执行一样的 UPDATE 语句，会出现什么问题？

* 介绍MySQL索引

* 为什么使用B+树而不用B树

* B树适合什么应用场景

* 索引的最左前缀匹配
  
* 索引下推

* 覆盖索引了解吗？

* MySQL事务隔离级别，主要解决哪些问题

* 幻读和脏读的区别

* 幻读怎么避免的 / 事务串行化怎么实现

* 数据库，MVCC了解吗

* 索引匹配原则；

* 给了个sql和一些约束，具体不记得了，问走了索引没，为什么？又写了sql，具体不记得了，问加锁没，加了什么锁？

* mysql的悲观锁和乐观锁怎么实现的

* 为啥用B+树索引，B树索引有什么好处

* Hash为啥不建议做索引数据结构


* mysql相关，mvcc、索引、redolog、undolog、binlog
  mysql事务、事务特性

mysql如何回滚
事务，通过什么实现？除了行锁还有什么？
索引相关
（1）单列索引 a和b select  where a= and b= 先查哪个 那个区分度大查那个 名字>年龄
（2）联合索引 a，b，c 然后查 b，c 会不会用到索引
（3）主键索引和单列索引区别

索引为什么选B+(对比红黑树、哈希表、B树)

如何提高数据库检索速度、索引



数据库 幻读了解吗？

redis几种类型

mysql索引

怎么建立索引？


外键需要索引吗


#### 怎么对数据库做的优化？

#### 你用的pgsql,我不太了解，能讲讲和mysql的区别吗？

#### pgsql如何保证数据一致性？单写是什么？

#### pg和mysql引擎上有什么区别？底层有什么区别？

pg做了哪些优化？底层？

#### 索引？有哪些？有什么特性？

#### 如果删除索引出现问题了导致锁表怎么办？

#### 死锁怎么办？


#### b + 树说一下？索引结构？

#### hash说一下？

#### hash为什么不能范围查找？

#### 索引结构？

#### 聚集索引和非聚集索引？

#### 回表？怎么减少回表？回表出现错误怎么办

#### 产生回表的原因？

#### 举一个需要回表的例子？

#### 什么是索引覆盖？

还有很多问题。。。以及记不清了，反正都是数据库，数据库，数据库。。。。。。。mlb
Redis是否了解过底层？
zset的跳表如何实现的？
Redis如何实现分布式锁
Redis怎么实现限制用户请求的？怎么计数+1的？如果多条线程过来怎么保证线程安全？
AOF和RDB有啥优缺点？AOF重写了解过吗？
缓存穿透，缓存击穿，缓存雪崩，什么概念和解决方案
Redis如何淘汰过期数据？
Kafka使用场景？为什么用？为什么吞吐量高？
MQ如何保证消息不丢失
#### mysql的四大隔离级别，分别解释，并会出现什么问题

#### 解释什么是幻读

#### 解释mvcc

#### 解释 当前读怎么解决幻读问题

#### mysql 的锁有哪几种除了表锁和行锁

#### 18.水平切分和垂直切分，分别在什么场景下用？
案例： 简单购物系统暂设涉及如下表：
1.产品表（数据量10w，稳定）
2.订单表（数据量200w，且有增长趋势）
3.用户表 （数据量100w，且有增长趋势）
以 MySQL 为例讲述下水平拆分和垂直拆分，MySQL能容忍的数量级在百万静态数据可以到千万

* 垂直拆分
解决问题：表与表之间的io竞争
不解决问题：单表中数据量增长出现的压力
方案： 把产品表和用户表放到一个server上 订单表单独放到一个server上

水平拆分
解决问题：单表中数据量增长出现的压力
不解决问题：表与表之间的io争夺
方案：用户表 通过性别拆分为男用户表和女用户表，订单表 通过已完成和完成中拆分为已完成订单和未完成订单，产品表 未完成订单放一个server上，已完成订单表盒男用户表放一个server上，女用户表放一个server上(女的爱购物 哈哈)


####  Redis的优点，Redis在数据持久化的时候用的是哪个代码实现的？
  在redis中生成RDB快照的方式有两种，一种是使用save，另一种是bgsave，但是底层实现上，其调用的是同一个函数，叫rdbsave，只是其调用的方式不同而已。

#### MySQL索引InnoDB中B+树一颗节点的大小
MySQL InnoDB一颗B+树能存多少数据？
MySQL InnoDB的B+树每个非叶子结点能有多少分支？
MySQL InnoDB为什么使用B+树而非B树/Hash？
MySQL InnoDB为什么推荐使用自增ID做主键？
InnoDB
索引类型
我们都知道，MySQL有多种储存引擎，比如：InnoDB，MyISAM，Memory，Merge，Archive，CSV，Blackhole等。
其中最常用的储存引擎就是InnoDB，所以学好InnoDB也是理解MySQL的核心。
InnoDB支持多种索引：

B+树索引 - 传统意义上的索引，B+树索引并不能根据键值找到具体的行数据，B+树索引只能找到行数据锁在的页，然后通过把页读到内存，再在内存中查找到行数据
B+树索引也是最常用的最为频繁使用的索引。
全文索引 - 全文索引是一种比较特殊的索引，一般都是基于倒排索引来实现的，可以解决 like %xxx%语句时，索引会失效的问题。
哈希索引 - 由数据库自身根据你的使用情况创建的，并不能人为的干预，所以叫作自适应哈希索引，采用的是哈希表数据结构。
所以对于字典类型查询就非常的快，但是对于范围查询就无能为力啦。
而要了解InnoDB的性能关键，就是了解它的B+树索引。

文件结构
首先我们需要理解一些基础概念。
InnoDB存储引擎的最小储存单元页（Page），一个页的大小默认是是16K，我们可以通过参数自定义设置大小（修改源码重新编译）。
在InnoDB中B+树的一个节点大小为一页，也就是16k。之所以设置为一页，是因为对于大部分业务，一页就足够了。
但如果表中一行的数据长度超过了16k，这时候就会出现行溢出，溢出的行是存放在另外的地方，存放该溢出数据的页叫uncompresse blob page。

B+树
我们先将数据记录按主键进行排序，分别存放在不同的页中。除了存放数据的数据页以外，还有存放键值+指针的页。
如图中非叶子结点中存放键值和指向数据页的指针，这样的页由多个键值+指针组成。
当然它也是排好序的。这样的数据组织形式，我们称为索引组织表。现在来看下，要查找一条数据，怎么查？


如select * from tab where id = 5;

这里id是主键,我们通过这棵B+树来查找，首先找到根页，我们怎么知道一个表的根页在哪呢？
其实每张表的根页位置在表空间文件中是固定的，即page number=3的页
（找到根页后，通过二分查找法，定位到id=5的数据页中，同样通过二分查询法即可找到id=5的记录。

所有的数据都在叶子节点，且每一个叶子节点都带有指向下一个节点的指针，形成了一个有序的链表。为什么要有序呢？
其实是为了范围查询。

比如说select * from tab where id > 1 and id < 100;

当找到1后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大的提高了范围区间的查询效率。
而哈希索引对这种范围查询是无能为力的。

总结一下：

InnoDB 存储引擎的最小存储单元是页，在B+树中叶子节点存放数据，非叶子节点存放键值+指针。
索引组织表通过非叶子节点的二分查找法以及指针确定数据在哪个页中，进而在去数据页中查找到需要的数据。
以下为B+树的优势：
单一节点存储更多元素，减少IO
所有查询都要找到叶子节点，查询稳定
所有叶子节点形成有序链表，方便范围查询
一般性情况，数据库的B+树的高度一般在2~4层，这就是说找到某一键值的行记录最多需要1到3次逻辑IO，速度是非常快的。
（根节点是常驻内存中的，所以三层树的查询只需要两次磁盘IO）
当然，由上图可得，范围查找的IO次数取决于范围查找的数量。
储存计算
其实储存计算有一个前提，我们要先假设主键ID的大小和一行数据的大小：
我们假设主键ID为bigint类型，8字节。
一行数据大小为1K左右。
这样我们那么一个页可以存放 16 行这样的数据。
数据页16K是一个包含文件头/页头/页尾等结构的数据页。
所以以上只是估算。


那非叶子节点呢？
其实这也很好算，我们假设主键 ID 为 bigint 类型，长度为 8 字节，而指针大小在 InnoDB 源码中设置为 6 字节，这样一共 14 字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针，即 16384/14=1170。

所以我们每个非叶子结点最多有1170个子节点。

那么可以算出一棵高度为 2 的 B+ 树，能存放 1170*16=18720 条这样的数据记录。

根据同样的原理我们可以算出一个高度为 3 的 B+ 树可以存放： 1170*1170*16=21902400 （2100万）条这样的记录。

那如果四层呢：那就是1170*1170*1170*16=256亿。大部分的InnoDB的B+树都是3到4层，3层的性能会更好。
如果主键是4字节，或者一行的数据更少的情况下，那么同样的层数能储存的行数会更多。

现在我们知道了，最多能存放多少数据不是固定的。一般来说我们为了保持3层的B+数层数，大概是千万级的数据量。

这里计算目的是为了让大家更深入的了解InnoDB B+树的知识，做到自己心中有数。其实这个面试题的意思，并不是为了得到一个具体的数字，而是分析这个问题本身。
这样你也知道你的数据表数据量到达多大之后可以开始分库分表了。

相关面试题
现在我们了解了InnoDB B+树的本质，那么以下的几个常见的面试题相信你也有了答案。

每个非叶子结点分支数量
从上面其实我们已经得到答案了：

如果我们的主键是bigint类型（8字节），16384/(8+6)=1170。
如果我们的主键是int类型（4字节），那就是16348/(4+6)=1634。
如果你使用占用空间更大的字符串比如UUID，那么数量会更少。

为什么使用B+树而非B树或Hash
B树
B树和B+树最重要的一个区别就是B+树只有叶节点存放数据，其余节点用来索引，而B树是每个索引节点都会存数据。
存数据意味着用来索引的空间变少，每个节点的子节点变少，想要存放同样的数据量需要更多的层数，更多的磁盘IO次数。
同时对范围查找无法像B+数那样通过链表直接串联起来那么方便。

Hash
Hash的检索效率非常高，但是Hash只能满足 “=”, “IN” 等查询，不能使用范围查询。
同时Hash无法利用索引的数据来进行排序。

为什么推荐使用自增ID做主键
这也是一个常见的面试题。

推荐使用自增ID做主键
通过上文我们知道InnoDB的最小储存单位是页。一个数据页存满了，MySQL就回去申请一个新的数据页来存数据。

如果主键是自增ID，那么就在一页插入满才插入下一页。
如果主键不是自增ID，为了保持B+树的有序，会造成频繁的页分裂和页旋转，插入速度比较慢。
所以聚集索引的主键值应尽量是连续增长的值，而不是随机值(不要用随机字符串或UUID)。
对于InnoDB的主键，尽量用整型，而且是递增的整型。这样在存储/查询上都是非常高效的。

尽量使用更小的主键
在满足业务需求的情况下，尽量使用占空间更小的主键。

主键占用空间越大，每个页存储的主键个数越少，B+树的深度会变长，导致IO次数会变多。
普通索引的叶子节点上保存的是主键 id 的值，如果主键 id 占空间较大的话，那将会成倍增加 MySQL 空间占用大小。

#### 假设一个帖子点赞量很大，一个redis set太大了，该怎么解决？
一、什么是Big Key?

二、Big Key产生的场景？

三、Big Key的危害？

四、如何识别Big Key？

五、如何解决Big Key问题？

一、什么是Big Key?
通俗易懂的讲，Big Key就是某个key对应的value很大，占用的redis空间很大，本质上是大value问题。key往往是程序可以自行设置的，value往往不受程序控制，因此可能导致value很大。

redis中这些Big Key对应的value值很大，在序列化/反序列化过程中花费的时间很大，因此当我们操作Big Key时，通常比较耗时，这就可能导致redis发生阻塞，从而降低redis性能。

用几个实际的例子对大Key的特征进行描述：

● 一个String类型的Key，它的值为5MB（数据过大）；
● 一个List类型的Key，它的列表数量为20000个（列表数量过多）；
● 一个ZSet类型的Key，它的成员数量为10000个（成员数量过多）；
● 一个Hash格式的Key，它的成员数量虽然只有1000个但这些成员的value总大小为100MB（成员体积过大）；

在实际业务中，大Key的判定仍然需要根据Redis的实际使用场景、业务场景来进行综合判断。通常都会以数据大小与成员数量来判定。

二、Big Key产生的场景？
1、redis数据结构使用不恰当
将Redis用在并不适合其能力的场景，造成Key的value过大，如使用String类型的Key存放大体积二进制文件型数据。

2、未及时清理垃圾数据
没有对无效数据进行定期清理，造成如HASH类型Key中的成员持续不断的增加。即一直往value塞数据，却没有删除机制，value只会越来越大。

3、对业务预估不准确
业务上线前规划设计考虑不足没有对Key中的成员进行合理的拆分，造成个别Key中的成员数量过多。

4、明星、网红的粉丝列表、某条热点新闻的评论列表
假设我们使用List数据结构保存某个明星/网红的粉丝，或者保存热点新闻的评论列表，因为粉丝数量巨大，热点新闻因为点击率、评论数会很多，这样List集合中存放的元素就会很多，可能导致value过大，进而产生Big Key问题。

三、Big Key的危害？
1、阻塞请求
Big Key对应的value较大，我们对其进行读写的时候，需要耗费较长的时间，这样就可能阻塞后续的请求处理。Redis的核心线程是单线程，单线程中请求任务的处理是串行的，前面的任务完不成，后面的任务就处理不了。

2、内存增大
读取Big Key耗费的内存比正常Key会有所增大，如果不断变大，可能会引发OOM（内存溢出），或达到redis的最大内存maxmemory设置值引发写阻塞或重要Key被逐出。

3、阻塞网络
读取单value较大时会占用服务器网卡较多带宽，自身变慢的同时可能会影响该服务器上的其他Redis实例或者应用。

4、影响主从同步、主从切换
删除一个大Key造成主库较长时间的阻塞并引发同步中断或主从切换。

四、如何识别Big Key？
1、使用redis自带的命令识别
例如可以使用Redis官方客户端redis-cli加上--bigkeys参数，可以找到某个实例5种数据类型(String、hash、list、set、zset)的最大key。
优点是可以在线扫描，不阻塞服务；缺点是信息较少，内容不够精确。

2、使用debug object key命令
根据传入的对象（Key的名称）来对Key进行分析并返回大量数据，其中serializedlength的值为该Key的序列化长度，需要注意的是，Key的序列化长度并不等同于它在内存空间中的真实长度，此外，debug object属于调试命令，运行代价较大，并且在其运行时，进入Redis的其余请求将会被阻塞直到其执行完毕。并且每次只能查找单个key的信息，官方不推荐使用。

3、redis-rdb-tools开源工具
这种方式是在redis实例上执行bgsave，bgsave会触发redis的快照备份，生成rdb持久化文件，然后对dump出来的rdb文件进行分析，找到其中的大key。
GitHub地址：https://github.com/sripathikrishnan/redis-rdb-tools
优点在于获取的key信息详细、可选参数多、支持定制化需求，结果信息可选择json或csv格式，后续处理方便，其缺点是需要离线操作，获取结果时间较长。

五、如何解决Big Key问题？
要解决Big Key问题，无非就是减小key对应的value值的大小，
也就是对于String数据结构的话，减少存储的字符串的长度；对于List、Hash、Set、ZSet数据结构则是减少集合中元素的个数。

1、对大Key进行拆分
将一个Big Key拆分为多个key-value这样的小Key，并确保每个key的成员数量或者大小在合理范围内，
然后再进行存储，通过get不同的key或者使用mget批量获取。

2、对大Key进行清理
对Redis中的大Key进行清理，从Redis中删除此类数据。R
edis自4.0起提供了UNLINK命令，该命令能够以非阻塞的方式缓慢逐步的清理传入的Key，
通过UNLINK，你可以安全的删除大Key甚至特大Key。

3、监控Redis的内存、网络带宽、超时等指标
通过监控系统并设置合理的Redis内存报警阈值来提醒我们此时可能有大Key正在产生，如：Redis内存使用率超过70%，Redis内存1小时内增长率超过20%等。

4、定期清理失效数据
如果某个Key有业务不断以增量方式写入大量的数据，并且忽略了其时效性，这样会导致大量的失效数据堆积。可以通过定时任务的方式，对失效数据进行清理。

5、压缩value
使用序列化、压缩算法将key的大小控制在合理范围内，但是需要注意序列化、反序列化都会带来一定的消耗。如果压缩后，value还是很大，那么可以进一步对key进行拆分。

#### 假设在此基础上，还需要对点赞按照时间进行一个倒排，取出最新的20个点赞该怎么解决

#### 所以 Redis 采用单线程（网络 I/O 和执行命令）那么快，有如下几个原因：
* Redis 的大部分操作都在内存中完成，并且采用了高效的数据结构，
因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；
* Redis 采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。
* Redis 采用了 I/O 多路复用机制处理大量的客户端 Socket 请求，
* IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。
* 简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，
* 同时存在多个监听 Socket 和已连接 Socket。
* 内核会一直监听这些 Socket 上的连接请求或数据请求。
* 一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。



* 数据库和redis如何保证一致性 （我回答了双写和binlog日志通过消息队列异步同步，但似乎不满意）
* 索引失效 你遇到过哪些（最左前缀和group by）这里埋了个坑，group by我自己忘了为啥会失效我还讲出来，不过的确是真的遇到过。

* 热key 在数据一致性同步时如何处理，
* （我回答双写可能导致db被打爆，就说如果不考虑数据实时一致性的话，就用binlog日志去异步同步。）但是好像也不满意
* 项目里的redis 如何代替raft实现数据一致性
* innodb加锁方式 对行的锁定如何锁定的
### 索引失效：
左、左右模糊匹配
使用函数
表达式计算
隐式转换
非最左匹配
where or

#### select语句的存储引擎执行过程

update加锁方式  加在哪儿 会导致全表锁定吗

有没有做过SQL优化吗？

MySQL慢查询如何优化？
Redis相关场景题，做一个热点课程的榜单功能该怎么实现
Redis用途，持久化（RDB和AOF），启动数据加载流程（回答反了）
redis能存什么类型数据
redis是单线程吗
redis单线程为什么高效
redis过期策略
对redis的理解，项目中的使用：
后端和数据库之间的缓存，存取速度比从数据库快。
为什么有时候单线程能够比多线程更快
redis是哪种IO模型
介绍一下redis底层数据结构
Redis缓存设计
如何保证数据库和redis数据一致性？
Redis：zset底层数据结构，使用场景（评论点赞）
redis的内存淘汰策略？
redis的hash结构，以及博客中如何具体使用
场景题 mysql 中有一万条数据，每个 redis 最多只能存一千条，怎么设计这个redis集群。