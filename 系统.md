
#### 计算机系统

* 进程间通信方式

#### 什么时候可能产生内存泄漏
* 内存泄漏，是指在程序代码中**动态申请的、堆上的内存 由于某种原因、在使用后没有被释放，进而造成内存的浪费**。
少部分的内存泄漏不会影响程序的正常运行，不过如果是持续的内存泄漏会耗光系统内存，最终会导致程序卡死甚至系统崩溃。
* 为了避免系统崩溃，在无法申请到内存的时候，要果断调用exit()函数主动杀死进程，而不是试图挽救这个进程。

* 如何察觉到内存泄漏
如果程序在正常地使用过程中，占用的内存随着时间推移不断增长，一般就说明存在内存泄漏的情况。也可以使用专门的工具来检测程序中的内存泄漏：
在vc++中可以使用 VLD(Visual LeakDetector) 进行检测，VLD 是一个免费开源的工具，只需要包含头文件即可，并且可以获取到内存泄漏的代码文件行号。
Tencent tMem Monitor是腾讯推出的一款运行时C/C++内存泄漏检测工具。TMM认为在进程退出时，堆内存中没有被释放且没有指针指向的无主内存块即为内存泄漏，并进而引入垃圾回收(GC, Garbage Collection)机制，在进程退出时检测出堆内存中所有没有被引用的内存单元，因而内存泄露检测准确率为100%。
gperftools 是 google 开源的一组套件，提供了高性能的、支持多线程的 malloc 实现，以及一组优秀的性能分析工具。gperftools 的 heap chacker 组件可以用于检测 C++ 程序中的内存泄露问题，它可以在不重启程序的情况下，进行内存泄露检查。

* 内存泄漏是如何产生的
最简单的解释就是，主动申请的内存块在使用后没有被释放。最常见的几种造成内存泄漏的原因有：
--malloc/new申请的内存没有主动释放
使用 malloc 申请的内存要主动调用 free，new 申请的内存要主动调用 delete，否则就会导致内存泄漏。
* 例如下面代码中的内存 ptr 在申请后没有被释放就造成了内存泄漏。
int main(){
void* ptr = malloc(1);
// use ptr ...
return 0;
}
* 使用free释放new申请的内存
malloc/free以及new/delete必须是各自成对出现，如果混用，就会导致意想不到的情况出现。
* 另外，如果用delete释放void指针指向的对象同样也会造成内存泄露。
* 使用delete去删除数组
使用 new 申请的数组，释放的时候要用 delete[] 删除，如果错误地使用 delete 删除，就会造成内存泄漏。

int main(){
int* ptr = new int[2];
// usr ptr ...
// delete ptr; // 错误！释放数组要用 delete[]
delete[] ptr; // 正确！
return 0;
}
* 基类的析构函数没有定义为虚函数
当基类指针指向子类对象时，如果基类的析构函数不是virtual，
* 那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。
* 例如下面代码中析构函数 ~A() 不是virtual，在调用 delete pa 的时候就不会调用子类 B 的析构函数，该对象中子类 B 中的内存无法被释放干净。

class A
{
public:
A(){}
~A(){}
}

class B : public A
{
public:
B(){}
~B(){}
private:
int num;
}

void main(){
A* pa = new B();
delete pa;
}

* 该如何避免内存泄漏
内存泄漏会导致程序不稳定，如果是在一个非常复杂的项目中去排查一处内存泄漏的地方，也是非常让人头疼的一件事情，与其研究如何更好地解决问题，
不如研究如何避免问题的发生。

在写代码的时候多花些时间保证代码的质量，往往是一种更为高效的方式。前期如果为了赶进度，匆匆写下的代码，在后期用则需要更多的时间去填坑，这就是“欲速则不达”。

为了避免内存泄漏的情况，有几种方法可以尝试。
* 谨慎使用动态内存
在编写代码的时候，对动态内存保持警惕，保证每一块儿申请的内存都要得到释放。
* 特别是在每个 return 之前，要想一想是否还有内存没有被释放，如果这里不释放，在其他地方是否会正常释放。

这是一种靠脑袋的方式，需要编写代码的时候时刻保持敏感，但是脑袋往往是不可靠的。最好选用其他的方式来保障。
* 使用RAII
RAII，全称资源获取即初始化（英语：Resource Acquisition Is Initialization），通过对象的初始化实现资源获取，
* 通过对象的销毁实现资源的释放，我们所说的资源就是动态内存。
* RAII要求，资源的有效期与持有资源的对象的生命周期严格绑定，通过构造函数获取资源，通过析构函数释放资源，这样就有效地避免了资源泄漏。
例如下面的例子中，通过 MemBlock 类的构造函数分配内存，通过析构函数释放内存，
* 在需要使用动态内存的地方只需要定义一个 MemBlock 对象 buff，通过成员函数 get() 获取内存地址，使用之后无需手动释放内存，
* 在 buff 离开作用域的时候，buff 会被自动释放（调用析构函数），在析构函数中调用 free 释放 buff 所持有的内存。
* 如果在所有需要使用内存的地方都用这种方法，只要保证 MemBlock 对象能被析构，就不会造成内存泄漏。

class MemBlock
{
public:
MemBlock(size_t size)
{
_ptr = malloc(size);
}
~MemBlock()
{
free(_ptr);
}
public:
void* ptr()
{
return _ptr;
}
protected:
void* _ptr;
};

void main(){
MemBlock buff(1024);
memset(buff.ptr(), 0x00, 1024);
// 使用内存后无需主动释放
}

当然，如果通过 new 来申请 MemBlock 对象，就又会存在该对象没有被释放的风险，这个时候使用智能指针来存档 MemBlock 对象将会是一个好的选择。
* 使用智能指针
   就是为了解决动态内存的使用安全问题，C++ 才引入了智能指针的概念，智能指针除了具备普通内存的所有功能之外，
* 还可以保证所指向的对象不再被被引用的时候，自动释放该对象。就这样 C++ 开发人员可以通过智能指针挪走头顶的达摩克里斯之剑。

标准库提供的两种智能指针 shared_ptr 和 unique_ptr，
二者的区别在于管理底层指针的方法不同，shared_ptr允许多个指针指向同一个对象，内部通过引用计数知道对象被几个指针引用，
当引用为0的时候就是该对象将被释放的时候；
unique_ptr 则“独占”所指向的对象，它不能被赋值，智能通过 std::move() 将引用转移到另一个 unique_ptr。
标准库还定义了一种名为weak_ptr的伴随类，它是一种弱引用，作为观察者指向 shared_ptr 所管理的对象，不会改变对象的引用计数。
这三种智能指针都定义在memory头文件中。
使用智能指针直接管理动态内存，在使用之后不需要手动释放，当这段内存不再被引用的时候，
这段内存会被调用 free 函数来释放，free函数是作为自定义的释放函数传给智能指针的，如果是其他类型的对象，不需要传入释放函数，会默认调用类型的析构函数来释放。

shared_ptr<void> ptr(malloc(1024), free); // 传入指定的释放函数
//auto ptr = make_shared<void>(malloc(1024), free); // 等价
memset(ptr.get(), 0x00, 1024);
使用智能指针结合RAII管理动态内存，通过 RAII 将内存的申请和释放进行封装，再使用智能指针管理封装后的类对象。这样实现对内存的自动管理，可以像使用 C# 或 Java 一样使用内存，无需担心内存的释放问题。结合上面定义的 MemBlock 类：
auto mem = make_shared<MemBlock>(1024);
memset(mem->ptr(), 0x00, 1024);
// 使用内存后无需主动释放
内存的申请释放通过MemBlock类的构造函数和析构函数实现，MemBlock 类的对象 mem 使用智能指针管理，不再使用内存的时候，mem 的引用计数变为0，自动被释放析构，同时 free 掉其拥有的内存。
* 如何检测内存泄漏(工具)
* 内存映射
* 页面置换算法有哪些
* 为什么页表一般是4KB - 16KB
* new和malloc的区别，delete析构是谁做的，如果不调用delete会怎么样
* 举个例子说明在什么情况下内存会彻底丢掉无法找回

* 一直申请内存导致不够用会怎么样，OOM会选择哪些进程删除
  -- 内存回收：
  后台内存回收：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。
  直接内存回收：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。
  --oom_badness() 函数，它会把系统中可以被杀掉的进程扫描一遍，并对每个进程打分，得分最高的进程就会被首先杀掉。
* points = process_pages + oom_score_adj * totalpages / 1000
  进程已经使用的物理内存页面数。
  每个进程的 OOM 校准值 oom_score_adj

* malloc出来的内存一定在物理内存上分配了吗
  --不是的，malloc() 分配的是虚拟内存。
  如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。
  只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，
  然后操作系统会建立虚拟内存和物理内存之间的映射关系。

* 介绍一下分页机制，缺页中断，虚拟内存和物理地址的关系

#### C++代码如何变成二进制文件的，动静态链接的优缺点
--C++从代码到可执行程序经历了什么？
--预编译:主要处理源代码文件中的以“#”开头的预编译指令。处理规则见下：
删除所有的#define，展开所有的宏定义。
处理所有的条件预编译指令，如“#if”、“#endif”、“#ifdef”、“#elif”和“#else”。
处理“#include”预编译指令，将文件内容替换到它的位置，这个过程是递归进行的，文件中包含其他 文件。
删除所有的注释，“//”和“/**/”。
保留所有的#pragma 编译器指令，编译器需要用到他们，如：#pragma once 是为了防止有文件被重 复引用。
添加行号和文件标识，便于编译时编译器产生调试用的行号信息，和编译时产生编译错误或警告是 能够显示行号。
--编译
把预编译之后生成的xxx.i或xxx.ii文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应 的汇编代码文件。
词法分析：利用类似于“有限状态机”的算法，将源代码程序输入到扫描机中，将其中的字符序列分 割成一系列的记号。
语法分析：语法分析器对由扫描器产生的记号，进行语法分析，产生语法树。由语法分析器输出的 语法树是一种以表达式为节点的树。
语义分析：语法分析器只是完成了对表达式语法层面的分析，语义分析器则对表达式是否有意义进 行判断，其分析的语义是静态语义——在编译期能分期的语义，相对应的动态语义是在运行期才能确定 的语义。
优化：源代码级别的一个优化过程。
目标代码生成：由代码生成器将中间代码转换成目标机器代码，生成一系列的代码序列——汇编语言 表示。
目标代码优化：目标代码优化器对上述的目标机器代码进行优化：寻找合适的寻址方式、使用位移 来替代乘法运算、删除多余的指令等。
--汇编
将汇编代码转变成机器可以执行的指令(机器码文件)。 
* 汇编器的汇编过程相对于编译器来说更简单，没 有复杂的语法，也没有语义，更不需要做指令优化，
* 只是根据汇编指令和机器指令的对照表一一翻译过 来，汇编过程有汇编器as完成。
* 经汇编之后，产生目标文件(与可执行文件格式几乎一样)xxx.o(Linux 下)、xxx.obj(Window下)。
--链接
将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和动态链 接：
--静态链接
函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，
* 链接器从库中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。
--空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，
--会出现同一个目标文件都在内存存在多个副本；
--更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。
--运行速度快：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西， 在执行的时候运行速度快。
--动态链接
动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，
而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。
共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多份副本，而是这多个程序在执行时共享同一份副本；
更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运 行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。
性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损 失

* 两个二进制文件都运行同一个库文件应该怎么做

* CPU缓存机制是怎么做的，L1、2、3缓存
* linux中写文件write的流程
* ![img.png](img.png)
  第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。
  第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。
  第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。
  第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。

* 为什么开销大

#### 用户态和内核态切换都做了什么

* 为什么有用户态和内核态

* 用户态和内核态的地址空间区别
  --32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间；
  --64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。
#### 虚拟内存的作用
  --虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，
  对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
  --由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。
  进程也没有办法访问其他进程的页表，些页表是私有的，这就解决了多进程之间地址冲突的问题。
  --页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

* 内存4个G，虚拟内存8个G。数据存在哪
  --因为 32 位操作系统，进程最多只能申请 3 GB 大小的虚拟内存空间，所以进程申请 8GB 内存的话
  在申请虚拟内存阶段就会失败（我手上没有 32 位操作系统测试，我估计失败的原因是 OOM）
  --64 位操作系统，进程可以使用 128 TB 大小的虚拟内存空间，所以进程申请 8GB 内存是没问题的，因为进程申请内存是申请虚拟内存，
  只要不读写这个虚拟内存，操作系统就不会分配物理内存。
  如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：
  如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
  如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；

* 什么样的内存访问是效率最高的
  --提高CPU缓存命中率
  数据缓存：是按照内存布局顺序访问
  指令缓存： 利用好CPU 自身的动态分支预测
* 如何高效利用缓存

* 缓存失效策略
  --Linux 操作系统为基于 Page Cache 的读缓存机制提供预读机制，一个例子是：
  应用程序只想读取磁盘上文件 A 的 offset 为 0-3KB 范围内的数据，由于磁盘的基本读写单位为 block（4KB），
  于是操作系统至少会读 0-4KB 的内容，这恰好可以在一个 page 中装下。
  但是操作系统出于空间局部性原理（靠近当前被访问数据的数据，在未来很大概率会被访问到），
  会选择将磁盘块 offset [4KB,8KB)、[8KB,12KB) 以及 [12KB,16KB) 都加载到内存，于是额外在内存中申请了 3 个 page；
  --如何避免预读失效造成的影响？
  要避免预读失效带来影响，最好就是让预读页停留在内存里的时间要尽可能的短，
  让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在内存里的时间尽可能长。
  那到底怎么才能避免呢？
  Linux 操作系统和 MySQL Innodb 通过改进传统 LRU 链表来避免预读失效带来的影响，具体的改进分别如下：
  Linux 操作系统实现两个了 LRU 链表：活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）；
  MySQL 的 Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：young 区域 和 old 区域。
  设计思想：将数据分为了冷数据和热数据，然后分别进行 LRU 算法。不再像传统的 LRU 算法那样，所有数据都只用一个 LRU 算法管理。
* 局部性原理
  --
* 顺序读和随机读的区别
  --
* 单例模式线程安全
  --
* git中merge和rebase区别
  --rebase的解释 ： rebase字面意思就是"变基"，可以直接理解为改变基底。
  feature分支是基于master分支的B拉出来的分支，feature的基底是B。而master在B之后有新的提交，就相当于此时要用master上新的提交来作为feature分支的新基底。
  实际操作为把B之后feature的提交存下来，然后删掉原来这些提交，再找到master的最新提交位置，把存下来的提交再接上去（新节点新commit id）
  如此feature分支的基底就相当于变成了M而不是原来的B了。
  注意，如果master上在B以后没有新提交，那么就还是用原来的B作为基，rebase操作相当于无效，此时和git merge就基本没区别了，
  差异只在于git merge会多一条记录Merge操作的提交记录。
  --推荐使用场景
* 拉公共分支最新代码的时候使用rebase，也就是git pull -r或git pull --rebase，
  但有个缺点就是rebase以后我就不知道我的当前分支最早是从哪个commitid拉出来的了，因为基底变了。
  （如果使用merge，多出无意义的一条提交记录"Merge … to …"）
* 往公共分支上合代码的时候，使用merge。如果使用rebase，那么其他开发人员想看主分支的历史，就不是原来的历史了，历史已经被你篡改了
* 线程和进程
--进程：资源分配和拥有的基本单位
--线程：程序执行的基本单位

* 进程调度的状态
* 进程调度的策略
* 多进程与多线程，它们各自的应用场景是什么。

* 线程，线程安全，锁，CAS，问的比较细
* 数据从磁盘到CPU经过了哪些地方，什么是零拷贝


* 进程和线程的区别
* 进程和线程资源共享问题
* 死锁的概念
* 死锁产生原因
* 死锁的预防
* 死锁的避免

* 键盘输入一个字符，显示器显示出来，发生了什么
#### * 进程调度算法，哪些是抢占式，哪些是非抢占式？
先来先服务调度算法 非抢占式
最短作业优先调度算法 抢占式
高响应比优先调度算法 非抢占式
时间片轮转调度算法 抢占式
最高优先级调度算法 抢占式
多级反馈队列调度算法 抢占式
什么时候会发生 CPU 调度呢？通常有以下情况：
当进程从运行状态转到等待状态；
当进程从运行状态转到就绪状态；
当进程从等待状态转到就绪状态；
当进程从运行状态转到终止状态；
其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。
非抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。
而抢占式调度，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。
你可能会好奇为什么第 3 种情况也会发生 CPU 调度呢？假设有一个进程是处于等待状态的，但是它的优先级比较高，如果该进程等待的事件发生了，它就会转到就绪状态，一旦它转到就绪状态，如果我们的调度算法是以优先级来进行调度的，那么它就会立马抢占正在运行的进程，所以这个时候就会发生 CPU 调度。
那第 2 种状态通常是时间片到的情况，因为时间片到了就会发生中断，于是就会抢占正在运行的进程，从而占用 CPU。
调度算法影响的是等待时间（进程在就绪队列中等待调度的时间总和），而不能影响进程真在使用 CPU 的时间和 I/O 时间。

#### 保证当多个线程时，数据访问安全的问题？
* 为什么说线程不便于资源的管理和保护，而进程相反
* 进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响
* 而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间
* 一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些

#### 缺页异常（缺页中断）。
当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于：
缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。
缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。
缺页中断的处理流程

* 在 CPU 里访问一条 Load M 指令，然后 CPU 会去找 M 所对应的页表项。
* 如果该页表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「无效的」，则 CPU 则会发送缺页中断请求。
操作系统收到了缺页中断，则会执行缺页中断处理函数，先会查找该页面在磁盘中的页面的位置。
找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。
页面从磁盘换入到物理内存完成后，则把页表项中的状态位修改为「有效的」。
最后，CPU 重新执行导致缺页异常的指令。
上面所说的过程，第 4 步是能在物理内存找到空闲页的情况，那如果找不到呢？
找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，
* 如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。

#### 页面置换算法
最佳页面置换算法（OPT）
先进先出置换算法（FIFO）
最近最久未使用的置换算法（LRU）
时钟页面置换算法（Lock）
最不常用置换算法（LFU）

#### 内存泄漏

#### 软中断和硬中断

#### 知道自旋锁吗？和互斥锁有什么区别？

#### 内存为什么要分段？分段就只是为了方便程序员吗？

#### 堆和栈都是存什么数据的，怎么存储的？

#### 栈里除了存函数参数和局部变量还能存放什么？（临时变量）

#### cpu如何调度进程，调度算法？

#### 锁的底层实现

#### 查看负载、内存、cpu的命令

#### 计算机底层为实现并发有哪些支持
epoll的两种触发事件？



为什么用epoll，对比一下select和poll。（老八股了）

reactor还有哪些开源库用到了？

#### 说一下僵尸进程，怎么检测出僵尸进程？


#### 内存模型，那些是线程可以共享的
#### 线程跟栈的关系，刷题时什么时候用到栈
#### 什么情况下会出现栈溢出，怎么防止栈溢出

野指针（产生的原因，访问野指针的后果）
优先级翻转，怎么解决
线程的状态
线程的抢占
系统负载，怎么设计线程的数量

RPC项目

RPC通常都由什么组成

调用逻辑

讲一下服务下线

#### kill一个线程发生了什么

#### 程序中怎么知道线程的状态



#### 段页式存储特点，分别用到什么寄存器了

MVCC

回表和覆盖索引

前缀索引怎么实现的
数据库事务
分布式CAP、BASE、Raft
### CPA ：一个分布式系统不可能同时满足一致性，可用性和分区容错性这三个基本需求，最多只能同时满足其中的2个
* *C（Consistence）*	一致性，指数据在多个副本之间能够保持一致的特性（严格的一致性）。
* *A（Availability）* 可用性，指系统提供的服务必须一直处于可用的状态，每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据。
* *P（Network partitioning）* 分区容错性，分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障。

分区：在分布式系统中，不同的节点分布在不同的子网络中，由于一些特殊的原因，这些子节点之间出现了网络不通的状态，但他们的内部子网络是正常的。**从而导致了整个系统的环境被切分成了若干个孤立的区域。**

### BASE：既是无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，
采用适当的方式来使系统达到最终一致性（Eventual consistency）。
* *Basically Available*(基本可用) 假设系统，出现了不可预知的故障，但还是能用，相比较正常的系统而言；**有响应时间上的损失和功能上的损失**
* *Soft state*（软状态） 相对于原子性而言，要求多个节点的数据副本都是一致的，这是一种 “硬状态”。 而软状态指的是：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即**允许系统在多个不同节点的数据副本存在数据延时**
* *Eventually consistent*（最终一致性）系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问最终都能够获取到最新的值。

Https
Redis的缓存、击穿、穿透
JVM的垃圾收集算法、对象死亡判断

你项目中用到的nginx，那 了解过吗？
客户端怎么实习的；
前面谈到epoll，项目中服务端用到的是边缘触发还是水平触发，回答边缘触发，然后把两个都简单说了区别
怎么保证边缘触发能一次读完数据？
#### fork一个子进程发生了什么？用户态与内核态的区别



11. 数据库与缓存一致性

14. rpc项目中遇到的困难（随便扯了个注册中心）
15. 这个rpc自己有没有在哪个项目中使用了（随便说了自己只有写demo测试过）
16. 用redis做注册中心的问题
17. 操作系统（没学，直接不会）
18. redis的删除策略
19. 说说对hashmap的了解
20. ConcurrentHashMap为什么是线程安全的
21. 线程池的执行流程
22. 线程池核心线程和最大线程数的区别
23. 线程生命周期
24. 线程的阻塞状态（因为上一问说到了，然后又卡住了）
25. 算法题：数组中的第 k 大的数字（直接卡壳了，只会暴力解）
26. 各种排序的时间复杂度
27. 叫我写个排序，然后用来实现这道题（写了一个希尔排序，忘记了好多，扯了好久，最后写出来了）
28. 8. 内核态和用户态区别。
29. 内核态和用户态地址转换是怎么样的。
    我们调试程序的时候会打断点，可以讲一下断点在底层是怎么实现的吗？
    我们在控制台按下ctrl+c的时候发生了什么？在一个进程收到信号退出的时候我们可能希望做一些数据写回保存等操作，怎么实现？

讲一下什么是非阻塞socket



讲一下epoll，它在内核中是怎么实现的？（红黑树）
#### 同步、异步、阻塞、非阻塞，以及它们的区别
同步和异步、阻塞和非阻塞本质上是一对相对的概念。
在进程通信这个层面，同步和异步针对的是发送方而言，取决于将数据写到内核缓冲区进程的行为，继续等待发送则为同步，反之即为异步。
在进程通信这个层面，阻塞非阻塞针对的是接收方而言，取决于将内核中的数据能否立即拷贝到用户空间，如果不能直接拷贝则为阻塞，反之则为非阻塞。
同步：执行一个操作之后，等待结果，然后才继续执行后续的操作。
异步：执行一个操作后，可以去执行其他的操作，然后等待通知再回来执行刚才没执行完的操作。
阻塞：进程给CPU传达一个任务之后，一直等待CPU处理完成，然后才执行后面的操作。
非阻塞：进程给CPU传达任务后，继续处理后续的操作，隔断时间再来询问之前的操作是否完成。这样的过程其实也叫轮询。

阻塞、非阻塞、多路IO复用，都是同步IO，异步必定是非阻塞的，所以不存在异步阻塞和异步非阻塞的说法。
真正的异步IO需要CPU的深度参与。
换句话说，只有用户线程在操作IO的时候根本不去考虑IO的执行全部都交给CPU去完成，而自己只等待一个完成信号的时候，
才是真正的异步IO。所以，拉一个子线程去轮询、去死循环，或者使用select、poll、epool，都不是异步
同步和异步
同步和异步是两种不同的消息通信机制，我们以客户端（调用者）和服务端（被调用者）之间的通信为例：

同步： 就是指客户端调用服务端的某个东西时，在没有得到调用结果之前，该调用就不会返回。也就是说客户端必须等到这个调用返回结果才能继续往后执行；
异步： 和同步相反，调用在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当客户端发送出了一个异步调用后，它不会立刻得到结果，而是在未来的某个时间，服务端通过状态、通知来通知客户端你的这个异步调用成功了，或者也可以通过回调函数来处理这个异步调用的返回结果。
举个通俗的例子，打电话：

你打电话问书店老板有没有某本书，如果是同步通信机制，书店老板会说，“您稍等，我查一下”，然后开始查啊查，等查好了（可能是 5 秒，也可能是一天）告诉你结果（返回结果）；

而异步通信机制，书店老板直接告诉你 “我查一下啊，查好了打电话给你”，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过 “回电” 这种方式来回调。

阻塞和非阻塞
另外，关于同步和异步，需要区别于阻塞和非阻塞，这几个概念经常容易混淆。
阻塞和非阻塞关注的是客户端在等待调用结果时的状态：

阻塞调用，是指调用结果返回之前，客户端的当前线程会被挂起，这个调用线程只有在获取到服务端的调用结果之后才能继续运行；
非阻塞调用，就是说即使客户端的线程无法立即获取到服务端的调用结果，这个线程也不会被阻塞，它可以继续去做其他的事情。
还是上面打电话的例子：

你打电话问书店老板有没有某本书，如果是阻塞式调用，你会一直把自己 “挂起”，直到得到这本书有没有的结果；

如果是非阻塞式调用，你不管老板有没有告诉你，你自己就先去做别的事情了， 当然你也要偶尔过几分钟 check 一下老板这边有没有返回结果。


#### Utf-8与unicode的区别
为什么是红黑树呢？（查询效率吧）

我们知道红黑树是一个有序的，那epoll树是依靠什么排序的呢？（不知道）

客户端多个线程发送请求，在读取响应结果时，怎么和每一个请求线程对应呢？（瞎说了个消息和tid绑定）

tcp和ip层的关系？（ip层只负责主机与主机之间的通信，tcp需要绑定端口实现进程间的通信。tcp是可靠传输的，ip只能尽力交付）

那就仅考虑主机与主机之间的通信？没有可靠保证，是不是就会有大量丢包呢？
整个网络的可靠性全部由传输层来保证吗？（答，可靠这个概念不仅仅是包是都按序全部到达，每一层都有自己的差错控制机制）

怎么理解你说的差错控制这个概念呢？（主要是校验，保证接受到的包和发送的包的数据是一致的）

#### 僵尸进程和孤儿进程


#### 牛客上代码运行的过程，换句话说点击QQ到页面打开的过程，从操作系统的层面思考
操作系统检测类型是否是可执行文件，Windows的可执行文件是PE
创建进程，并且将可执行文件映射到该进程
为该进程设置CPU上下文环境
将代码和数据从磁盘读入内存
运行过程中发生缺页异常则重复4
执行相关系统调用函数，在显示器上显示图标  


多进程 多线程的区别
openmp和mpi
分布式系统的性质，及其实现原理。
我从CAP入手，讲了一下在CA之间的平衡策略。
分布式系统的几种一致性（强一致性、最终一致性、弱一致性）。

分布式消息队列的消费数据如何保证幂等性

实习内容介绍
自定义延迟队列如何实现，是否可以使用redis解决等
linux内核有什么功能

#### 第二部分：操作系统

* 进程和线程有什么区别？

* 哪些资源是线程独占的？

* 线程死循环会导致所在进程（单线程进程和多线程进程）出现什么问题，有什么影响？出现假死现象（一定会出现假死吗？）
  CPU会飙升吗？
* 线程崩溃会导致进程崩溃吗？一定会导致进程崩溃吗？

* 线程崩溃之后会使用什么方式通知进程呢？

* fork()之前创建的socket，父子进程能否同时读/写此socket？
  fork()创建的socket，父子进程可以同时读/写此socket，父子进程会轮流获得socket读/写权，这点好像和1）冲突，需要详细研究内因。

守护进程、僵尸进程和孤儿进程
#### 守护进程
* 指在后台运行的，没有控制终端与之相连的进程。
* 它独立于控制终端，周期性地执行某种任务。Linux的大多数服务器就是用守护进程的方式实现的，如web服务器进程http等

创建守护进程要点：

（1）让程序在后台执行。方法是调用fork（）产生一个子进程，然后使父进程退出。

（2）调用setsid（）创建一个新对话期。控制终端、登录会话和进程组通常是从父进程继承下来的，守护进程要摆脱它们，不受它们的影响，方法是调用setsid（）使进程成为一个会话组长。setsid（）调用成功后，进程成为新的会话组长和进程组长，并与原来的登录会话、进程组和控制终端脱离。

（3）禁止进程重新打开控制终端。经过以上步骤，进程已经成为一个无终端的会话组长，但是它可以重新申请打开一个终端。为了避免这种情况发生，可以通过使进程不再是会话组长来实现。再一次通过fork（）创建新的子进程，使调用fork的进程退出。

（4）关闭不再需要的文件描述符。子进程从父进程继承打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误。首先获得最高文件描述符值，然后用一个循环程序，关闭0到最高文件描述符值的所有文件描述符。

（5）将当前目录更改为根目录。

（6）子进程从父进程继承的文件创建屏蔽字可能会拒绝某些许可权。为防止这一点，使用unmask（0）将屏蔽字清零。

（7）处理SIGCHLD信号。对于服务器进程，在请求到来时往往生成子进程处理请求。如果子进程等待父进程捕获状态，则子进程将成为僵尸进程（zombie），从而占用系统资源。如果父进程等待子进程结束，将增加父进程的负担，影响服务器进程的并发性能。在Linux下可以简单地将SIGCHLD信号的操作设为SIG_IGN。这样，子进程结束时不会产生僵尸进程。

* 孤儿进程
如果父进程先退出，子进程还没退出，那么子进程的父进程将变为init进程。（注：任何一个进程都必须有父进程）。

一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。
孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

* 僵尸进程
如果子进程先退出，父进程还没退出，那么子进程必须等到父进程捕获到了子进程的退出状态才真正结束，否则这个时候子进程就成为僵尸进程。

设置僵尸进程的目的是维护子进程的信息，以便父进程在以后某个时候获取。
这些信息至少包括进程ID，进程的终止状态，以及该进程使用的CPU时间，所以当终止子进程的父进程调用wait或waitpid时就可以得到这些信息。
如果一个进程终止，而该进程有子进程处于僵尸状态，那么它的所有僵尸子进程的父进程ID将被重置为1（init进程）。
继承这些子进程的init进程将清理它们（也就是说init进程将wait它们，从而去除它们的僵尸状态）。

#### 如何避免僵尸进程？
通过signal(SIGCHLD, SIG_IGN)通知内核对子进程的结束不关心，由内核回收。
如果不想让父进程挂起，可以在父进程中加入一条语句：signal(SIGCHLD,SIG_IGN);
表示父进程忽略SIGCHLD信号，该信号是子进程退出的时候向父进程发送的。

父进程调用wait/waitpid等函数等待子进程结束，如果尚无子进程退出wait会导致父进程阻塞。
waitpid可以通过传递WNOHANG使父进程不阻塞立即返回。

如果父进程很忙可以用signal注册信号处理函数，在信号处理函数调用wait/waitpid等待子进程退出。

通过两次调用fork。父进程首先调用fork创建一个子进程然后waitpid等待子进程退出，子进程再fork一个孙进程后退出。
这样子进程退出后会被父进程等待回收，而对于孙子进程其父进程已经退出所以孙进程成为一个孤儿进程，孤儿进程由init进程接管，
孙进程结束后，init会等待回收。
第一种方法忽略SIGCHLD信号，这常用于并发服务器的性能的一个技巧因为并发服务器常常fork很多子进程，子进程终结之后需要服务器进程去wait清理资源。
如果将此信号的处理方式设为忽略，可让内核把僵尸子进程转交给init进程去处理，省去了大量僵尸进程占用系统资源。

#### 局部性原理你知道吗？主要有哪两大局部性原理？各自是什么？
主要分为时间局部性和空间局部性。

时间局部性:如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行;
如果某个数据被访问过，不久之后该数据很可能再次被访问。(因为程序中存在大量的循环) 
空间局部性:一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。
(因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的)