
#### 计算机系统

* 进程间通信方式

#### 什么时候可能产生内存泄漏
* 内存泄漏，是指在程序代码中**动态申请的、堆上的内存 由于某种原因、在使用后没有被释放，进而造成内存的浪费**。
少部分的内存泄漏不会影响程序的正常运行，不过如果是持续的内存泄漏会耗光系统内存，最终会导致程序卡死甚至系统崩溃。
* 为了避免系统崩溃，在无法申请到内存的时候，要果断调用exit()函数主动杀死进程，而不是试图挽救这个进程。

* 如何察觉到内存泄漏
如果程序在正常地使用过程中，占用的内存随着时间推移不断增长，一般就说明存在内存泄漏的情况。也可以使用专门的工具来检测程序中的内存泄漏：
在vc++中可以使用 VLD(Visual LeakDetector) 进行检测，VLD 是一个免费开源的工具，只需要包含头文件即可，并且可以获取到内存泄漏的代码文件行号。
Tencent tMem Monitor是腾讯推出的一款运行时C/C++内存泄漏检测工具。TMM认为在进程退出时，堆内存中没有被释放且没有指针指向的无主内存块即为内存泄漏，并进而引入垃圾回收(GC, Garbage Collection)机制，在进程退出时检测出堆内存中所有没有被引用的内存单元，因而内存泄露检测准确率为100%。
gperftools 是 google 开源的一组套件，提供了高性能的、支持多线程的 malloc 实现，以及一组优秀的性能分析工具。gperftools 的 heap chacker 组件可以用于检测 C++ 程序中的内存泄露问题，它可以在不重启程序的情况下，进行内存泄露检查。

* 内存泄漏是如何产生的
最简单的解释就是，主动申请的内存块在使用后没有被释放。最常见的几种造成内存泄漏的原因有：
--malloc/new申请的内存没有主动释放
使用 malloc 申请的内存要主动调用 free，new 申请的内存要主动调用 delete，否则就会导致内存泄漏。
* 例如下面代码中的内存 ptr 在申请后没有被释放就造成了内存泄漏。
int main(){
void* ptr = malloc(1);
// use ptr ...
return 0;
}
* 使用free释放new申请的内存
malloc/free以及new/delete必须是各自成对出现，如果混用，就会导致意想不到的情况出现。
* 另外，如果用delete释放void指针指向的对象同样也会造成内存泄露。
* 使用delete去删除数组
使用 new 申请的数组，释放的时候要用 delete[] 删除，如果错误地使用 delete 删除，就会造成内存泄漏。

int main(){
int* ptr = new int[2];
// usr ptr ...
// delete ptr; // 错误！释放数组要用 delete[]
delete[] ptr; // 正确！
return 0;
}
* 基类的析构函数没有定义为虚函数
当基类指针指向子类对象时，如果基类的析构函数不是virtual，
* 那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。
* 例如下面代码中析构函数 ~A() 不是virtual，在调用 delete pa 的时候就不会调用子类 B 的析构函数，该对象中子类 B 中的内存无法被释放干净。

class A
{
public:
A(){}
~A(){}
}

class B : public A
{
public:
B(){}
~B(){}
private:
int num;
}

void main(){
A* pa = new B();
delete pa;
}

* 该如何避免内存泄漏
内存泄漏会导致程序不稳定，如果是在一个非常复杂的项目中去排查一处内存泄漏的地方，也是非常让人头疼的一件事情，与其研究如何更好地解决问题，
不如研究如何避免问题的发生。

在写代码的时候多花些时间保证代码的质量，往往是一种更为高效的方式。前期如果为了赶进度，匆匆写下的代码，在后期用则需要更多的时间去填坑，这就是“欲速则不达”。

为了避免内存泄漏的情况，有几种方法可以尝试。
* 谨慎使用动态内存
在编写代码的时候，对动态内存保持警惕，保证每一块儿申请的内存都要得到释放。
* 特别是在每个 return 之前，要想一想是否还有内存没有被释放，如果这里不释放，在其他地方是否会正常释放。

这是一种靠脑袋的方式，需要编写代码的时候时刻保持敏感，但是脑袋往往是不可靠的。最好选用其他的方式来保障。
* 使用RAII
RAII，全称资源获取即初始化（英语：Resource Acquisition Is Initialization），通过对象的初始化实现资源获取，
* 通过对象的销毁实现资源的释放，我们所说的资源就是动态内存。
* RAII要求，资源的有效期与持有资源的对象的生命周期严格绑定，通过构造函数获取资源，通过析构函数释放资源，这样就有效地避免了资源泄漏。
例如下面的例子中，通过 MemBlock 类的构造函数分配内存，通过析构函数释放内存，
* 在需要使用动态内存的地方只需要定义一个 MemBlock 对象 buff，通过成员函数 get() 获取内存地址，使用之后无需手动释放内存，
* 在 buff 离开作用域的时候，buff 会被自动释放（调用析构函数），在析构函数中调用 free 释放 buff 所持有的内存。
* 如果在所有需要使用内存的地方都用这种方法，只要保证 MemBlock 对象能被析构，就不会造成内存泄漏。

class MemBlock
{
public:
MemBlock(size_t size)
{
_ptr = malloc(size);
}
~MemBlock()
{
free(_ptr);
}
public:
void* ptr()
{
return _ptr;
}
protected:
void* _ptr;
};

void main(){
MemBlock buff(1024);
memset(buff.ptr(), 0x00, 1024);
// 使用内存后无需主动释放
}

当然，如果通过 new 来申请 MemBlock 对象，就又会存在该对象没有被释放的风险，这个时候使用智能指针来存档 MemBlock 对象将会是一个好的选择。
* 使用智能指针
   就是为了解决动态内存的使用安全问题，C++ 才引入了智能指针的概念，智能指针除了具备普通内存的所有功能之外，
* 还可以保证所指向的对象不再被被引用的时候，自动释放该对象。就这样 C++ 开发人员可以通过智能指针挪走头顶的达摩克里斯之剑。

标准库提供的两种智能指针 shared_ptr 和 unique_ptr，
二者的区别在于管理底层指针的方法不同，shared_ptr允许多个指针指向同一个对象，内部通过引用计数知道对象被几个指针引用，
当引用为0的时候就是该对象将被释放的时候；
unique_ptr 则“独占”所指向的对象，它不能被赋值，智能通过 std::move() 将引用转移到另一个 unique_ptr。
标准库还定义了一种名为weak_ptr的伴随类，它是一种弱引用，作为观察者指向 shared_ptr 所管理的对象，不会改变对象的引用计数。
这三种智能指针都定义在memory头文件中。
使用智能指针直接管理动态内存，在使用之后不需要手动释放，当这段内存不再被引用的时候，
这段内存会被调用 free 函数来释放，free函数是作为自定义的释放函数传给智能指针的，如果是其他类型的对象，不需要传入释放函数，会默认调用类型的析构函数来释放。

shared_ptr<void> ptr(malloc(1024), free); // 传入指定的释放函数
//auto ptr = make_shared<void>(malloc(1024), free); // 等价
memset(ptr.get(), 0x00, 1024);
使用智能指针结合RAII管理动态内存，通过 RAII 将内存的申请和释放进行封装，再使用智能指针管理封装后的类对象。这样实现对内存的自动管理，可以像使用 C# 或 Java 一样使用内存，无需担心内存的释放问题。结合上面定义的 MemBlock 类：
auto mem = make_shared<MemBlock>(1024);
memset(mem->ptr(), 0x00, 1024);
// 使用内存后无需主动释放
内存的申请释放通过MemBlock类的构造函数和析构函数实现，MemBlock 类的对象 mem 使用智能指针管理，不再使用内存的时候，mem 的引用计数变为0，自动被释放析构，同时 free 掉其拥有的内存。
* 如何检测内存泄漏(工具)
* 内存映射
* 页面置换算法有哪些
* 为什么页表一般是4KB - 16KB
* new和malloc的区别，delete析构是谁做的，如果不调用delete会怎么样
* 举个例子说明在什么情况下内存会彻底丢掉无法找回

* 一直申请内存导致不够用会怎么样，OOM会选择哪些进程删除
  -- 内存回收：
  后台内存回收：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。
  直接内存回收：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。
  --oom_badness() 函数，它会把系统中可以被杀掉的进程扫描一遍，并对每个进程打分，得分最高的进程就会被首先杀掉。
* points = process_pages + oom_score_adj * totalpages / 1000
  进程已经使用的物理内存页面数。
  每个进程的 OOM 校准值 oom_score_adj

* malloc出来的内存一定在物理内存上分配了吗
  --不是的，malloc() 分配的是虚拟内存。
  如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。
  只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，
  然后操作系统会建立虚拟内存和物理内存之间的映射关系。

* 介绍一下分页机制，缺页中断，虚拟内存和物理地址的关系

#### C++代码如何变成二进制文件的，动静态链接的优缺点
--C++从代码到可执行程序经历了什么？
--预编译:主要处理源代码文件中的以“#”开头的预编译指令。处理规则见下：
删除所有的#define，展开所有的宏定义。
处理所有的条件预编译指令，如“#if”、“#endif”、“#ifdef”、“#elif”和“#else”。
处理“#include”预编译指令，将文件内容替换到它的位置，这个过程是递归进行的，文件中包含其他 文件。
删除所有的注释，“//”和“/**/”。
保留所有的#pragma 编译器指令，编译器需要用到他们，如：#pragma once 是为了防止有文件被重 复引用。
添加行号和文件标识，便于编译时编译器产生调试用的行号信息，和编译时产生编译错误或警告是 能够显示行号。
--编译
把预编译之后生成的xxx.i或xxx.ii文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应 的汇编代码文件。
词法分析：利用类似于“有限状态机”的算法，将源代码程序输入到扫描机中，将其中的字符序列分 割成一系列的记号。
语法分析：语法分析器对由扫描器产生的记号，进行语法分析，产生语法树。由语法分析器输出的 语法树是一种以表达式为节点的树。
语义分析：语法分析器只是完成了对表达式语法层面的分析，语义分析器则对表达式是否有意义进 行判断，其分析的语义是静态语义——在编译期能分期的语义，相对应的动态语义是在运行期才能确定 的语义。
优化：源代码级别的一个优化过程。
目标代码生成：由代码生成器将中间代码转换成目标机器代码，生成一系列的代码序列——汇编语言 表示。
目标代码优化：目标代码优化器对上述的目标机器代码进行优化：寻找合适的寻址方式、使用位移 来替代乘法运算、删除多余的指令等。
--汇编
将汇编代码转变成机器可以执行的指令(机器码文件)。 
* 汇编器的汇编过程相对于编译器来说更简单，没 有复杂的语法，也没有语义，更不需要做指令优化，
* 只是根据汇编指令和机器指令的对照表一一翻译过 来，汇编过程有汇编器as完成。
* 经汇编之后，产生目标文件(与可执行文件格式几乎一样)xxx.o(Linux 下)、xxx.obj(Window下)。
--链接
将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和动态链 接：
--静态链接
函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，
* 链接器从库中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。
--空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，
--会出现同一个目标文件都在内存存在多个副本；
--更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。
--运行速度快：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西， 在执行的时候运行速度快。
--动态链接
动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，
而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。
共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多份副本，而是这多个程序在执行时共享同一份副本；
更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运 行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。
性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损 失

* 两个二进制文件都运行同一个库文件应该怎么做

* CPU缓存机制是怎么做的，L1、2、3缓存
* linux中写文件write的流程
* ![img.png](img.png)
  第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。
  第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。
  第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。
  第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。

* 为什么开销大

#### 用户态和内核态切换都做了什么

* 为什么有用户态和内核态

* 用户态和内核态的地址空间区别
  --32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间；
  --64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。
#### 虚拟内存的作用
  --虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
  --由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，些页表是私有的，这就解决了多进程之间地址冲突的问题。
  --页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

* 内存4个G，虚拟内存8个G。数据存在哪
  --因为 32 位操作系统，进程最多只能申请 3 GB 大小的虚拟内存空间，所以进程申请 8GB 内存的话
  在申请虚拟内存阶段就会失败（我手上没有 32 位操作系统测试，我估计失败的原因是 OOM）
  --64 位操作系统，进程可以使用 128 TB 大小的虚拟内存空间，所以进程申请 8GB 内存是没问题的，因为进程申请内存是申请虚拟内存，
  只要不读写这个虚拟内存，操作系统就不会分配物理内存。
  如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：
  如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
  如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；

* 什么样的内存访问是效率最高的
  --提高CPU缓存命中率
  数据缓存：是按照内存布局顺序访问
  指令缓存： 利用好CPU 自身的动态分支预测
* 如何高效利用缓存

* 缓存失效策略
  --Linux 操作系统为基于 Page Cache 的读缓存机制提供预读机制，一个例子是：
  应用程序只想读取磁盘上文件 A 的 offset 为 0-3KB 范围内的数据，由于磁盘的基本读写单位为 block（4KB），
  于是操作系统至少会读 0-4KB 的内容，这恰好可以在一个 page 中装下。
  但是操作系统出于空间局部性原理（靠近当前被访问数据的数据，在未来很大概率会被访问到），
  会选择将磁盘块 offset [4KB,8KB)、[8KB,12KB) 以及 [12KB,16KB) 都加载到内存，于是额外在内存中申请了 3 个 page；
  --如何避免预读失效造成的影响？
  要避免预读失效带来影响，最好就是让预读页停留在内存里的时间要尽可能的短，
  让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在内存里的时间尽可能长。
  那到底怎么才能避免呢？
  Linux 操作系统和 MySQL Innodb 通过改进传统 LRU 链表来避免预读失效带来的影响，具体的改进分别如下：
  Linux 操作系统实现两个了 LRU 链表：活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）；
  MySQL 的 Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：young 区域 和 old 区域。
  设计思想：将数据分为了冷数据和热数据，然后分别进行 LRU 算法。不再像传统的 LRU 算法那样，所有数据都只用一个 LRU 算法管理。
* 局部性原理
  --
* 顺序读和随机读的区别
  --
* 单例模式线程安全
  --
* git中merge和rebase区别
  --rebase的解释 ： rebase字面意思就是"变基"，可以直接理解为改变基底。
  feature分支是基于master分支的B拉出来的分支，feature的基底是B。而master在B之后有新的提交，就相当于此时要用master上新的提交来作为feature分支的新基底。
  实际操作为把B之后feature的提交存下来，然后删掉原来这些提交，再找到master的最新提交位置，把存下来的提交再接上去（新节点新commit id）
  如此feature分支的基底就相当于变成了M而不是原来的B了。
  注意，如果master上在B以后没有新提交，那么就还是用原来的B作为基，rebase操作相当于无效，此时和git merge就基本没区别了，
  差异只在于git merge会多一条记录Merge操作的提交记录。
  --推荐使用场景
* 拉公共分支最新代码的时候使用rebase，也就是git pull -r或git pull --rebase，
  但有个缺点就是rebase以后我就不知道我的当前分支最早是从哪个commitid拉出来的了，因为基底变了。
  （如果使用merge，多出无意义的一条提交记录"Merge … to …"）
* 往公共分支上合代码的时候，使用merge。如果使用rebase，那么其他开发人员想看主分支的历史，就不是原来的历史了，历史已经被你篡改了
* 线程和进程
--进程：资源分配和拥有的基本单位
--线程：程序执行的基本单位

* 进程调度的状态

* 多进程与多线程，它们各自的应用场景是什么。

* 线程，线程安全，锁，CAS，问的比较细
* 数据从磁盘到CPU经过了哪些地方，什么是零拷贝
* 进程和线程的区别
* 进程和线程资源共享问题
* 死锁的概念
* 死锁产生原因
* 死锁的预防
* 死锁的避免

* 键盘输入一个字符，显示器显示出来，发生了什么

#### 保证当多个线程时，数据访问安全的问题？
* 为什么说线程不便于资源的管理和保护，而进程相反


#### 内存泄漏

#### 软中断和硬中断

#### 知道自旋锁吗？和互斥锁有什么区别？

#### 内存为什么要分段？分段就只是为了方便程序员吗？

#### 堆和栈都是存什么数据的，怎么存储的？

#### 栈里除了存函数参数和局部变量还能存放什么？（临时变量）

#### cpu如何调度进程，调度算法？

#### 锁的底层实现

#### 查看负载、内存、cpu的命令

#### 计算机底层为实现并发有哪些支持
epoll的两种触发事件？



为什么用epoll，对比一下select和poll。（老八股了）

reactor还有哪些开源库用到了？

#### 说一下僵尸进程，怎么检测出僵尸进程？


#### 内存模型，那些是线程可以共享的
#### 线程跟栈的关系，刷题时什么时候用到栈
#### 什么情况下会出现栈溢出，怎么防止栈溢出

野指针（产生的原因，访问野指针的后果）
优先级翻转，怎么解决
线程的状态
线程的抢占
系统负载，怎么设计线程的数量

RPC项目

RPC通常都由什么组成

调用逻辑

讲一下服务下线

#### kill一个线程发生了什么

#### 程序中怎么知道线程的状态



#### 段页式存储特点，分别用到什么寄存器了

MVCC

回表和覆盖索引

前缀索引怎么实现的
数据库事务
分布式CAP、BASE、Raft
Https
Redis的缓存、击穿、穿透
JVM的垃圾收集算法、对象死亡判断

你项目中用到的nginx，那 了解过吗？
客户端怎么实习的；
前面谈到epoll，项目中服务端用到的是边缘触发还是水平触发，回答边缘触发，然后把两个都简单说了区别
怎么保证边缘触发能一次读完数据？
#### fork一个子进程发生了什么？用户态与内核态的区别



11. 数据库与缓存一致性

14. rpc项目中遇到的困难（随便扯了个注册中心）
15. 这个rpc自己有没有在哪个项目中使用了（随便说了自己只有写demo测试过）
16. 用redis做注册中心的问题
17. 操作系统（没学，直接不会）
18. redis的删除策略
19. 说说对hashmap的了解
20. ConcurrentHashMap为什么是线程安全的
21. 线程池的执行流程
22. 线程池核心线程和最大线程数的区别
23. 线程生命周期
24. 线程的阻塞状态（因为上一问说到了，然后又卡住了）
25. 算法题：数组中的第 k 大的数字（直接卡壳了，只会暴力解）
26. 各种排序的时间复杂度
27. 叫我写个排序，然后用来实现这道题（写了一个希尔排序，忘记了好多，扯了好久，最后写出来了）
28. 8. 内核态和用户态区别。
29. 内核态和用户态地址转换是怎么样的。
    我们调试程序的时候会打断点，可以讲一下断点在底层是怎么实现的吗？
    我们在控制台按下ctrl+c的时候发生了什么？在一个进程收到信号退出的时候我们可能希望做一些数据写回保存等操作，怎么实现？

讲一下什么是非阻塞socket



讲一下epoll，它在内核中是怎么实现的？（红黑树）
#### 同步、异步、阻塞、非阻塞，以及它们的区别
同步和异步、阻塞和非阻塞本质上是一对相对的概念。
在进程通信这个层面，同步和异步针对的是发送方而言，取决于将数据写到内核缓冲区进程的行为，继续等待发送则为同步，反之即为异步。
在进程通信这个层面，阻塞非阻塞针对的是接收方而言，取决于将内核中的数据能否立即拷贝到用户空间，如果不能直接拷贝则为阻塞，反之则为非阻塞。
同步：执行一个操作之后，等待结果，然后才继续执行后续的操作。
异步：执行一个操作后，可以去执行其他的操作，然后等待通知再回来执行刚才没执行完的操作。
阻塞：进程给CPU传达一个任务之后，一直等待CPU处理完成，然后才执行后面的操作。
非阻塞：进程给CPU传达任务后，继续处理后续的操作，隔断时间再来询问之前的操作是否完成。这样的过程其实也叫轮询。

阻塞、非阻塞、多路IO复用，都是同步IO，异步必定是非阻塞的，所以不存在异步阻塞和异步非阻塞的说法。
真正的异步IO需要CPU的深度参与。
换句话说，只有用户线程在操作IO的时候根本不去考虑IO的执行全部都交给CPU去完成，而自己只等待一个完成信号的时候，
才是真正的异步IO。所以，拉一个子线程去轮询、去死循环，或者使用select、poll、epool，都不是异步
同步和异步
同步和异步是两种不同的消息通信机制，我们以客户端（调用者）和服务端（被调用者）之间的通信为例：

同步： 就是指客户端调用服务端的某个东西时，在没有得到调用结果之前，该调用就不会返回。也就是说客户端必须等到这个调用返回结果才能继续往后执行；
异步： 和同步相反，调用在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当客户端发送出了一个异步调用后，它不会立刻得到结果，而是在未来的某个时间，服务端通过状态、通知来通知客户端你的这个异步调用成功了，或者也可以通过回调函数来处理这个异步调用的返回结果。
举个通俗的例子，打电话：

你打电话问书店老板有没有某本书，如果是同步通信机制，书店老板会说，“您稍等，我查一下”，然后开始查啊查，等查好了（可能是 5 秒，也可能是一天）告诉你结果（返回结果）；

而异步通信机制，书店老板直接告诉你 “我查一下啊，查好了打电话给你”，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过 “回电” 这种方式来回调。

阻塞和非阻塞
另外，关于同步和异步，需要区别于阻塞和非阻塞，这几个概念经常容易混淆。
阻塞和非阻塞关注的是客户端在等待调用结果时的状态：

阻塞调用，是指调用结果返回之前，客户端的当前线程会被挂起，这个调用线程只有在获取到服务端的调用结果之后才能继续运行；
非阻塞调用，就是说即使客户端的线程无法立即获取到服务端的调用结果，这个线程也不会被阻塞，它可以继续去做其他的事情。
还是上面打电话的例子：

你打电话问书店老板有没有某本书，如果是阻塞式调用，你会一直把自己 “挂起”，直到得到这本书有没有的结果；

如果是非阻塞式调用，你不管老板有没有告诉你，你自己就先去做别的事情了， 当然你也要偶尔过几分钟 check 一下老板这边有没有返回结果。


#### Utf-8与unicode的区别
为什么是红黑树呢？（查询效率吧）

我们知道红黑树是一个有序的，那epoll树是依靠什么排序的呢？（不知道）

客户端多个线程发送请求，在读取响应结果时，怎么和每一个请求线程对应呢？（瞎说了个消息和tid绑定）

tcp和ip层的关系？（ip层只负责主机与主机之间的通信，tcp需要绑定端口实现进程间的通信。tcp是可靠传输的，ip只能尽力交付）

那就仅考虑主机与主机之间的通信？没有可靠保证，是不是就会有大量丢包呢？
整个网络的可靠性全部由传输层来保证吗？（答，可靠这个概念不仅仅是包是都按序全部到达，每一层都有自己的差错控制机制）

怎么理解你说的差错控制这个概念呢？（主要是校验，保证接受到的包和发送的包的数据是一致的）