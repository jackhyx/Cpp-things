
#### 计算机系统

* 进程间通信方式

* 什么时候可能产生内存泄漏
* 如何检测内存泄漏(工具)
* 内存映射
* 页面置换算法有哪些
* 为什么页表一般是4KB - 16KB
* new和malloc的区别，delete析构是谁做的，如果不调用delete会怎么样
* 举个例子说明在什么情况下内存会彻底丢掉无法找回

* 一直申请内存导致不够用会怎么样，OOM会选择哪些进程删除
  -- 内存回收：
  后台内存回收：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。
  直接内存回收：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。
  --oom_badness() 函数，它会把系统中可以被杀掉的进程扫描一遍，并对每个进程打分，得分最高的进程就会被首先杀掉。
* points = process_pages + oom_score_adj * totalpages / 1000
  进程已经使用的物理内存页面数。
  每个进程的 OOM 校准值 oom_score_adj

* malloc出来的内存一定在物理内存上分配了吗
  --不是的，malloc() 分配的是虚拟内存。
  如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。
  只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，
  然后操作系统会建立虚拟内存和物理内存之间的映射关系。
* 介绍一下分页机制，缺页中断，虚拟内存和物理地址的关系

* C++代码如何变成二进制文件的，动静态链接的优缺点

* 两个二进制文件都运行同一个库文件应该怎么做

* CPU缓存机制是怎么做的，L1、2、3缓存
* linux中写文件write的流程
* ![img.png](img.png)
  第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。
  第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。
  第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。
  第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。

* 为什么开销大
* 用户态和内核态切换都做了什么
* 为什么有用户态和内核态
* 用户态和内核态的地址空间区别
  --32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间；
  --64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。
* 虚拟内存的作用
  --虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
  --由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，些页表是私有的，这就解决了多进程之间地址冲突的问题。
  --页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。
* 内存4个G，虚拟内存8个G。数据存在哪
  --因为 32 位操作系统，进程最多只能申请 3 GB 大小的虚拟内存空间，所以进程申请 8GB 内存的话
  在申请虚拟内存阶段就会失败（我手上没有 32 位操作系统测试，我估计失败的原因是 OOM）
  --64 位操作系统，进程可以使用 128 TB 大小的虚拟内存空间，所以进程申请 8GB 内存是没问题的，因为进程申请内存是申请虚拟内存，
  只要不读写这个虚拟内存，操作系统就不会分配物理内存。
  如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：
  如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
  如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；

* 什么样的内存访问是效率最高的
  --提高CPU缓存命中率
  数据缓存：是按照内存布局顺序访问
  指令缓存： 利用好CPU 自身的动态分支预测
* 如何高效利用缓存

* 缓存失效策略
  --Linux 操作系统为基于 Page Cache 的读缓存机制提供预读机制，一个例子是：
  应用程序只想读取磁盘上文件 A 的 offset 为 0-3KB 范围内的数据，由于磁盘的基本读写单位为 block（4KB），
  于是操作系统至少会读 0-4KB 的内容，这恰好可以在一个 page 中装下。
  但是操作系统出于空间局部性原理（靠近当前被访问数据的数据，在未来很大概率会被访问到），
  会选择将磁盘块 offset [4KB,8KB)、[8KB,12KB) 以及 [12KB,16KB) 都加载到内存，于是额外在内存中申请了 3 个 page；
  --如何避免预读失效造成的影响？
  要避免预读失效带来影响，最好就是让预读页停留在内存里的时间要尽可能的短，
  让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在内存里的时间尽可能长。
  那到底怎么才能避免呢？
  Linux 操作系统和 MySQL Innodb 通过改进传统 LRU 链表来避免预读失效带来的影响，具体的改进分别如下：
  Linux 操作系统实现两个了 LRU 链表：活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）；
  MySQL 的 Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：young 区域 和 old 区域。
  设计思想：将数据分为了冷数据和热数据，然后分别进行 LRU 算法。不再像传统的 LRU 算法那样，所有数据都只用一个 LRU 算法管理。
* 局部性原理
  --
* 顺序读和随机读的区别
  --
* 单例模式线程安全
  --
* git中merge和rebase区别
  --rebase的解释 ： rebase字面意思就是"变基"，可以直接理解为改变基底。
  feature分支是基于master分支的B拉出来的分支，feature的基底是B。而master在B之后有新的提交，就相当于此时要用master上新的提交来作为feature分支的新基底。
  实际操作为把B之后feature的提交存下来，然后删掉原来这些提交，再找到master的最新提交位置，把存下来的提交再接上去（新节点新commit id）
  如此feature分支的基底就相当于变成了M而不是原来的B了。
  注意，如果master上在B以后没有新提交，那么就还是用原来的B作为基，rebase操作相当于无效，此时和git merge就基本没区别了，
  差异只在于git merge会多一条记录Merge操作的提交记录。
  --推荐使用场景
* 拉公共分支最新代码的时候使用rebase，也就是git pull -r或git pull --rebase，
  但有个缺点就是rebase以后我就不知道我的当前分支最早是从哪个commitid拉出来的了，因为基底变了。
  （如果使用merge，多出无意义的一条提交记录"Merge … to …"）
* 往公共分支上合代码的时候，使用merge。如果使用rebase，那么其他开发人员想看主分支的历史，就不是原来的历史了，历史已经被你篡改了
* 线程和进程
* 虚拟内存
* 进程调度的状态
* 多进程与多线程，它们各自的应用场景是什么。
* 线程，线程安全，锁，CAS，问的比较细
* 数据从磁盘到CPU经过了哪些地方，什么是零拷贝
* 进程和线程的区别
* 进程和线程资源共享问题
* 死锁的概念
* 死锁产生原因
* 死锁的预防
* 死锁的避免

* 键盘输入一个字符，显示器显示出来，发生了什么
进程线程的区别
进程之间通讯方式？
* 进程和线程
* 进程之间的通信
* 保证当多个线程时，数据访问安全的问题？

死锁条件 ？如何避免？

进程和线程的区别，各自适用的场景
程序的地址保存的是虚拟地址还是物理地址
内存泄漏

知道自旋锁吗？和互斥锁有什么区别？