### Redis 主从复制第一次同步
三个阶段：
* 建立连接， 协商同步
  从服务器：replicaof->psync:runID offset
  主：FULLRESYNC 全量复制

* 主服务器同步数据给从服务器
  主：bgsave:RDB 期间的写操作没有进来 造成主从服务器间数据不一致
  三个时间间隙写入replication buffer:
  主生成RDB
  主发送RDB给从
  从加载RDB

* 主服务器发送新写操作命令给从服务器
  从收到RDB 先清空 然后加载RDB
  主发送replication buffer 主从数据一致

### 基于长连接的命令传播

分摊主服务器的压力
两个方面 bgsave fork()子进程耗时阻塞主进程
传输RDB网络带宽
主服务器生成 RDB 和传输 RDB 的压力可以分摊到充当经理角色的从服务器。

### 增量复制： 网络断开又恢复
恢复网络后，从请求psync offset != -1
主：CONTINUE——> 发送从断线期间所执行的写命令
怎么知道发送那些增量数据：repl_backlog_buffer:默认1M 避免全量 应该尽可能大一些

从服务器要读取的数据还在里面 就增量复制——>写入replication buffer
不在了 就全量复制


### 怎么判断某个redis节点是否正常工作
心跳检测ping-pong 如果有一半以上节点Ping一个节点没有回应 集群就认为这个节点挂了

主：每个10s ping
从：每隔1s replconf ack{offset} 上报自身偏移量
实时检测主从节点网络状态；上报复制偏移量，检测复制数据是否丢失

#### 主从复制架构中，过期Key处理：
主节点处理或淘汰一个key后，模拟一条del命令发送给从

#### redis是同步复制还是异步复制
收到写命令后，先写到内部缓冲区，然后异步发送给从

#### replication buffer 、repl backlog buffer 区别如下：
repl backlog buffer：保存着最近传播的写命令。
出现的阶段不一样：
是在增量复制阶段出现，一个主节点只分配一个 repl backlog buffer；
在全量复制阶段和增量复制阶段都会出现，主节点会给每个新连接的从节点，分配一个 replication buffer；
这两个 Buffer 都有大小限制的，当缓冲区满了之后，发生的事情不一样：
当 repl backlog buffer 满了，因为是环形结构，会直接覆盖起始位置数据;
当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，重新开始全量复制。

### 为什么会出现主从数据不一致？ 异步复制 无法强一致性

### 如何应对主从数据不一致：
尽量保证主从节点间网络连接状况良好
开发一个外部程序监控主从间复制进度

得到双方复制进度-> 双方复制进度差值-> 大于阈值 不让客户端和这个从节点进行数据读取， 减少读到不一致数据的情况

### Redis单线程为什么这么快？

大部分操作在内存中完成，并且采用高效的数据结构因此Redis的瓶颈可能是机器的内存或者网络带宽，而并非CPU

单线程模型避免多线程竞争，省去多线程切换的时间和性能开销，不会死锁

I/O多路复用，处理大量的客户端socket请求，一个Redis线程处理多个IO流

### 6.0引入多线程，提高处理网络IO的并行度，命令的执行还是单线程

### Redis持久化
AOF：每执行一条写命令，就把该命令以追加的方式写入到文件
RDB：某一时间内存数据，以二进制写入硬盘
混合持久化

### AOF写回
always 同步写回
everySec 每秒写回
No 由操作系统控制写回

AOF过大->AOF重写
读取数据库所有键值对，每个键值对用一条命令记录到新的AOF文件上->压缩了AOF文件的体积

AOF重写过程：后台进程bgrewriteaof

重写期间，主进程仍可以处理命令请求，不会阻塞主进程
父子进程共享内存，只读；任意一方修改了共享内存，发生写时复制，父子进程就有了独立数据副本，不用加锁

### 数据不一致？
* AOF重写缓冲区
  AOF重写期间，主进程三个工作
  执行客户端发来的命令
  将执行后写命令追加到AOF缓冲区
  将执行后写命令追加到AOF重写缓冲区

子进程完成AOF重写工作后，向主进程发送信号，信号处理函数
将AOF重写缓冲区的内容追加到新的AOF文件，保证数据一致
新的AOF文件改名，覆盖现有AOF