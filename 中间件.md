7.k8s中的自定义控制器如何实现
8.项目中有哪些与k8s交互的部分
4.删除一个pod的过程
5.node与主节点失联后经过多长时间会监测到（真不知道，10s?）
如果一个pod被调度到一个节点上，但是节点上的资源不够了会怎么样？
#### MQ的对比和场景选型
引入MQ后的注意事项
引入MQ最大的优点就是异步解耦和流量削峰，但是引入MQ后也有很多需要注意的事项和问题，
主要包括：系统的整体可用性降低、系统的复杂度变高、引入了消息一致性的问题。
* 系统的整体可用性降低
在对一个系统进行架构设计时，引入的外部依赖越多，系统的稳定性和可用性就会降低。
* 系统中引入了MQ，部分业务就会出现强依赖MQ的现象，此时，如果MQ宕机，则部分业务就会变得不可用。
* 所以，引入MQ时，我们就要考虑如何实现MQ的高可用。

* 系统的复杂度变高
引入MQ后，会使之前的同步接口调用变成通过MQ的异步调用，在实际的开发过程中，异步调用会比同步调用复杂的多。
* 并且异步调用出现问题后，重现问题，定位问题和解决问题都会比同步调用复杂的多。
并且引入MQ后，还要考虑如何保证消息的顺序等问题。

* 消息一致性问题
引入MQ后，不得不考虑的一个问题就是消息的一致性问题。这期间就要考虑如何保证消息不丢失，消息幂等和消息数据处理的幂等性问题。

消息中间件(MQ)
优点
缺点
使用场景
* RabbitMQ
功能全面、消息的可靠性比较高
吞吐量低，消息大量积累会影响性能，使用的开发语言是erlang，不好定制功能。
规模不大的场景

* Kafka
吞吐量最高，性能最好，集群模式下高可用
功能上比较单一，会丢失部分数据
日志分析，大数据场景

* RocketMQ
吞吐量高，性能高，可用性高，功能全面。使用Java语言开发，容易定制功能。
开源版不如阿里云上版，文档比较简单。
几乎支持所有场景，包含大数据场景和业务场景。

#### kafka架构
producer -- broker -- consumer -- zookeeper集群

#### kafka消费者组重平衡

#### rocketmq的消费者是怎么消费的
* 负载均衡模式（集群模式）
消费者采用负载均衡方式消费消息，一个分组(Group)下的多个消费者共同消费队列消息，每个消费者处理的消息不同。
一个Consumer Group中的各个Consumer实例分摊去消费消息，即一条消息只会投递到一个Consumer Group下面的一个实例。
例如某个Topic有3个队列，其中一个Consumer Group 有 3 个实例，那么每个实例只消费其中的1个队列。集群消费模式是消费者默认的消费方式。

* 广播模式
广播消费模式中消息将对一个Consumer Group下的各个Consumer实例都投递一遍。
* 即使这些 Consumer属于同一个Consumer Group，消息也会被Consumer Group 中的每个Consumer都消费一次。
* 实际上，是一个消费组下的每个消费者实例都获取到了topic下面的每个Message Queue去拉取消费。所以消息会投递到每个消费者实例

rocketmq消费是有序的吗

为什么用虚拟机部署，没有考虑用docker呢
分布式消息队列的消费数据如何保证幂等性

#### 限流算法怎么实现的，原理，还了解别的限流算法吗
限流算法有多种，这两个方法按照不同算法有不同的具体实现。
* 限流算法主要有：计数器限流、滑动窗口限流、令牌桶限流、漏桶限流。
* 计数器限流算法
计数器限流算法也叫固定窗口限流算法。
首先，选定一个时间窗口作为一个周期，假设为 5 秒；
第二步，设定 5 秒内允许通过的流量，如 1000 个请求；
第三步，每次请求，计数器都加 1；
第四步，判断计数器数值是否超过 1000 ，超过了就触发限流策略，如：拒绝或者延迟处理请求等；
最后，如果时间过了 5 秒，则重置计数为 0，开始一个新的周期。

该限流算法的优点是实现简单，缺点是面对突发流量时不够精确。面对瞬时流量时，会存在资源利用率的剧烈抖动。

* 滑动窗口限流算法
滑动窗口限流算法是对计数器限流算法的优化。
* 它的主要原理是将计数器限流算法中的一个周期拆分成很多等分，比如将 5 秒的周期拆成 5 个 1 秒，每次统计从当前时间开始过去 5 秒内的流量，
* 每隔 1 秒往后滑动 1 秒。
由于将周期拆分成多个小的单位，相比计数器限流算法，滑动窗口限流算法对流量的统计和控制要更精确，资源利用率抖动更小。
* 但它还是没有彻底解决因瞬时流量导致资源使用率抖动的问题。
那么，有没有办法解决这个问题呢？有，它就是我接下来要介绍的令牌桶限流算法和漏桶限流算法。

* 令牌桶限流算法
令牌桶算法的基本原理是，使用一个定时器以恒定速度往桶里颁发令牌，桶满了则丢弃多余令牌。请看示意图：
在令牌桶算法中，一般只有拿到令牌的请求才会被处理，没拿到的将会被拒绝。
* 这个过程就像景区的人工售票窗口售票，只有买到票了才能检票进入景区。
* 这其中，令牌就是门票，令牌桶就是售票窗口，负责发令牌的线程就类似于售票员，处理请求的线程就是检票员。

* 漏桶限流算法
漏桶算法的原理跟令牌桶有点相似，只不过漏桶算法采用“生产者-消费者”模型。在“生产者”一端，所有请求进队列，队列满了则丢弃请求。
* 在“消费者”一端，以恒定速度消费队列并处理请求。
举个例子：乒乓球教练将乒乓球放入到发球机中，乒乓球发球机能以固定速度发出乒乓球，球员可以以固定速度击打乒乓球。例子中的乒乓球相当于软件系统中的请求，教练相当于“生产者”，发球机相当于漏桶，而球员相当于“消费者”。
以上这几种限流算法中，流量控制效果从好到差依次是：漏桶限流 > 令牌桶限流 > 滑动窗口限流 > 计数器限流。
其中，只有漏桶算法真正实现了恒定速度处理请求，能够绝对防止突发流量超过下游系统承载能力。
* 不过，漏桶限流也有个不足，就是需要分配内存资源缓存请求，这会增加内存的使用率。
* 而令牌桶限流算法中的“桶”可以用一个整数表示，资源占用相对较小，这也让它成为最常用的限流算法。
正是因为这些特点，漏桶限流和令牌桶限流经常在一些大流量系统中结合使用。比如秒杀系统中就同时使用了这两种限流算法。

### Kafka怎么保证数据不丢失 producer、 broker 、 consumer 参数配置来考虑
今天我们来分析一下这个问题。

先来回忆一下kafka 中消息传输的整个过程
* kafka 在producer 端产生消息，调用kafka producer client send方法发送消息 
* kafka producer client 使用一个单独的线程，异步的将消息发送给kafka server
* kafka server收到消息以后，保存数据，并同步至副本
* 消息保存完成以后，返回给kafka producer client 端 【消息发送成功】
* 、kafka consumer client 调用poll 方法，循环 从kafka server 端获取消息列表
* kafka consumer 端 从kafka server获取到消息以后，开始消费消息
* kafka consumer 消费消息完毕以后，向kafka server（topic为 _offset_consumer的消息队列） 发送偏移量
在上述的整个流程中，消息丢失的情况分为以几种可能性：
1、producer 端 发送消息给kafka server 端，中间网络出现问题，消息无法送达
2、kafka server端 在收到消息以后，保存消息时发生异常,异常分为三种
（1）可重试错误，通过重试来解决
（2） 网络连接错误
（3）无主（no leader）错误
3、consumer 在消费消息时发生异常，导致consumer端消费失败
注：当然这里还可能发生另一种错误，就是在producer发送消息到kafka server端时，消息体过大，producer client 直接抛出异常，导致发送失败
#### 如何解决
* producer 端的发送方式优化
我们先来了解一下，producer端发送消息的方式：

* 简单发送，无需关心结果
ProducerRecord<String,String> record = new ProducerRecord<>(
"topicName","key","value"  
);
try{
//这里只是把消息放进了一个缓冲区中，然后使用单独的线程将消息发送到服务端
producer.send(record);
}
catch(Exception){
e.printStackTrace();
}
* 同步发送

ProducerRecord<String,String> record = new ProducerRecord<>(
"topicName","key","value"  
);
try{
//send方法返回的是Future<RecordMetaData> 对象，然后我们可以调用get()方法等待响应
Future<RecordMetaData> future = producer.send(record);
future.get();
}
catch(Exception){
e.printStackTrace();
}
* 异步发送
private class DemoProducerCallback implements Callback{
@override
public void onCompletion(RecordMetadata recordMetadata,Exception e){
//发生错误的回调方法,可以写入日志，或写入DB通过其它线程重重试，保证最终的数据送达
}
}
ProducerRecord<String,String> record = new ProducerRecord<>(
"topicName","key","value"  
);
producer.send(record，new DemoProducerCallback()))

* producer端的配置优化
在producer 端的配置项中有很多的配置项，我们摘出几种比较重要的来一一解读：
acks:该参数指定了，kafka server的多少个副本收到消息以后才算真的正消息发送成功。取值范围：
acks = 0 表示producer 在将消息成功写入到 kafka server 之前不会收任消息
acks = 1 表示只要kafka server 集群中的leader节点收到消息，producer 端就会收到kafka server的成功响应
acks = all 表示只有当消息到leader节点，并且这条数据也同步到了所有副本中，producer 才会收到kafka server的成功响应。
buffer.memory:生产端 缓冲区的大小设置
compression type:生产端采用的数据压缩方式，取值 snappy,gzip,lz4,默认不会压缩。
(启用压缩意味着，需要producer 和kafka server要占用更多的cpu资源)
retries:生产端发送消息到kafka server时，发生临时性错误以后，生产者发送消息到kafka server端重试的次数。如果重试超过该次数，则发生异常
producer端使用producer.send(msg, callback)带有回调的send方法。
设置retries为一个较大的值。同样是Producer的参数。当出现网络抖动时，消息发送可能会失败，此时配置了retries的Producer能够自动重试发送消息，尽量避免消息丢失。
batch.size: 当多个消息被发送至同一分区时，生产者会把它们发送到同一批。该参数指定了同一批次可以使用的内存大小，按字节数计算（而不是消息条数）。
linger.ms:该参数指定了生产者在发送批次之前等待更多消息加入批次的时间，producer client 会在批次填满（batch.size） 或linger.ms 到上限时，将消息发送至kafka server.
max.in.flight.requests.per.connection：该参数指定了生产者在收到kafka server 的成功响应之前，可以发送多少消息。（可以利用该配置让kafka server中的消息变得有序）
max.request.size:该参数用来控制生产者发送单个请求的数据大小。对于消费端也有相同的配置（message.max.bytes）,建议两边设置相同。
* 总结：我们的问题，可以通过设置配置项 acks 、retries 来保证数据的不丢失。

* kafka server
这里需要补充一个知识点，kafka的server端同一个topic下有多个分区，单个分区会有不同的副本。
* 如果producer 发送消息么kafka server端，leader收到了消息以后，告诉producer 发送成功，此时再同步消息到多个副本，
* 但由于某一个副本同步较慢，此时leader挂了，需要选主，选主的过程中，一旦那个较慢的副本成为新的leader，
* 那么新的leader中就不包含了原leader收到的那条最新数据，导致消息丢失。
broker中的配置项,unclean.leader.election.enable = false，表示不允许非ISR中的副本被选举为首领，以免数据丢失。
如果一个Broker落后原先的Leader太多，那么它一旦成为新的Leader，将会导致消息丢失。故一般都要将该参数设置成false。
ISR：是指与leader保持一定程度（这种范围是可通过参数进行配置的）同步的副本和 leader 共同被称为ISR
OSR：与leader同步时，滞后很多的副本（不包括leader）被称为OSR
AR，分区中所有的副本统称为AR。AR = ISR + OSR

* kafka consumer端的优化
kafka consumer的配置中，默认的enable.auto.commit = true,
* 表示在kafka consumer 通过poll方法 获取到消息以后，每过5秒（通过配置项可修改）会自动获取poll中得到的最大的offset, 
* 提交给kafka server 中的_offset_consumer(存储 offset 的特定topic )
  确保消息消费完成再提交。Consumer端有个参数enable.auto.commit，最好设置成false，并自己来处理offset的提交更新
如果enable.auto.commit = false时，则关闭了自动提交，你可以手动的通过应用程序代码进行提交，
这里我来梳理一下，consumer 消费消息的整个流程
consumer端循环向kafka server请求获取信息
如果kafka server中的分区中没有消息，则阻塞指定秒数(consumer端配置)后，返回给consumer端
如果 kafka server中有消息 或是在阻塞等待的过程中有消息写入，则立即返回给consumer端
consumer开始消费消息
consumer消费消息完毕以后，提交偏移量到topic为 _offset_consumer（kafka server端） 的消息队列
我们来看一下，enale.auto.commit = false时，如何手动提交的
public void consumerMsg(){
while(true){
//这里的poll(100)指的是kafka server端没有消息时，连接等待的时间，超过该时间立即返回空给consumer
ConsumerRecords<String,String> records = consomer.poll(100);
for(ConsumerRecord<String,String> record : records){
// 这里是消费消息的逻辑（简单逻辑输入到控制台）
System.out.printIn(record.value));
//提交偏移量
try{
consumer.commitSync();  //同步提交 如果异步的话，可以使用 consumer.commitAsync();
}
catch(CommitFailedException ex){
log.error("commit fail");
}
}
}
}

consumer端消息丢失的情况分为两种：
consumer 端启用了 enable.auto.commit= true,在消费消息时发生了异常
consumer 端 enable.auto.commit= false，但是在消息消费之前，提交了offset
针对这两种丢失的情况，我们做以下处理：
1、设置 enable.auto.commit = false
2、在consumer端消费消息操作完成以后 再提交 offset,类似于上文中的代码示例

* Kafka的Broker机制保证了数据的不丢失。
对于Kafka的Broker而言，Kafka 的复制机制和分区的多副本机制是Kafka 可靠性保证的核心。
* 把消息写到多个副本中能保证在Kafka服务器崩溃后能够继续保证消息持久性。
知道问题的核心，来看三个配置参数来回答该问题。
设置replication.factor >= 3。这也是Broker端的参数。保存多份消息冗余，不多解释了。
设置min.insync.replicas > 1。Broker端参数，控制消息至少要被写入到多少个副本才算是“已提交”。
* 设置成大于 1 可以提升消息持久性。在生产环境中不要使用默认值 1。
* 确保replication.factor > min.insync.replicas。如果两者相等，那么只要有一个副本离线，整个分区就无法正常工作了。推荐设置成replication.factor = min.insync.replicas + 1。
Topic 副本因子个数：replication.factor >= 3
同步副本列表(ISR)：min.insync.replicas = 2
禁用unclean选举：unclean.leader.election.enable=false
副本因子
Kafka的topic可以分区，并且可以为分区配置多个副本，可以通过replication.factor参数实现配置。
* Kafka的分区副本包含两种类型：Leader Replica和Follower Replica，每个分区在创建时都会选举一个副本作为Leader副本，其余都是Follower副本。
而Follower副本对外不提供任何服务，即任何Follower副本不会响应消费者和生产者的读写请求，所有请求都得由Leader副本来处理。
所以，所有读写请求都必须发往Leader副本所在的Broker，由该 Broker 负责处理。
Follower副本不处理客户端请求，唯一任务是从Leader副本异步拉取消息，并写入到自己的提交日志中，从而实现与Leader副本的同步。
#### 一般来说，副本设为3可以满足大部分的使用场景，也有可能是5个副本(比如银行)。
如果副本因子为N，那么在N-1个broker 失效的情况下，仍然能够从topic读取数据或向topic写入数据。
所以，更高的副本因子会带来更高的可用性、可靠性和更少的故障。
另一方面，副本因子N需要至少N个broker ，而且会有N个数据副本，也就是说它们会占用N倍的磁盘空间。
实际生产环境中一般会在可用性和存储硬件之间作出权衡。
副本的分布同样也会影响可用性。
默认情况下，Kafka会确保分区的每个副本分布在不同的Broker上，但是如果这些Broker在同一个机器上，一旦机器的交换机发生故障，
分区将不可用。所以建议把Broker分布在不同的机器上，可以使用broker.rack参数配置Broker所在机器的名称。

* 同步副本列表
In-sync replica(ISR)称为同步副本，ISR中的副本都是与Leader副本数据状态同步的副本。
ISR存在哪些副本呢？Leader副本总是存在于ISR中。以及与Leader副本保持了“同步”的follower副本。
* Kafka的broker端有一个参数replica.lag.time.max.ms, 该参数表示follower副本滞后于Leader副本的最长时间间隔，默认是10秒。
* 意味着只要follower副本落后于leader副本的时间间隔不超过10秒，就可以认为该follower副本与leader副本是同步的。
可以看出ISR是一个动态的。所以即便是为分区配置了3个副本，
* 还是会出现同步副本列表中只有一个副本的情况(其他副本由于不能够与leader及时保持同步，被移出ISR列表)。
* 如果这个同步副本变为不可用，我们必须在可用性和一致性之间作出选择(CAP理论)。
根据Kafka对可靠性的定义，消息只有在写入所有同步副本之后才被认为是已提交的。
* 但如果这里的“所有同步副本”只包含一个同步副本，那么在这个副本变为不可用时，数据就会丢失。（某副本宕机后，没有副本保存原有数据状态。）
如果要确保已提交的数据被写入不止一个副本，就需要把最小同步副本数量设置为大一点的值。
* 对于一个包含3 个副本的主题分区，如果min.insync.replicas=2，那么至少要存在两个同步副本才能向分区写入数据。
* 满足这个条件，生产者才能将生产的数据放入消息队列中）
举例：如果进行了上面的配置，此时必须要保证ISR中至少存在两个副本，
* 如果ISR中的副本个数小于2，那么Broker就会停止接受生产者的请求。
* 尝试发送数据的生产者会收到NotEnoughReplicasException异常，消费者仍然可以继续读取已有的数据。

* 禁用unclean选举
选择一个同步副本列表中的分区作为leader 分区的过程称为clean leader election。注意，这里要与在非同步副本中选一个分区作为leader分区的过程区分开，在非同步副本中选一个分区作为leader的过程称之为unclean leader election。由于ISR是动态调整的，所以会存在ISR列表为空的情况，通常来说，非同步副本落后 Leader 太多，因此，如果选择这些副本作为新 Leader，就可能出现数据的丢失。毕竟，这些副本中保存的消息远远落后于老 Leader 中的消息。在 Kafka 中，选举这种副本的过程可以通过Broker 端参数 unclean.leader.election.enable控制是否允许 Unclean 领导者选举。开启 Unclean 领导者选举可能会造成数据丢失，但好处是，它使得分区 Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。反之，禁止 Unclean Leader 选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。分布式系统的CAP理论说的就是这种情况。
不幸的是，unclean leader election的选举过程仍可能会造成数据的不一致，因为同步副本并不是完全同步的。由于复制是异步完成的，因此无法保证follower可以获取最新消息。比如Leader分区的最后一条消息的offset是100，此时副本的offset可能不是100，这受到两个参数的影响：

replica.lag.time.max.ms：同步副本滞后leader副本的时间
zookeeper.session.timeout.ms：与zookeeper会话超时时间
简而言之，如果我们允许不同步的副本成为leader，那么就要承担丢失数据和出现数据不一致的风险。如果不允许它们成为leader，那么就要接受较低的可用性
，因为我们必须等待原先的Leader恢复到可用状态。（高可用性和数据一致性的平衡）

关于unclean选举，不同的场景有不同的配置方式。对数据质量和数据一致性要求较高的系统会禁用这种unclean的leader选举(比如银行)。如果在可用性要求较高的系统里，比如实时点击流分析系统， 一般不会禁用unclean的leader选举。

#### 了解哪些消息队列？消息队列是怎么防止消息丢失的（用的RabbitMQ）

#### k8s中informer如何使用，长短连接的使用场景

#### 消息队列的消息丢失和消息堆积
* 消息队列
--异步处理
* 消息队列提供了异步处理机制，因为很多时候用户并不需要立即响应来处理消息，那么通过这个机制就可以把所有消息放入 MQ 中。
* 比如，某系统发来的数据中包含很多图片信息，如果对其中的信息都进行保存处理，用户一番操作下来可能会很久。
* 采用异步处理之后，系统会将所有数据存放在 MQ 中，用户不需要立即处理，大大缩短了系统的响应时间。
--应用解耦
* 消息队列可以对系统间的依赖进行解耦，降低依赖系统变更带来的影响。
* 比如，用户在下单后，订单系统A需要通知系统B、系统C等做出响应的处理。传统的做法，如下图所示。
此时的系统A是强依赖系统B和系统C的，一旦系统B出现故障或者需要重新加入高耦合的系统D时，就必须要更改系统A的代码。
如果经常出现这种依赖系统迭代的情况，那么系统A就会很难维护，可以通过消息队列对依赖系统进行解耦（如下图），这样系统A也无需关心其他系统的可用性。
--流量削峰
* 流量削峰还有个形象的名字叫做削峰填谷，其实就是指当数据量激增时，能够有效地隔离上下游业务，
* 将上游突增的流量缓存起来，真正地填到谷中，以平滑的方式传到下游系统，避免了流量的不规则冲击。
比如，有个活动页面平时也就 50qps，某一特殊时刻访问量突然增多，能达到 1000qps，但是当前系统的处理能力最多为 100qps，这个时候可以通过消息队列来进行削峰填谷，如下图所示。
当然，Kafka 除了以上 MQ 这些功能之外，还提供了消息顺序性保障、回溯消息、持久化存储等功能，这个在后续文章中会详细讲解。

* 消息队里使用的缺点
系统解耦,分布式,带来了数据一致性问题,数据丢失与重复
流量控制，也会导致消息堆积的问题

* 在使用 MQ 消息队列时，如何确保消息不丢失？
一条消息从生产到消费完成这个过程，可以划分三个阶段，分别为消息生产阶段，消息存储阶段和消息消费阶段。
消息生产阶段：
从消息被生产出来，然后提交给 MQ 的过程中，只要能正常收到 MQ Broker 的 ack 确认响应，就表示发送成功，所以只要处理好返回值和异常，
* 这个阶段是不会出现消息丢失的。
消息存储阶段：
这个阶段一般会直接交给 MQ 消息中间件来保证，要了解它的原理，比如 Broker 会做副本，
* 保证一条消息至少同步两个节点再返回 ack（这里涉及数据一致性原理），消息队里自带的持久化等。
消息消费阶段：
消费端从 Broker 上拉取消息，只要消费端在收到消息后，不立即发送消费确认给 Broker，而是等到执行完业务逻辑后，再发送消费确认，
* 也能保证消息的不丢失。
 但在分布式系统中，故障不可避免，作为消费生产端，你并不能保证 MQ 是不是弄丢了你的消息，消费者是否消费了你的消息，
* 所以，还是需要一种机制，来 Check 消息是否丢失了。
解决思路：
在消息生产端，给每个发出的消息都指定一个全局唯一 ID，或者附加一个连续递增的版本号，然后在消费端做对应的版本校验。
在生产端发送消息之前，通过拦截器将消息版本号注入消息中（版本号可以采用连续递增的 ID 生成，也可以通过分布式全局唯一 ID生成）。
* 然后在消费端收到消息后，再通过拦截器检测版本号的连续性或消费状态，这样实现的好处是消息检测的代码不会侵入到业务代码中，
* 可以通过单独的任务来定位丢失的消息，做进一步的排查。
* （注意：如果同时存在多个消息生产端和消息消费端，通过版本号递增的方式就很难实现了，因为不能保证版本号的唯一性，
* 此时只能通过全局唯一 ID 的方案来进行消息检测，具体的实现原理和 版本号递增的方式一致。）

#### 怎么解决消息被重复消费的问题
 其实就是如何解决消费端幂等性问题。
实现方案：在数据库中建一张消息日志表
这个表有两个字段：消息 ID 和消息执行状态。这样，我们消费消息的逻辑可以变为：在消息日志表中增加一条消息记录，然后再根据消息记录，
异步操作更新用户消费数据。因为我们每次都会在插入之前检查是否消息已存在，所以就不会出现一条消息被执行多次的情况，这样就实现了一个幂等的操作。

#### 如何处理消息积压问题
其实就是如何通过 MQ 实现真正的高性能问题 因为消息发送之后才会出现积压问题，故和消息生产端没关系，
又因为绝大部分的消息队列单节点都能达到每秒钟几万的处理能力，相对于业务逻辑来说，性能不会出现在中间件的消息存储上面。
毫无疑问，出问题的肯定是消息消费阶段，那么从消费端入手

解决思路方案:
如果是线上突发问题，要临时扩容，增加消费端的数量，与此同时，降级一些非核心的业务
。通过扩容和降级承担流量。其次，排查解决异常问题，如通过监控，日志等手段分析是否消费端的业务逻辑代码出现了问题，优化消费端的业务处理逻辑。

* 重复消费
现在消息队列一般都能保证at least once的，也就是消息至少一次投递。
* 在这种情况为什么会出现重复消费的问题呢？通常都是由于网络原因造成的，
* 原因如下：通常消息被成功消费后消费者都会发送一个成功标志给MQ，MQ收到这个标志就表示消息已经成功消费了，
* 就不会再发送给其他消费者了。但是如果因为网络这个标志没有送到MQ就丢失了，MQ就认为这个消息没有被成功消费，就会再次发送给其他消费者消费，
* 就造成重复了。

这时我们看这个问题就变成了我们怎么保证消费端的幂等性。
幂等性 是指一个操作其执行任意多次所产生的影响均与一次执行的影响相同，大白话就是你同样的参数调用我这个接口，调用多少次结果都相同。
怎么保证消息队列消费的幂等性
其实还是得结合业务来思考，我这里给出几个解决方案：
分布式锁。生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，
然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？
如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
* 唯一键防重。基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。
先查后写。要写数据库前，先根据主键查一下，如果这数据都有了，你就别插入了，update一下好了。
关闭重试机制。如果把重试机制关掉的话不显示，虽然解决了重复消费的问题，但是可能会造成丢失消息，不建议这么做。

不同的业务可以选择不同的方案，如果服务的并发量不高，可以考虑唯一键防重或者先查后写的方案；如果并发量较高，追求性能，沐子推荐采用分布式锁实现幂等性（本公司目前采用的方案）

* 消息堆积
* 消息堆积的产生原因
消息堆积的原因主要在于两方面，其一为消费的太慢或消费方出现异常，
* 其二为生产方生产的太快，总的来说就是消息的速度赶不上生产的速度，生产和消费速度不匹配造成的。

消息堆积的解决方案

1）生产端：一般当生产端发生积压（Broker正常的情况下）就要查看你的业务逻辑是否有异常的耗时步骤导致的，是否需要改并行化操作等。
Broker端：当Broker端发生积压我们首先要查看，消息队列内存使用情况，如果有分区的的话还得看每个分区积压的消息数量差异。当每个分区的消息积压数据量相对均匀的话，我们大致可以认为是流量激增。需要在消费端做优化，或者同时需要增加Broker节点（相当于存储扩容），如果分区加压消息数量差异很大的话（有的队列满了，有的队列可能还是空闲状态），我们这时候就要检查我们的路由转发规则是否合理。
2） 增加消费者，多部署几台消费者机器（横向扩展），提升消费者的消费能力。
3）此种情况可以将这些消费不成功的消息转发到其它队列里去(类似死信队列)，后面再慢慢分析死信队列里的消息处理问题。
4)mq 中的消息过期失效了。可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。
总之，上面说到消息积压的问题，我们需要查看是否有无限重发的消息或者有进入死锁的程序等等，当确定是流量激增的话，我们需要评估是否需要增加资源还是通过限流的方式解决，当短时间大量消息需要处理时，在资源允许的情况下，我们可以新启一批消费者与消息队列，将原来的消费者中的消息直接作为生产者转发到临时应急队列中，这样大概率的能够快速解决消息积压。与其事后处理不如我们在设计之初就要把积压考虑进来，对于数据量非常大，但是实时性要求不高的场景，可以设计出批量消息发送，当队列积累到一定阀值再做批量消费消费，这里需要注意的就是重复消费带来的影响，设计不好就是一场灾难。
* 消息丢失
一般来讲消息丢失的途径有三个：生产者弄丢数据、消息队列弄丢数据、消费者弄丢数据。
* 生产者弄丢数据
* 丢失的原因：因为网络传输的不稳定性，当生产者在向MQ发送消息的过程中，MQ没有成功接收到消息，
* 但是生产者却以为MQ成功接收到了消息，不会再次重复发送该消息，从而导致消息的丢失。

b、解决办法：有两个解决办法，第一个方法：向broker发送消息时，如果由于网络抖动等原因导致消息发送失败，可以设置失败重试次数让消息重发。
第二个方法：事务机制和confirm机制，最常用的是confirm机制；

事务机制和 confirm 机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，
但是 confirm 机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息 MQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。
* MQ弄丢数据
a、丢失的原因：MQ接收到生产者发送过来的消息，是存在内存中的，如果没有被消费完，此时MQ宕机了，那么再次启动的时候，原来内存中的那些消息都丢失了。
b、解决办法：开启MQ的持久化。结合上面的说到的confirm机制，只有当消息成功持久化磁盘之后，才会回调生产者的接口返回ack消息，否则都算失败，生产者会重新发送。存入磁盘的消息不会丢失，就算MQ挂掉了，重启之后，他会读取磁盘中的消息，不会导致消息的丢失。
注意，哪怕是你给 MQ 开启了持久化机制，也有一种可能，就是这个消息写到了MQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时MQ挂了，就会导致内存里的一点点数据丢失。
所以，持久化可以跟生产者那边的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack 了，所以哪怕是在持久化到磁盘之前，MQ 挂了，数据丢了，生产者收不到 ack，你也是可以自己重发的。
* 消费者弄丢数据
a、丢失的原因：如果MQ成功的把消息发送给了消费者，那么MQ的ack机制会自动的返回成功，表明发送消息成功，下次就不会发送这个消息。但如果就在此时，消费者还没处理完该消息，然后宕机了，那么这个消息就丢失了。
b、解决的办法：1）简单来说，就是必须关闭 MQ 的自动提交，把自动提交改为手动提交，也就是说当我消费成功后才会进行提交。
2）消费者端已经正常接收到消息但是在执行后续消息处理时发生了异常，最终返回处理失败。重试-进行重新消费问题，如果一直这样重复消费都持续失败到一定次数，可以投递到 DLQ 死信队列，应用可以监控死信队列来做人工干预。
* 顺序消费
比如一个电商的下单操作，下单后先减库存然后生成订单，这个操作就需要顺序执行的。队列本身是有顺序的，但是为什么还要保证顺序消费呢，主要是因为生产环境服务实例一般都是集群，当消费者是多个实例时，队列中的消息会分发到所有实例进行消费（同一个消息只能发给一个消费者实例），这样就不能保证消息顺序的消费，因为你不能确保哪台机器执行消费端业务代码的速度快。
保证每次只有单个消费实例消费
所以对于需要保证顺序消费的业务，我们可以只部署一个消费者实例，然后设置MQ 每次只推送一个消息，再开启手动 ack 即可。这样MQ 每次只会从队列推送一个消息过来，处理完成之后我们 ack 回应，再消费下一个，就能确保消息顺序性。
这样MQ 每次只会从队列推送一个消息过来，处理完成之后我们 ack 回应，再消费下一个，就能确保消息顺序性。
但是这样的操作也会降低消费者的性能，一个消费者消费消息时，其他消费者会阻塞，所以很多场景下可能并不会采用这样的方案。
所以一般会根据场景，制定一定的策略来解决消费顺序问题。
多线程并发抢占出现消费乱序问题
当MQ采用简单队列模式的时候,如果消费者采用多线程的方式来加速消息的处理,此时也会出现消息乱序的问题。
多线程并发抢占出现消费乱序问题，将消息ID进行hash计算，将相同值放入同一个内存队列，让指定线程执行，即可解决顺序消费问题。
在多个分区中保证消息顺序和消息处理效率
首先使用多个分区，消息可以被发送端发送至多个分区，保证消息发送的效率。然后在消费端在拉消息时使用ConutdownLunch来记录一组有序消息的个数。如果达到个数，说明已拉取到完整的一组有序消息。然后在消费端根据消息序号进行排序，消费端将排好序的消息发到内存队列(可以搞多个)，一个内存队列开启一个线程顺序处理消息。即可最大程度上既保证顺序又保证效率！
RocketMQ作为阿里开源的一款高性能、高吞吐量的消息中间件，支持顺序消息，所以如果有这种场景或者要使用MQ，小编建议你直接使用RocketMQ即可。
我们说了一些处理与分析问题的方法，这里有一个最重要的点就是我们需要有一套实用的监控发现工具或者方式，在问题第一时间发现才是王道，不然我们上面所说的都空谈，当问题发现的时候损失已经无法挽回。所以我们要在设计系统之初需要要为监控系统或者程序提供完备或者必须的日志，接口，数据等，这要才是一个合理的设计。当没有监控系统的情况下我们必须自己设计一套简单分析接口。
